{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc31ad21",
   "metadata": {},
   "source": [
    "# Access Token 생성\n",
    "- 학습된 모델을 Huggingface hub에 올리기 위해서는 access token이 필요하다.\n",
    "  \n",
    "![huggingface_create_apikey.png](figures/huggingface_accesstoken.png)\n",
    "![huggingface_create_apikey.png](figures/huggingface_accesstoken2.png)\n",
    "\n",
    "- 1. 로그인 -> 2. Profile -> 3. Access Tokens 선택\n",
    "- 생성할 때 `write` 권한을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce81c9e7-13a9-491d-a67e-370ba0e72894",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f033fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory 아래 `.env` file을 생성\n",
    "# .gitignore file에 `.env`를 등록해서 github에 올라가지 않도록 함.\n",
    "# 이름-값 형식으로 환경변수를 설정\n",
    "## HUGGINGFACE_API_KEY = \"받은 Access Token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418374ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경변수 값 읽기\n",
    "import os\n",
    "os.getenv(\"JAVA_HOME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# working directory에서 환경변수 파일(default : `.env`)를 찾아서 그 file에 설정된 값을 O/S의 환경변수로 등록해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얘는 재시작하면 날아가서 위 코드로 다시 등록해줘야함\n",
    "hf_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "# os.environ[\"HUGGINGFACE_API_KEY\"]\n",
    "print(hf_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a2b3c4-8539-466d-ad52-da953f97498f",
   "metadata": {},
   "source": [
    "# Naver 영화댓글 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca8d80-d72b-4c50-8225-16a06f17c731",
   "metadata": {},
   "source": [
    "# Huggingface Dataset 패키지\n",
    "- 허깅페이스 허브에 공유된 데이터셋을  다운로드해서 전처리 및 관리할 수있도록 돕는 라이브러리. \n",
    "- 많은 공개데이터셋을 동일한 인터페이스로 사용할 수있다.\n",
    "- 설치\n",
    "    - `pip install datasets`\n",
    "- https://huggingface.co/datasets\n",
    "- https://github.com/huggingface/datasets\n",
    "      \n",
    "## Huggingface Dataset loading\n",
    "- datasets 로딩\n",
    "    - `load_data('dataset name')`\n",
    "        - huggingface datasets에 등록된 Dataset 이름 넣어 Loading한다.\n",
    "          \n",
    "![img](figures/huggingface_dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf57c5-8fb9-4da6-b74d-6db47842e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSMC dataset load\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "nsmc = load_dataset(\"e9t/nsmc\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae86b0-062f-43cd-bd66-3e6b0a500a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "# DatasetDict : Dataset들을 모아놓은 dict기반의 자료구조\n",
    "#\t\t\t\ttrain/valid/test set을 모아서 제공할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(nsmc), nsmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feae1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1666892",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = nsmc['train']\n",
    "testset = nsmc['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca44c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5610ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 조회\n",
    "trainset['id'][:5], trainset['document'][:5], trainset['label'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets.Dataset을 다른 형식으로 변환\n",
    "# dataset객체.to_xxxxx()\n",
    "df = trainset.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b06fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 형식으로 저장된 data를 datasets.Dataset으로 변환\n",
    "# datasets.Dataset.from_xxxxx()\n",
    "d = datasets.Dataset.from_pandas(df.head(100))\t# df 100개만 가져오기도 가능\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de4508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling \n",
    "# train : 10_000, test : 5_000\n",
    "sample_train = trainset.shuffle().select(range(10_000))\t# dataset.shuffle() : 섞어줌\n",
    "sample_test = testset.shuffle().select(range(5_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06321f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_train)\n",
    "print(sample_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd956109-6f8f-4412-a159-4c9c4cdb0ef8",
   "metadata": {},
   "source": [
    "## 모델, 토크나이저 loading\n",
    "\n",
    "- 모델 별 Model 클래스를 이용하거나 Auto class를 이용해 모델, 전처리기(tokenizer, ImageProcessor 등)을 로딩한다.\n",
    "    - Huggingface에 저장된 model name을 입력해서 pretrained 모델을 loading 한다.\n",
    "    - fine tuning 한 경우 모델 저장 디렉토리 경로를 넣어 pretrained 모델을 loading한다.\n",
    "- AutoModel은 model name을 주면 그 모델이 학습한 base 모델에 맞는 객체를 생성해서 반환한다.\n",
    "    - Auto Model은 task 별로 다양한 클래스들이 있다.\n",
    "        - 클래스 이름 형식: AutoModelFor{Task형식}\n",
    "        - ex) `AutoModelForObjectDetection`, `AutoModelForSequenceClassification`\n",
    "    - https://huggingface.co/docs/transformers/model_doc/auto\n",
    "    - 전처리기(tokenzier)는 사용하려는 모델이 사용한 전처리기를 사용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f7b81-3eb6-4d4b-9031-d38010e13c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_id = \"beomi/kcbert-base\"\n",
    "# tokenizer, 분류 모델 로딩 - tokenizer와 model은 같은 id를 받아야함\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels = 2)\n",
    "# num_labels : 분류할 class 개수 (긍/부정)\n",
    "# model_id : kcbert-base - pretrained된 Feature Extractor\n",
    "# model : Estimator는 학습 안된 layer로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b22541-3ad5-4d18-ad53-9dbdbe6682c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb52259-f139-4db7-9314-c3496e52ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = sample_train[\"document\"]\t# sample_train -> trainset(전체)\n",
    "train_y = sample_train[\"label\"]\n",
    "\n",
    "test_X = sample_test[\"document\"]\t# sample_train -> testset(전체)\n",
    "test_y = sample_test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac6d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X(댓글)을 토큰화\n",
    "train_encoding = tokenizer(train_X, return_tensors= \"pt\", padding=True)\t# train_X에서 가장 긴 문장을 기준으로 padding 처리\n",
    "test_encoding = tokenizer(test_X, return_tensors= \"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97075240",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoding.keys()\n",
    "train_encoding['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df981f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Pytorch의 Dataset을 정의, 생성\n",
    "#################################\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "class NSMCDataset(Dataset):\n",
    "    \n",
    "\tdef __init__(self, comments, labels):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\t\tcomments(dict) : tokenizer로 토큰화한 input data\n",
    "\t\t\tlabels(list) : 정답\n",
    "\t\t\"\"\"\n",
    "\t\tself.comments = comments\n",
    "\t\tself.labels = labels\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.labels)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\t\"\"\"\n",
    "\t\tindex번 째 data를 반환\n",
    "\t\tBERT model 입력 형식에 맞춰서 반환. input_ids, token_type_ids, attention_mask + label\n",
    "\t\tArgs:\n",
    "\t\t\tindex(int)\n",
    "\t\tReturns:\n",
    "\t\t\tdictionary - input_idx, token_type_ids, attention_mask, label\n",
    "\t\t\t\t\t\t 입력 data와 정답 label을 dict에 묶어서 반환\n",
    "\t\t\"\"\"\n",
    "\t\tdata = {key:value[index] for key, value in self.comments.items()}\n",
    "\t\tdata[\"labels\"] = torch.tensor([self.labels[index]], dtype = torch.int64)\n",
    "\t\treturn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33799b2d-c76f-4c24-8704-7ad1c05c5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = NSMCDataset(train_encoding, train_y)\t# NSMCDataset 객체 생성 (train set)\n",
    "test_set = NSMCDataset(test_encoding, test_y)\t\t# NSMCDataset 객체 생성 (test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab74ab-3349-49fa-9626-3f2f28e52754",
   "metadata": {},
   "source": [
    "## pytorch Dataset 생성\n",
    "모델 입력으로 다음 4개 항목을 dictionary로 묶어서 제공하도록 구현한다.\n",
    "1. input_ids: 입력 text 토큰을 id로 변환한 값\n",
    "2. token_type_ids: 문자쌍 구분시 사용. 단일 문장: 0, 문자쌍-첫문장: 0, 두 번째 문장: 1\n",
    "3. attention_mask: 실제 토큰값과 패딩구분값\n",
    "4. labels: 정답 class index\n",
    "\n",
    "1 ~ 3은 위의 train_encoding, test_encoding으로 만듬. labels은 train_data/test_data의 label 키 값 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19f905f-3f53-480b-8e70-1e76f8479555",
   "metadata": {},
   "source": [
    "# 학습\n",
    "- Transformers는 model 학습을 위해 TrainingArguments, Trainer 클래스를 제공한다.\n",
    "- TrainingArguments Trainer를 위한 설정을 하는 클래스\n",
    "- TrainingArguments, Trainer를 이용하면 training option, logging, gradient accumulation, mixed precision등을 쉽게 설정해 학습, 평가를 모두 진행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a80239-306a-4574-ae6b-5603ae161a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "N_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 어떻게 학습할지에 대한 설정\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=\"models/nsmc\", \t# train model을 저장할 dir path\n",
    "    num_train_epochs=N_EPOCHS,\t# train epoch수\n",
    "    per_device_train_batch_size=BATCH_SIZE,\t# train batch size\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\t# eval batch size\n",
    "    \n",
    "\teval_strategy=\"epoch\",\t# 평가 전략 : \"no\", \"steps\", \"epoch\"\n",
    "    save_strategy=\"epoch\",\t# 저장 전략\n",
    "    \n",
    "\tsave_total_limit=1,\t\t# 저장할 model의 최대 개수\n",
    "    load_best_model_at_end=True,\t\t# 학습 종료 후 검증결과가 가장 좋은 모델을 저장.\n",
    "\t\t\t\t\t\t\t\t\t\t# True : eval_strategy, save_strategy가 같아야함.\n",
    "\tmetric_for_best_model= \"eval_loss\",\t# best model을 결할 검증 기준 평가지표\n",
    "    greater_is_better=False,\t\t\t# 검증 평가지표값이 높아야 좋은지 낮아야 좋은지\n",
    "    \n",
    "\treport_to =\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378b3e7-803b-41dd-9456-1d03288c7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수 정의 - evaluate 패키지를 이용\n",
    "# huggingface에서 제공하는 라이브러리, 다양한 평가함수들을 제공\n",
    "%pip install evaluate scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7ea65-606c-4572-8e6f-a253cefadb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# 정확도 평가 함수\n",
    "acc_fn = evaluate.load(\"accuracy\")\t# f1, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f858681",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.tensor([0,1,0,1])\n",
    "ref = torch.tensor([0,1,0,0])\n",
    "\n",
    "acc_fn.compute(predictions=pred, references=ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe72986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    model이 학습하는 도중 예측값을 받아서 평가 점수를 계산하는 func\n",
    "    Trainer에 의해서 호출된 func\n",
    "    Args:\n",
    "\t\tpred(EvalPrediction) - model의 예측값, 정답들을 묶어서 제공\n",
    "\tReturns:\n",
    "\t\tdictionary - key: 평가지표이름, value: 평가점수\n",
    "    \"\"\"\n",
    "    labels = pred.label_ids\t\t# 정답\n",
    "    preds = pred.predictions.argmax(axis=-1)\t\t# model의 출력값\n",
    "    metrics1 = evaluate.load(\"accuracy\")\n",
    "    metrics2 = evaluate.load(\"f1\")\n",
    "    \n",
    "    acc = metrics1.compute(references = labels, predictions = preds)\n",
    "    f1 = metrics2.compute(references = labels, predictions = preds)\n",
    "    return {\"accuracy\" : acc, \"f1\" : f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c10b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 객체\n",
    "trainer = Trainer(\n",
    "    model = model,\t\t\t\t# 학습 모델 대상\n",
    "    args = train_args,\t\t\t# TrainingArguments\n",
    "    train_dataset=train_set,\t# 학습 dataset, pythorch의 Dataset객체\n",
    "    eval_dataset=test_set,\t\t# 검증 dataset\n",
    "    compute_metrics = compute_metrics\t# loss 이외에 검증/평가 시 확인할 지표를 계산하는 func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ab4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f9fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa63859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 - local directory\n",
    "## tokenizer와 model을 같이 같은 경로에 저장\n",
    "save_path = \"models/nsmc\"\n",
    "tokenizer.save_pretrained(save_path)\n",
    "model.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6e490a-4d3e-454d-a7dd-15b052cee797",
   "metadata": {},
   "source": [
    "## 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23911e38-7e34-416d-9137-b9ce7c7895d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "save_path = \"models/nsmc\"\n",
    "load_tokenizer = AutoTokenizer.from_pretrained(save_path)\n",
    "load_model = AutoModelForSequenceClassification.from_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e0f780-a07d-45d4-af5b-43af910adc5c",
   "metadata": {},
   "source": [
    "# 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1abb813-88ca-41b3-8be6-7ff47eef5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"이걸 영화라고 만든 거냐?\", \"아무 기대 없이 봤는데 재미있네.\", \"내가 감독이어도 이것보다 재미있게 만들겠다.\", \"시간이 어떻게 가는 줄 모르고 봤다.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81194e5f-9197-46b7-9074-c54ca04ebdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(task = \"text-classification\", tokenizer = load_tokenizer, model = load_model)\n",
    "result = pipe(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef35b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 학습한 model, tokenizer를 huggingface hub에 업로드 ######\n",
    "# 1. TrainingArguments에 설정해서 학습 도중 끝나면 자동으로 업로드 되게 설정\n",
    "# 2. model/tokenizer.push_to_hub(\"계정/모델id\")를 이용해서 수동으로 올린다.\n",
    "\n",
    "# 로그인\n",
    "from huggingface_hub import login\n",
    "# login() # token에 Access Token 입력 후 Login 클릭\n",
    "login(\"Huggingface Access Token\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d50cca-be78-4fb9-bb8c-9a3a0ff02b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "hf_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "login(hf_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168441b-4ca7-4a46-bf02-e5eb6030d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"kcbert-nsmc-10000\"\n",
    "load_tokenizer.push_to_hub(model_id)\n",
    "load_model.push_to_hub(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc7f10b-f61f-4f3d-abb0-29c00fdc679a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
