{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ee8245-0329-4185-971d-21bf20cc780e",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "**Chain**(체인)은 여러 컴포넌트(요소)를 정해진 순서대로 연결하여 **복잡한 AI 작업을 단계별로 자동화**할 수 있도록 돕는 구조이다.\n",
    "\n",
    "- 각 컴포넌트는 입력을 받아 특정 처리를 수행한 후 다음 단계로 결과를 전달한다.\n",
    "- 복잡한 작업을 여러 개의 단순한 단계로 나누고, 각 단계를 순차적으로 실행함으로써 전체 작업을 체계적으로 구성할 수 있다.\n",
    "\n",
    "## 기본 개념\n",
    "\n",
    "- 체인은 하나의 LLM 호출에 그치지 않고 **여러 LLM 호출이나 도구 실행을 순차적으로 연결**할 수 있다.\n",
    "- 예를 들어, 사용자의 질문 → 검색 → 요약 → 응답 생성 같은 일련의 작업을 체인으로 구성할 수 있다.\n",
    "- 체인을 사용하면 코드의 재사용성과 유지 보수성이 향상된다.\n",
    "\n",
    "## LangChain에서의 Chain 구성 방식\n",
    "\n",
    "LangChain은 다음 두 가지 방식을 통해 체인을 구성할 수 있다.\n",
    "\n",
    "### 1. Off-the-shelf Chains 방식 (클래식 방식)\n",
    "\n",
    "- LangChain에서 제공하는 **미리 정의된 Chain 클래스**(예: `LLMChain`, `SequentialChain`, `SimpleSequentialChain`)를 활용하는 방식이다.\n",
    "- 이 방식은 LangChain의 **초기 구조**이며, 대부분의 클래스는 현재 **더 이상 사용되지 않음(deprecated)** 상태이다.\n",
    "\n",
    "> 현재 LangChain에서는 이 방식을 권장하지 않는다.\n",
    "\n",
    "### 2. LCEL (LangChain Expression Language) 방식\n",
    "\n",
    "- 체인을 함수형 방식으로 선언할 수 있는 **표현식 기반의 체인 구성 언어**이다.\n",
    "- LCEL 방식은 간결하고 선언적인 문법을 제공하여 **직관적이고 확장성 있는 체인 구성**이 가능하다.\n",
    "- `Runnable`이라는 공통 인터페이스를 기반으로 다양한 요소를 조합하여 체인을 구성한다.\n",
    "- 체인의 각 구성 요소는 `invoke()` 메서드로 실행된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba00ec-6c7c-496e-b31f-f3978b74bdba",
   "metadata": {},
   "source": [
    "# [LCEL](https://python.langchain.com/docs/how_to/#langchain-expression-language-lcel) (LangChain Expression Language)\n",
    "- LCEL은 LangChain의 핵심 기능인 체인(Chain)을 더욱 간결하고 유연하게 구성할 수 있도록 고안된 **선언형 체인(chain) 구성 언어**이다.\n",
    "- 파이프 연산자 `|`를 사용해 선언적 방법으로 여러 작업을 연결한다.\n",
    "- 체인을 구성하는 각 요소는 `Runnable` 타입으로, 체인 내에서 실행 가능한 단위이다.\n",
    "- 각 단계는 invoke() 메서드를 통해 실행되며, 앞 단계의 출력이 다음 단계의 입력으로 자동 전달된다.\n",
    "    - [Runnable 컴포넌트별 입출력 타입](https://python.langchain.com/docs/concepts/runnables/#input-and-output-types)\n",
    "    - 각 컴포넌트의 input과 output 타입에 맞춰 값이 전달되도록 한다.\n",
    "- https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f9cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# off-the-shelf 방식\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"{item}에 어울리는 이름 {count}개를 만들어 주세요\"\n",
    "    )\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 변수:값 -> (prompt_template)-prompt -> (model)-응답결과 -> (parser) -> 최종결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c22bd983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_16808\\1602056365.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "chain = LLMChain(\n",
    "    prompt=prompt_template,\n",
    "    llm=model,\n",
    "    output_parser=parser\n",
    ")\n",
    "response = chain.invoke({\"item\":\"가방\", \"count\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027eb8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item': '가방',\n",
       " 'count': 5,\n",
       " 'text': '물론입니다! 가방에 어울리는 멋진 이름 다섯 개를 제안해 드릴게요:\\n\\n1. **루미너스 가방** - 빛나는 듯한 매력을 지닌 가방\\n2. **스텔라 백** - 별처럼 독특한 스타일을 가진 가방\\n3. **엘레강스 클러치** - 우아함이 강조된 클러치 백\\n4. **모던 트렌드 백** - 현대적인 감각의 트렌디한 가방\\n5. **디자인 포켓** - 실용성과 디자인을 모두 갖춘 포켓 가방\\n\\n이 이름들이 가방의 개성을 잘 표현해 줄 수 있기를 바랍니다!'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "767d0f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 가방에 어울리는 멋진 이름 다섯 개를 제안해 드릴게요:\n",
      "\n",
      "1. **루미너스 가방** - 빛나는 듯한 매력을 지닌 가방\n",
      "2. **스텔라 백** - 별처럼 독특한 스타일을 가진 가방\n",
      "3. **엘레강스 클러치** - 우아함이 강조된 클러치 백\n",
      "4. **모던 트렌드 백** - 현대적인 감각의 트렌디한 가방\n",
      "5. **디자인 포켓** - 실용성과 디자인을 모두 갖춘 포켓 가방\n",
      "\n",
      "이 이름들이 가방의 개성을 잘 표현해 줄 수 있기를 바랍니다!\n"
     ]
    }
   ],
   "source": [
    "print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f0d52c-23da-4ec6-87cc-925e3d6259ea",
   "metadata": {},
   "source": [
    "## [Runnable](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html)\n",
    "- LangChain의 Runnable은 실행 가능한 작업 단위를 캡슐화한 개념으로, 데이터 흐름의 각 단계를 정의하고 **체인(chain) 에 포함 되어**  복잡한 작업의 각 단계를 수행 한다.\n",
    "- Chain을 구성하는 class들은 Runnable의 상속 받아 구현한다.\n",
    "- **Prompt Template클래스**, **Chat 모델, LLM 모델 클래스**, **Output Parser 클래스** 등 다양한 컴포넌트가 Runnable을 상속받아 구현된다.\n",
    "\n",
    "### 주요 특징\n",
    "- 작업 단위의 캡슐화:\n",
    "    - Runnable은 특정 작업(예: 프롬프트 생성, LLM 호출, 출력 파싱 등)을 수행하는 독립적인 컴포넌트이다.\n",
    "    - 각 컴포넌트는 독립적으로 테스트 및 재사용이 가능하며, 조합하여 복잡한 체인을 구성할 수 있다.\n",
    "- 체인 연결 및 작업 흐름 관리:\n",
    "    - Runnable은 체인(chain, 일련의 연결된 작업 흐름)을 구성하는 기본 단위로 사용된다.\n",
    "    - LangChain Expression Language(LCEL)를 사용하면 | 연산자를 통해 여러 Runnable을 쉽게 연결할 수 있다.\n",
    "    - 입력과 출력의 형식을 일관되게 유지하여 각 단계가 자연스럽게 연결된다.\n",
    "- 모듈화 및 디버깅 용이성:\n",
    "    - 각 단계가 명확히 분리되어 문제 발생 시 어느 단계에서 오류가 발생했는지 쉽게 확인할 수 있다.\n",
    "    - 복잡한 작업을 작은 단위로 나누어 체계적으로 관리할 수 있다.\n",
    "      \n",
    "### Runnable의 표준 메소드\n",
    "- 모든 Runnable이 구현하는 공통 메소드\n",
    "    - `invoke()`: 단일 입력을 처리하여 결과를 반환.\n",
    "    - `batch()`: 여러 입력 데이터들을 한 번에 처리.\n",
    "    - `stream()`: 입력에 대해 스트리밍 방식으로 응답을 반환.\n",
    "    - `ainvoke()`: 비동기 방식으로 입력을 처리하여 결과를 반환. (속도 빠름)\n",
    "\n",
    "### Runnable의 주요 구현체(하위 클래스)\n",
    "\n",
    "- `RunnableSequence`\n",
    "    - 여러 `Runnable`을 순차적으로 연결하여 실행하는 구성이다.\n",
    "    - 각 단계의 출력이 다음 단계의 입력으로 전달된다.\n",
    "    - LCEL을 사용하여 체인을 구성할 경우 자동으로 `RunnableSequence`로 변환된다.\n",
    "-  `RunnablePassThrough`\n",
    "    - 입력 데이터를 가공하지 않고 그대로 다음 단계로 전달하는 `Runnable`이다.\n",
    "    - 선택적으로 미리 정의된 키-값 쌍을 함께 전달할 수 있다.\n",
    "\n",
    "- `RunnableParallel`\n",
    "    - 여러 `Runnable`을 병렬로 실행한 후, 결과를 결합하여 다음 단계로 전달한다.\n",
    "    - 병렬 처리를 통해 처리 속도를 개선할 수 있다.\n",
    "\n",
    "- `RunnableLambda`\n",
    "    - 일반 함수 또는 `lambda` 함수를 `Runnable`로 변환하여 체인에 포함할 수 있다.\n",
    "    - 사용자 정의 함수로 동작을 확장할 때 유용하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f2ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98816c-6666-4d36-a91d-4b4f64519de4",
   "metadata": {},
   "source": [
    "#### Runnable 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c0af369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable # 모든 Runnable의 최상위\n",
    "# 사용자정의 Runnable\n",
    "class MyRunnable(Runnable):\n",
    "\n",
    "    def invoke(self, input_data:str, config:dict=None):\n",
    "        # invoke(): 구현하는 Runnable이 해야하는 작업을 구현하는 메소드.\n",
    "        # input_data: 입력값\n",
    "        # config: 일할 때 필요한 설정값들\n",
    "        if config is not None and config.get('lang') == \"en\":\n",
    "            return f\"Explain {input_data} in one sentences.\"\n",
    "        return f\"{input_data}에 대해서 한 문장으로 설명해줘.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a5ac9fd-2616-4031-a079-a1822d784e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explain Apple in one sentences.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_runnable = MyRunnable()\n",
    "my_runnable.invoke(\"사과\")\n",
    "my_runnable.invoke(\"컴퓨터\")\n",
    "my_runnable.invoke(\"Apple\", {\"lang\":\"en\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9a0680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langchain은 다양한 언어 모델과 외부 데이터 소스를 연결하여 자연어 처리 애플리케이션을 구축할 수 있도록 돕는 프레임워크입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 19, 'total_tokens': 56, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BgjJSF4WqrABNj3e9G7LI12yd9G5G', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--6590f1eb-5586-46ae-b57e-85eb6cc70fc1-0' usage_metadata={'input_tokens': 19, 'output_tokens': 37, 'total_tokens': 56, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "my_runnable = MyRunnable()\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "prompt = my_runnable.invoke(\"Apple\", {\"lang\":\"en\"})\n",
    "prompt = my_runnable.invoke(\"Langchain\")\n",
    "response = model.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96f7012b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='배는 부드러운 과육과 달콤한 맛을 가진 과일로, 주로 샐러드나 디저트에 사용된다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 20, 'total_tokens': 53, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BgjLVQAHNXXzmCJzo5vmynjJ7SKCQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e47f2f63-abb2-4f52-945f-e32764ed94d7-0', usage_metadata={'input_tokens': 20, 'output_tokens': 33, 'total_tokens': 53, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain -> Runnable | Runnable | Runnable\n",
    "chain = my_runnable | model\n",
    "\n",
    "# chain 호출 => invoke\n",
    "res = chain.invoke(\"과일 배\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7957d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# 기본 체인 구성: prompt_template -> model -> output parser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, CommaSeparatedListOutputParser\n",
    "\n",
    "# role: system, user/human, ai/assistant\n",
    "#       system: 채팅 전체에 적용되는 공통 지침을 지정하는 role\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", \"당신은 오랜 경력의 한국 관광 가이드입니다. 여행객들에게 설명하듯이 친절하게 답변을 해주세요.\"),\n",
    "        (\"human\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=1.0)\n",
    "\n",
    "guide_chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "print(type(guide_chain)) # RunnableSequence: Runnable 타입 => chain도 다른 chain의 구성 요소로 포함될 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93e07c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"서울에서 꼭 가봐야하는 여행지를 세 곳만 알려줘.\"\n",
    "response = guide_chain.invoke({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fda4538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 서울은 다양한 매력적인 여행지로 가득한 도시입니다. 그 중에서 꼭 가봐야 할 세 곳을 추천해드릴게요.\n",
      "\n",
      "1. **경복궁**: 서울의 대표적인 고궁인 경복궁은 조선 왕조의 주거지였습니다. 아름다운 건축물과 함께 한국의 전통 문화를 느낄 수 있는 곳이죠. 특히, 정오에는 수문장 교대식도 볼 수 있으니 시간 맞추어 가시면 좋습니다. 주변에 국립민속박물관과 청와대도 있으니 함께 둘러보시면 더 좋습니다.\n",
      "\n",
      "2. **남산서울타워(N 서울타워)**: 서울을 한눈에 내려다볼 수 있는 명소로, 남산의 정상에 위치해 있습니다. 타워에 올라가면 멋진 서울의 전경을 감상할 수 있으며, 밤에는 특히 아름답게 빛나는 야경이 인상적입니다. 타워 주변의 남산공원에서 산책도 즐길 수 있으니 시간 여유를 두고 가보세요.\n",
      "\n",
      "3. **명동**: 서울의 패션과 쇼핑의 중심지로, 다양한 브랜드 상점과 맛있는 거리가 가득합니다. 특히 길거리 음식은 놓칠 수 없는 매력이죠! 다양한 먹거리를 즐기며 한국의 현대적인 면모도 느끼실 수 있습니다. 또한, 명동성당과 같은 역사적인 건물도 있어 가벼운 관광 코스로 좋습니다.\n",
      "\n",
      "이 세 곳은 서울의 전통과 현대를 모두 체험할 수 있는 장소들이니, 꼭 방문해보시길 추천드립니다! 즐거운 여행 되세요!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44bfdb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 세 번째 관광지에 대해서 자세히 설명해주\n",
      "AI: 물론이죠! 세 번째 관광지에 대해 자세히 설명해 드리겠습니다. 다만, 제가 어떤 관광지를 말하는지 모르므로, 여러 유명한 관광지 중 하나를 예로 들어 설명해 보겠습니다. 만약 특정 관광지를 염두에 두셨다면 말씀해 주세요!\n",
      "\n",
      "예를 들어, **경주**를 소개해 드리겠습니다.\n",
      "\n",
      "경주는 한국의 역사와 문화가 살아 숨 쉬는 도시로, 신라 시대의 수도였던 장소입니다. 이곳은 유네스코 세계유산으로 등록된 많은 유적지와 고택이 있어, 여행객들에게 깊은 인상을 남깁니다.\n",
      "\n",
      "1. **불국사**: 세계문화유산으로 지정된 이 사찰은 신라 시대의 대표적인 불교 건축물입니다. 특히, 아름다운 석탑과 대웅전의 웅장한 모습은 압도적입니다. 사찰 내부에는 다양한 불상과 고대의 유물들이 보관되어 있어, 신라 시대의 불교문화에 대해 깊이 있게 이해할 수 있습니다.\n",
      "\n",
      "2. **석굴암**: 불국사와 함께 세계문화유산으로 등재된 석굴암은 인공적으로 조성된 석굴 사원입니다. 이곳의 중심에는 아미타불이 조각되어 있는데, 정교한 조각과 내부의 독특한 구조가 상당한 예술적 가치를 자랑합니다. 자연과 인공의 조화가 아름답게 이루어진 장소로, 많은 관광객이 사진을 찍기 위해 찾아옵니다.\n",
      "\n",
      "3. **경주 동궁과 월지**: 이곳은 신라 왕족의 별궁이었던 자리로, 아름다운 연못과 함께 환상적인 야경을 제공합니다. 특히 밤이 되면 조명이 켜져 매우 로맨틱한 분위기를 자아내어, 많은 사람들이 산책을 즐깁니다.\n",
      "\n",
      "4. **안압지**: 경주의 또 다른 아름다운 장소인 안압지는 역사적인 의미 외에도 자연경관이 뛰어납니다. 이곳은 신라 시대의 궁궐터로, 연못과 꽃들이 어우러져 평화롭고 serene한 분위기를 만들어냅니다.\n",
      "\n",
      "이처럼 경주는 역사적인 의미뿐 만 아니라, 아름다운 자연경관과 조화롭게 어우러져 많은 관광객에게 편안한 힐링의 장소가 되고 있습니다. 방문하시면 그 매력에 푹 빠지실 것입니다!\n",
      "\n",
      "다른 관광지를 원하신다면 구체적으로 말씀해 주세요! 추가로 더 설명드리겠습니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"질문:\")\n",
    "    if query == \"!quit\":\n",
    "        break\n",
    "    resp = guide_chain.invoke({\"query\":query})\n",
    "    print(\"User:\", query)\n",
    "    print(\"AI:\", resp)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579eb03d",
   "metadata": {},
   "source": [
    "#### RunnableLambda 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e07649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반 함수 또는 lambda 함수를 실행하는 runnable을 생성. Class로 복잡하게 만들 필요 없어짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89f810ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LLM를 한 문장으로 설명해줘.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "my_runnable2 = RunnableLambda(lambda input_data : f\"{input_data}를 한 문장으로 설명해줘.\")\n",
    "# lambda input_data : f\"{input_data}를 한 문장으로 설명해줘.\"\n",
    "my_runnable2.invoke(\"LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4c5c5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LLM(대형 언어 모델)은 방대한 양의 텍스트 데이터를 기반으로 자연어를 이해하고 생성하는 머신러닝 모델입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 18, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BgkAMawwgRnlERioa5b8T52bvDRJs', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--98249d14-6239-453f-814e-899d3651aa80-0', usage_metadata={'input_tokens': 18, 'output_tokens': 32, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = my_runnable2 | model\n",
    "chain.invoke(\"LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e352cd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum(nums):\n",
    "    return nums[0]+nums[1]\n",
    "\n",
    "my_runnable2 = RunnableLambda(sum)\n",
    "my_runnable2.invoke({0:10, 1:20})\n",
    "\n",
    "# invoke(입력데이터:str|dict, 설정정보:dict)\n",
    "# 입력데이터가 여러개일 경우 dict 등의 자료구조를 이용해서 받는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884fd4c-feaa-46f1-af21-c5779900e502",
   "metadata": {},
   "source": [
    "#### RunnablePassthrough 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e43fcf5-e5c7-4502-830f-b722b832f3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## RunnablePassthrough ##########\n",
    "# 1. 앞 Runnable이 처리한 결과를 다음 Runnable에 그대로 전달\n",
    "# 2. 앞 Runnable이 처리한 결과에 Item을 추가해서 다음 Runnable에 전달\n",
    "# RunnableParallel과 함께 많이 쓰임\n",
    "#########################################\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1e9e6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key': 'value'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "RunnablePassthrough().invoke(\"안녕하세요\")\n",
    "RunnablePassthrough().invoke({\"key\":\"value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11bd0e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '홍길동', 'address': '서울시 금천구', 'phone': '010-1111-2222'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 -> 입력으로 dictionary 받아서 거기에 item을 추가.\n",
    "# RunnablePassthrough.assign(key=Runnable, key=Runnable, ...)\n",
    "# 받은 dictionary에 \"key1\":Runnable반환값, \"key2\":\"Runnable반환값\", .. 추가해서 다음으로 전달\n",
    "\n",
    "address_runnable = RunnableLambda(lambda x: \"서울시 금천구\") # \"서울시 금천구\"를 반환.\n",
    "phone_runnable = RunnableLambda(lambda x: \"010-1111-2222\")\n",
    "\n",
    "RunnablePassthrough.assign(address=address_runnable, phone=phone_runnable).invoke({\"name\":\"홍길동\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ba482-5dab-41df-96d1-c6649ecb8cee",
   "metadata": {},
   "source": [
    "#### RunnableSequence 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afd2c247-a4e3-4b1b-a494-400b077eba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain과 같은 역할. 실제로 RunnableSequence를 써서 만들 이유는 없음.\n",
    "\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "run1 = RunnableLambda(lambda x: x+1)\n",
    "run2 = RunnableLambda(lambda x: x*2)\n",
    "\n",
    "chain = run1 | run2\n",
    "print(type(chain))\n",
    "chain.invoke(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "251c80dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2 = RunnableSequence(run1, run2) # (prompt_template, model, output_parser)\n",
    "chain2.invoke(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1531bb-ad33-4d1b-a59b-62cf08cb4457",
   "metadata": {},
   "source": [
    "#### RunnableParallel 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cce6992c-85e1-4a2f-b16f-e294c50a3c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result1': 11, 'result2': 20, 'result3': 3, 'result4': 10}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Runnable들을 각각 실행하고 그 결과를 key에 할당한 Dictionary에 반환\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "run1 = RunnableLambda(lambda x: x+1)\n",
    "run2 = RunnableLambda(lambda x: x*2)\n",
    "run3 = RunnableLambda(lambda x: x//3)\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    {\n",
    "        \"result1\":run1,\n",
    "        \"result2\":run2,\n",
    "        \"result3\":run3,\n",
    "        \"result4\":RunnablePassthrough() # 앞에서 받은 값을 그대로 다음에 전달.\n",
    "    }\n",
    ")\n",
    "runnable.invoke(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af622cf3-8627-4136-80cd-2c87b31f743a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fe6327f-591c-4d0b-87b2-796d41ad6b98",
   "metadata": {},
   "source": [
    "#### LCEL Chain 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e916435d-e288-4ca3-9e32-b3c17e95d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음식 이름을 받아서 레시피를 \"영어로\" 출력하는 chain을 구성\n",
    "# prompt template -> model -> output parser\n",
    "\n",
    "# 기본 체인 구성: prompt_template -> model -> output parser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from textwrap import dedent\n",
    "\n",
    "# role: system, user/human, ai/assistant\n",
    "#       system: 채팅 전체에 적용되는 공통 지침을 지정하는 role\n",
    "prompt_template = PromptTemplate(\n",
    "    template=dedent(\"\"\"\n",
    "    # instruction\n",
    "    당신은 숙련된 요리 연구가입니다. 요청한 음식의 레시피를 작성해주세요.\n",
    "    \n",
    "    # Input data\n",
    "    음식이름: {food}\n",
    "\n",
    "    # Output indicator\n",
    "    - 다음 항목을 넣어서 작성하세요.\n",
    "        - 재료\n",
    "        - 조리 순서               \n",
    "    \"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "food_chain = prompt_template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "047be191-28eb-4674-af53-9ac2a0d0ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = food_chain.invoke({\"food\":\"탕후루\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "06149d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 탕후루 레시피\n",
      "\n",
      "## 재료\n",
      "- 식용유 (튀김용) 적당량\n",
      "- 딸기 또는 물엿에 담근 과일 (예: 포도, 귤 등) 10~12개\n",
      "- 설탕 1컵\n",
      "- 물 1/2컵\n",
      "- 레몬즙 1큰술\n",
      "- 옥수수 전분 1큰술 (선택사항, 바삭한 식감을 원할 경우)\n",
      "- 김치 젓갈이나 소금 약간 (조리 시 간을 맞추기 위한 기본 재료로 선택사항)\n",
      "\n",
      "## 조리 순서\n",
      "\n",
      "1. **재료 준비**: 딸기와 같은 과일들을 깨끗이 씻고 물기를 제거합니다. 과일이 물에 젖어 있으면 설탕이 잘 붙지 않으니 주의하세요.\n",
      "\n",
      "2. **설탕 시럽 만들기**: 작은 냄비에 설탕, 물, 레몬즙을 넣고 중약 불에서 끓입니다. 설탕이 완전히 녹을 때까지 저어준 후, 약 5-10분 정도 끓여 시럽이 농도가 될 때까지 조리합니다. (옥수수 전분을 사용할 경우, 시럽이 바로 끓기 시작했을 때 옥수수 전분을 미리 물에 풀어 넣어주세요.)\n",
      "\n",
      "3. **튀김기 준비**: 깊은 팬이나 냄비에 식용유를 부어 예열합니다. (약 170도 정도) 기름이 준비되면 과일을 한 번에 튀길 수 있을 만큼만 준비하세요.\n",
      "\n",
      "4. **과일 튀기기**: 과일을 설탕 시럽에 담가 고루 묻힌 후, 예열된 기름에 조심스럽게 넣습니다. 과일의 표면이 황금색으로 바삭하게 튀겨질 때까지 약 2-3분 정도 튀깁니다.\n",
      "\n",
      "5. **기름 빼기**: 튀겨진 과일을 기름에서 빼내어 키친타올 위에 올려 기름을 제거합니다.\n",
      "\n",
      "6. **서빙**: 완성된 탕후루는 식혀서 바삭한 상태로 먹는 것이 좋습니다. 필요하면 찬 물에 급속히 식히거나 얼음 모양의 그릇에 담아 내면 더욱 예쁘게 즐길 수 있습니다.\n",
      "\n",
      "이제 맛있는 탕후루가 완성되었습니다! 생과일의 달콤함과 바삭한 식감이 조화를 이루어 특별한 간식으로 즐길 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e306d3-430f-4bfa-982c-a806e1910f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 chain -> 입력된 내용을 지정한 언어로 번역하는 체인.\n",
    "# prompt template -> model -> output parser\n",
    "\n",
    "prompt_template_trans = PromptTemplate(\n",
    "    template=dedent(\"\"\"\n",
    "    # instruction\n",
    "    당신은 모든 언어를 다룰 줄 아는 번역가입니다. 입력내용을 지정된 언어 {language}로 번역해주세요.\n",
    "    \n",
    "    # Input data(번역할 문장)\n",
    "    내용: {content}\n",
    "    \"\"\"\n",
    "    )\n",
    ")\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "translate_chain = prompt_template_trans | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7d1ab4d0-0f9f-4227-a821-5d9751d49942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## تانغولو (الفاكهة المسكرة)\n",
      "\n",
      "### المكونات:\n",
      "- 200 جرام من توت السدر (أو تفاح/كرز كفاكهة بديلة)\n",
      "- 200 جرام من السكر الحبيبي\n",
      "- 100 مل من الماء\n",
      "- 1 ملعقة طعام من شراب الذرة (اختياري، لمزيد من اللمعان)\n",
      "- أسياخ خشبية\n",
      "- ورق زبدة (للتبريد)\n",
      "\n",
      "### التعليمات:\n",
      "\n",
      "1. **تحضير الفاكهة:**\n",
      "   - اشطف توت السدر تحت الماء البارد لإزالة الأوساخ.\n",
      "   - إذا كنت تستخدم فواكه أخرى، اغسلها وجففها جيدًا. إذا اخترت التفاح أو الكرز، قم بإزالة النواة أو البذور حسب الحاجة.\n",
      "   - قم بتثبيت التوت أو الفواكه على الأسياخ الخشبية، مع ترك مساحة بين كل قطعة.\n",
      "\n",
      "2. **تحضير شراب السكر:**\n",
      "   - في قدر متوسط، امزج السكر الحبيبي والماء وشراب الذرة (إذا كنت تستخدمه).\n",
      "   - ضع القدر على نار متوسطة، مع التحريك المستمر حتى يذوب السكر بالكامل.\n",
      "   - بعد الذوبان، زد الحرارة حتى يغلي المزيج. لا تقم بالتحريك بمجرد أن يبدأ الغليان.\n",
      "\n",
      "3. **طهي الشراب:**\n",
      "   - استمر في غلي الشراب حتى يصل إلى درجة حرارة حوالي 150 درجة مئوية (300 درجة فهرنهايت) على ميزان حرارة الحلوى، أو حتى يتحول لونه إلى الذهبي ويتجاوز اختبار التكسير (قم بسكب كمية صغيرة في الماء البارد؛ يجب أن تتصلب على الفور).\n",
      "\n",
      "4. **تغليف الفاكهة:**\n",
      "   - قم بإزالة القدر بسرعة من النار. أمسك كل سيخ فوق الشراب واغمس الفاكهة في الشراب المغلي، مع التأكد من تغطيته بالكامل.\n",
      "   - اترك الشراب الزائد يتقطر قبل وضع الأسياخ على ورق الزبدة لتبرد وتتصلب.\n",
      "\n",
      "5. **التبريد والتقديم:**\n",
      "   - اترك الفاكهة المسكرة تبرد تمامًا حتى يصبح الشراب صلبًا وقويًا.\n",
      "   - قدّمها كوجبة خفيفة ممتعة أو حلوى، واستمتع بالملمس المقرمش والمذاق الحلو والحامض!\n",
      "\n",
      "### نصائح:\n",
      "- تأكد من أن الشراب ساخن بما يكفي قبل الغمس للحصول على سطح مقرمش مثالي.\n",
      "- يمكنك إضافة ملون غذائي إلى الشراب للحصول على مظهر احتفالي، إذا رغبت.\n"
     ]
    }
   ],
   "source": [
    "trans_res = translate_chain.invoke({\"content\":response, \"language\":\"아랍어\"})\n",
    "print(trans_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c45fac",
   "metadata": {},
   "source": [
    "## Chain과 Chain간의 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9cd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# food chain ----> translate_chain\n",
    "## food_chain_prompt: 변수 - food\n",
    "## translate_chain_prompt: 변수 - language\n",
    "\n",
    "# food -> food_chain, language -> translate_chain\n",
    "# food_chain 최종결과(레시피) => {\"content\":레시피} - 전달 -> translate_chain\n",
    "\n",
    "# RunnableParallel({\"key\":Runnable, \"key2\":Runnable})\n",
    "# LCEL에서 RunnableParallel => {\"key\":Runnable, \"key2\":Runnable} |\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "full_chain = RunnableParallel(\n",
    "    {\"content\": food_chain,\n",
    "     \"language\": RunnableLambda(lambda x: x['language'])} # RunnablePassthrough(lambda x: x['language'])} / RunnableLambda(lambda x: x['language'])}\n",
    ") | translate_chain\n",
    "\n",
    "full_res = full_chain.invoke({\"food\":\"갈비찜\", \"language\":\"한국어\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fc9f3200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 갈비찜 레시피\n",
      "\n",
      "## 재료\n",
      "- 소갈비 1kg\n",
      "- 당근 1개 (꽤 크게)\n",
      "- 감자 1개\n",
      "- 양파 1개\n",
      "- 대파 1대\n",
      "- 마늘 5쪽\n",
      "- 생강 1조각 (약 10g)\n",
      "- 간장 1컵\n",
      "- 물 3컵\n",
      "- 설탕 2큰술\n",
      "- 참기름 1큰술\n",
      "- 후춧가루 약간\n",
      "- 통깨 약간\n",
      "- 식용유 적당량\n",
      "\n",
      "## 조리 순서\n",
      "\n",
      "1. **갈비 손질**: 소갈비는 찬물에 1-2시간 담궈 핏물을 제거한 후, 물기를 제거합니다.\n",
      "\n",
      "2. **양념 준비**: 큰 볼에 간장, 물, 설탕, 참기름, 다진 마늘, 다진 생강, 후춧가루를 넣고 잘 섞어 양념장을 만듭니다.\n",
      "\n",
      "3. **갈비 재우기**: 핏물이 제거된 갈비를 양념장에 1시간 이상 재워둡니다. 자주 뒤집어 주세요.\n",
      "\n",
      "4. **재료 손질**: 당근과 감자는 먹기 좋은 크기로 썰고, 양파는 크게 채 썰고, 대파는 송송 썰어 준비합니다.\n",
      "\n",
      "5. **갈비 익히기**: 큰 냄비에 식용유를 두르고 재워둔 갈비를 갈색이 나도록 볶아줍니다. 그 후 양념장을 넣고 중불에서 끓입니다.\n",
      "\n",
      "6. **채소 추가**: 끓기 시작하면 썰어둔 당근, 감자, 양파를 넣고 불을 약하게 줄여줍니다. 뚜껑을 덮고 40-50분 정도 푹 익힙니다. 중간중간 양념과 재료가 타지 않도록 잘 저어주세요.\n",
      "\n",
      "7. **마무리**: 모든 재료가 잘 익고 양념이 자작하게 졸아들면, 뚜껑을 열고 위에서 대파를 넣고 2-3분 더 끓입니다.\n",
      "\n",
      "8. **서빙**: 완성된 갈비찜을 그릇에 담고 통깨를 뿌려 장식하세요. 뜨끈하게 제공하고 밥과 함께 즐기면 좋습니다.\n",
      "\n",
      "맛있게 드세요!\n"
     ]
    }
   ],
   "source": [
    "print(full_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b59505-5ef9-4bc5-9a32-9e359d3bf0a1",
   "metadata": {},
   "source": [
    "# 사용자 함수를 Chain에 적용하기\n",
    "\n",
    "## 사용자 함수를 Runnable로 정의 (RunnableLambda)\n",
    "- 임의의 함수를 Runnable로 정의 할 수있다.\n",
    "  - chain에 포함할 기능을 함수로 정의할 때 주로 사용. \n",
    "- `RunnableLambda(함수)` 사용\n",
    "  - 함수는 invoke() 메소드를 통해 입력받은 값을 받을 **한개의 파라미터**를 선언해야 한다.\n",
    "\n",
    "## 사용자 함수를 Chain으로 정의\n",
    "- Chain 을 구성하는 작업 사이에 추가 작업이 필요할 경우, 중간 결과를 모두 사용해야 하는 경우 함수로 구현한다.\n",
    "- `@chain` 데코레이터를 사용해 함수에 선언한다.\n",
    "\n",
    "### Runnable 에 사용할 **사용자 정의 함수** 구문\n",
    "- 이전 Chain의 출력을 입력 받는 **파라미터를 한개** 선언한다. (첫번째 파라미터)\n",
    "- `invoke()`로 호출 할때 전달 하는 추가 설정을 입력받는 파라미터를 선언한다.(두번째 파라미터 - Optional)\n",
    "  - RunnableConfig 타입의 값을 받는데 Dictionary 형식으로 `{\"configuable\": {\"설정이름\":\"설정값\"}}` 형식으로 받는다.\n",
    "- 만약 함수가 여러개의 인자를 받는 경우 단일 입력을 받아들이고 이를 여러 인수로 풀어내는 래퍼 함수를 작성하여 Runnable로 만든다.\n",
    "  ```python\n",
    "  def plus(num1, num2):\n",
    "      ...\n",
    "\n",
    "  def wrapper_plus(nums:dict|list):\n",
    "      return plus(nums['num1'], nums['num2'])\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0de6e8-4bcf-412c-8983-9be3d7679ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69710192-a281-43a2-b944-ccd3705d3b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c44ce-3e5b-4992-9ddf-cb2835c361be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c8b48ae-b4b2-412f-a7b5-17e9c1ebc1a4",
   "metadata": {},
   "source": [
    "# Cache\n",
    "\n",
    "- 응답 결과를 저장해서 같은 질문이 들어오면 LLM에 요청하지 않고 저장된 결과를 보여주도록 한다.\n",
    "    - 처리속도와 비용을 절감할 수 있다.\n",
    "    - 특히 chatbot같이 비슷한 질문을 하는 경우 유용하다.\n",
    "- 저장 방식은 `메모리`, `sqlite` 등 다양한 방식을 지원한다.\n",
    "  \n",
    "    ```python\n",
    "    set_llm_cache(Cache객체)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c002f-7f0c-4357-b3ae-efe8569f04cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a46a8-703c-452b-9d57-e80749c3f528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520effd5-677c-46e3-9068-553e973bfea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
