{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abaeb157",
   "metadata": {},
   "source": [
    "## ğŸ” GRU(Gated Recurrent Unit) êµ¬ì¡°ì™€ ë™ì‘ ì›ë¦¬\n",
    "\n",
    "### âœ… LSTMì˜ ì¥ì ì„ ê°€ì ¸ì˜¨ GRU\n",
    "\n",
    "GRU(Gated Recurrent Unit)ëŠ” **LSTMì˜ ì¥ì ì„ ìœ ì§€í•˜ë©´ì„œ ë” ë‹¨ìˆœí•œ êµ¬ì¡°**ë¡œ ë§Œë“  ìˆœí™˜ ì‹ ê²½ë§(RNN) <br>\n",
    "LSTMì˜ í•µì‹¬ ê¸°ëŠ¥ì¸ **ì¥ê¸° ê¸°ì–µ ìœ ì§€**ëŠ” ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¤ë˜, ë‚´ë¶€ êµ¬ì¡°ë¥¼ ë” ê°„ì†Œí™”í•´ì„œ **ì—°ì‚°ëŸ‰ì„ ì¤„ì´ê³  í•™ìŠµ ì†ë„ë¥¼ ê°œì„ **\n",
    "\n",
    "\n",
    "### ğŸ” GRUì˜ í•µì‹¬ íŠ¹ì§•\n",
    "\n",
    "- LSTMì—ì„œ ì‚¬ìš©ë˜ë˜ 3ê°œì˜ ê²Œì´íŠ¸ (Forget, Input, Output)ë¥¼  \n",
    "  â†’ 2ê°œì˜ ê²Œì´íŠ¸ (Update, Reset)ë¡œ ì¶•ì†Œ\n",
    "- LSTMì˜ **Cell State** $C_t$ë¥¼ ì œê±°í•˜ê³ ,  \n",
    "  â†’ í•˜ë‚˜ì˜ **Hidden State** $h_t$ê°€ ëª¨ë“  ê¸°ì–µì„ ë‹´ë‹¹\n",
    "- êµ¬ì¡°ëŠ” ë‹¨ìˆœí•˜ì§€ë§Œ, ì„±ëŠ¥ì€ LSTMì— ê·¼ì ‘í•˜ê±°ë‚˜ ìœ ì‚¬\n",
    "\n",
    "\n",
    "### ğŸ“¦ GRUì˜ êµ¬ì¡° ê°œìš”\n",
    "\n",
    "- GRUëŠ” ì€ë‹‰ ìƒíƒœ $h_{t-1}$ì—ì„œ ë‹¤ìŒ ìƒíƒœ $h_t$ë¡œ ì—°ê²°ë  ë•Œ  \n",
    "  **ë‘ ê°ˆë˜ë¡œ ë¶„ê¸°ë˜ì—ˆë‹¤ê°€ ë‹¤ì‹œ í•©ì³ì§€ëŠ” êµ¬ì¡°(ì¥ê¸°ê¸°ì–µê³¼ ë‹¨ê¸°ê¸°ì–µ)** ë¥¼ ê°€ì§! (LSTMì´ë‘ ë¹„ìŠ·)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984124d4",
   "metadata": {},
   "source": [
    "![gru_cell](figures/rnn/23_gru_cell.png)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de16c15",
   "metadata": {},
   "source": [
    "###  ğŸ§  GRU (Gated Recurrent Unit) ê³„ì‚° íë¦„\n",
    "##### âœ… Step 0. ì…ë ¥ ì •ë³´\n",
    "- $x_t$: í˜„ì¬ ì‹œì ì˜ ì…ë ¥ ë²¡í„° (ì˜ˆ: ë‹¨ì–´ ì„ë² ë”©)\n",
    "- $h_{t-1}$: ì´ì „ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœ (ê³¼ê±° ì •ë³´ì˜ ìš”ì•½)\n",
    "#### ğŸ§© Step 1. Reset Gate ê³„ì‚°\n",
    "**â†’ ê³¼ê±° ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ 'ì´ˆê¸°í™”'í• ì§€ ê²°ì •**\n",
    "\n",
    "$r_t = \\sigma(W_r x_t + U_r h_{t-1})$\n",
    "- $\\sigma$: sigmoid í•¨ìˆ˜ (ì¶œë ¥ê°’ 0~1)\n",
    "- $W_r$: ì…ë ¥ $x_t$ì— ëŒ€í•œ ê°€ì¤‘ì¹˜\n",
    "- $U_r$: ì´ì „ ìƒíƒœ $h_{t-1}$ì— ëŒ€í•œ ê°€ì¤‘ì¹˜\n",
    "- ğŸ‘‰ $r_t$ê°€ ì‘ì„ìˆ˜ë¡ ê³¼ê±° ì •ë³´ë¥¼ ë¬´ì‹œí•˜ê³  ìƒˆ ì •ë³´ë¥¼ ë” ë°˜ì˜\n",
    "\n",
    "ğŸ§  **ì˜ë„**: ë¬¸ë§¥ì´ ë°”ë€” ë•Œ ì´ì „ ê¸°ì–µì„ ì§€ì›Œì•¼ í•  ê²½ìš° ì‚¬ìš©ë¨\n",
    "\n",
    "#### ğŸ§© Step 2. Update Gate ê³„ì‚°\n",
    "**â†’ í˜„ì¬ ìƒíƒœì— ê³¼ê±°ë¥¼ ì–¼ë§ˆë‚˜ ìœ ì§€í• ì§€ ê²°ì •**\n",
    "\n",
    "$z_t = \\sigma(W_z x_t + U_z h_{t-1})$\n",
    "- $z_t \\approx 1$: ì´ì „ ìƒíƒœ $h_{t-1}$ë¥¼ ê±°ì˜ ê·¸ëŒ€ë¡œ ìœ ì§€  \n",
    "- $z_t \\approx 0$: ìƒˆë¡œ ê³„ì‚°ëœ ì •ë³´ë¥¼ ë” ë°˜ì˜\n",
    "\n",
    "ğŸ§  **ì˜ë„**: ì¥ê¸° ê¸°ì–µì´ í•„ìš”í•œ ê²½ìš°, ê³¼ê±° ìƒíƒœë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "\n",
    "#### ğŸ§ª Step 3. Candidate Hidden State ê³„ì‚°\n",
    "**â†’ í˜„ì¬ ì…ë ¥ê³¼ ì„ íƒëœ ê³¼ê±° ì •ë³´ë¡œ ìƒˆë¡œìš´ ìƒíƒœ í›„ë³´ ìƒì„±**\n",
    "\n",
    "$\\tilde{h}_t = \\tanh(W x_t + U (r_t \\cdot h_{t-1}))$\n",
    "- $r_t \\cdot h_{t-1}$: reset gateë¡œ ì¡°ì ˆëœ ê³¼ê±° ì •ë³´\n",
    "- $\\tanh$: ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜ (ì¶œë ¥ ë²”ìœ„ -1 ~ 1)\n",
    "\n",
    "ğŸ§  **ì˜ë„**: í˜„ì¬ ì…ë ¥ê³¼ ì¼ë¶€ ê³¼ê±° ì •ë³´ë¥¼ ì´ìš©í•´ ìƒˆ ì •ë³´ë¥¼ ìƒì„±\n",
    "\n",
    "#### âš™ï¸ Step 4. ìµœì¢… Hidden State ê³„ì‚°\n",
    "**â†’ ìƒˆ ì •ë³´ì™€ ê³¼ê±° ì •ë³´ë¥¼ ë¹„ìœ¨ì— ë”°ë¼ í˜¼í•©**\n",
    "\n",
    "$h_t = z_t \\cdot h_{t-1} + (1 - z_t) \\cdot \\tilde{h}_t$\n",
    "- $z_t$: ì´ì „ ìƒíƒœë¥¼ ìœ ì§€í•  ì •ë„\n",
    "- $1 - z_t$: ìƒˆë¡œìš´ ìƒíƒœ í›„ë³´ë¥¼ ë°˜ì˜í•  ì •ë„\n",
    "\n",
    "ğŸ§  **ì˜ë„**: í•„ìš”ì— ë”°ë¼ 'ê¸°ì–µ ìœ ì§€' ë˜ëŠ” 'ê¸°ì–µ ê°±ì‹ 'ì„ ìë™ìœ¼ë¡œ ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c795ee38",
   "metadata": {},
   "source": [
    " ### ğŸ“˜Pytorch GRU\n",
    "- `nn.GRU` í´ë˜ìŠ¤ ì´ìš©\n",
    "    - https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "- **ì…ë ¥**\n",
    "    - **input**: (seq_length, batch, hidden_size) shapeì˜ tensor. (batch_first=False), batch_first=Trueì´ë©´ `seq_length`ì™€ `batch` ìœ„ì¹˜ê°€ ë°”ë€ë‹¤.\n",
    "    - **hidden**: (D * num_layers, batch, hidden_size) shapeì˜ Tensor. D(ì–‘ë°©í–¥:2, ë‹¨ë°©í–¥:1), hiddenì€ ìƒëµí•˜ë©´ 0ì´ ì…ë ¥ë¨.\n",
    "- **ì¶œë ¥** - outputê³¼ hidden stateê°€ ë°˜í™˜ëœë‹¤.\n",
    "    - **output**\n",
    "        - ëª¨ë“  sequenceì˜ ì²˜ë¦¬ê²°ê³¼ë“¤ì„ ëª¨ì•„ì„œ ì œê³µ.\n",
    "        - shape: (seq_length, batch, D * hidden_size) : D(ì–‘ë°©í–¥:2, ë‹¨ë°©í–¥:1), batch_first=Trueì´ë©´ `seq_length`ì™€ `batch` ìœ„ì¹˜ê°€ ë°”ë€ë‹¤.\n",
    "    - **hidden**\n",
    "        - ë§ˆì§€ë§‰ time step ì²˜ë¦¬ê²°ê³¼\n",
    "        - shape: (D * num_layers, batch, hidden) : D(ì–‘ë°©í–¥:2, ë‹¨ë°©í–¥:1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402a5c6",
   "metadata": {},
   "source": [
    "ğŸ“ ë‹¤ìŒ ì½”ë“œì˜ ë¹ˆì¹¸ì„ ì±„ìš°ê³  ì£¼ì„ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b15627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRU ì…ì¶œë ¥  í™•ì¸\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# dummy data -> (seq len-20, batch-2, ê°œë³„ timestepì˜ ì…ë ¥ featureìˆ˜-10ìœ¼ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”!)\n",
    "input_data = torch.randn((20,2,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce34fc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 256])\n",
      "torch.Size([1, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# ë‹¨ë°©í–¥, layer ìˆ˜ : 1\n",
    "gru1 = nn.GRU(  # GRU ê³„ì¸µì„ ì…ë ¥í•˜ì„¸ìš”!\n",
    "    input_size=10,   # ê°œë³„ timestepì˜ feature ìˆ˜(embedding.dim)\n",
    "    hidden_size=256, # ê° timestepë³„ë¡œ 256ê°œì˜ íŠ¹ì„±ì„ ì¶”ì¶œ(unit)\n",
    "    num_layers=1, # ëª‡ì¸µ(layer)ë¥¼ ìŒ“ì„ ì§€. (default: 1)\n",
    "    bidirectional=False # ì–‘ë°©í–¥ ì—¬ë¶€ (default: False)\n",
    ")\n",
    "out1, hidden1 = gru1(input_data)\n",
    "#ëª¨ë“  timestepì˜ hidden stateê°’ì„ ë¬¶ì–´ì„œ ë°˜í™˜.[20:seq len, 2:batch, 256:hidden_size] \n",
    "# 256ê°œì˜ ê°’ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆëŠ” 20ê°œì˜ seq ê°’.\n",
    "print(out1.shape) \n",
    "# ë§ˆì§€ë§‰ timestep ì²˜ë¦¬ hidden stateê°’ [1: seq len, 2, 256]\n",
    "print(hidden1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c71ff5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 512])\n",
      "torch.Size([2, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# ì–‘ë°©í–¥, layer ìˆ˜: 1\n",
    "gru2 = nn.GRU(  # GRU ê³„ì¸µì„ ì…ë ¥í•˜ì„¸ìš”!\n",
    "    input_size=10,\n",
    "    hidden_size=256, \n",
    "    num_layers=1, # ëª‡ì¸µ(layer)ë¥¼ ìŒ“ì„ ì§€. (default: 1)\n",
    "    bidirectional=True# ì–‘ë°©í–¥ ì—¬ë¶€ (default: False)\n",
    ")\n",
    "out2, hidden2 = gru2(input_data)\n",
    "\n",
    "# [20: seq_len, 2: batch, 512:hidden_size * 2]  ì–‘ë°©í–¥(ì •/ì—­ë°©í–¥) hidden stateë¥¼ í•©ì³ì„œ(concat) ë°˜í™˜.\n",
    "print(out2.shape)\n",
    "# [2:ì •/ì—­ë°©í–¥ ë‘ê°œ, 2:batch, 256:hidden size]\n",
    "print(hidden2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f440ce",
   "metadata": {},
   "source": [
    "# Seq2Seq ë¥¼ ì´ìš©í•œ Chatbot ëª¨ë¸ êµ¬í˜„\n",
    "- Encoderë¥¼ ì´ìš©í•´ ì§ˆë¬¸ì˜ íŠ¹ì„±ì„ ì¶”ì¶œí•˜ê³  Decoderë¥¼ ì´ìš©í•´ ë‹µë³€ì„ ìƒì„±í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fd6b28",
   "metadata": {},
   "source": [
    "### ğŸ“˜ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ce25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests ëª¨ë“ˆë¡œ ë°›ê¸°\n",
    "import requests\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a7fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv\"\n",
    "res = requests.get(url)\n",
    "if res.status_code == 200:\n",
    "    with open(\"data/chatbot_data.csv\", \"wt\", encoding=\"utf-8\") as fw:\n",
    "        fw.write(res.text)\n",
    "else:\n",
    "    print(f\"ë¶ˆëŸ¬ì˜¤ì§€ ëª»í•¨: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ed997b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/chatbot_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6450d0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ë²¨ ì œê±°\n",
    "df.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22770231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12ì‹œ ë•¡!</td>\n",
       "      <td>í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´</td>\n",
       "      <td>ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL ì‹¬í•˜ë„¤</td>\n",
       "      <td>ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A\n",
       "0           12ì‹œ ë•¡!   í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.\n",
       "1      1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´    ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.\n",
       "2     3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .\n",
       "3  3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .\n",
       "4          PPL ì‹¬í•˜ë„¤   ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4877defd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.</td>\n",
       "      <td>í‹°ê°€ ë‚˜ë‹ˆê¹Œ ëˆˆì¹˜ê°€ ë³´ì´ëŠ” ê±°ì£ !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.</td>\n",
       "      <td>í›”ì³ë³´ëŠ” ê±° í‹°ë‚˜ë‚˜ë´ìš”.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>í‘ê¸°ì‚¬ í•´ì£¼ëŠ” ì§ë‚¨.</td>\n",
       "      <td>ì„¤ë œê² ì–´ìš”.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>í˜ë“  ì—°ì•  ì¢‹ì€ ì—°ì• ë¼ëŠ”ê²Œ ë¬´ìŠ¨ ì°¨ì´ì¼ê¹Œ?</td>\n",
       "      <td>ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆëŠ” ì‚¬ì´ ì—¬ë¶€ì¸ ê±° ê°™ì•„ìš”.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>í˜ë“¤ì–´ì„œ ê²°í˜¼í• ê¹Œë´</td>\n",
       "      <td>ë„í”¼ì„± ê²°í˜¼ì€ í•˜ì§€ ì•Šê¸¸ ë°”ë¼ìš”.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A\n",
       "11818           í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.        í‹°ê°€ ë‚˜ë‹ˆê¹Œ ëˆˆì¹˜ê°€ ë³´ì´ëŠ” ê±°ì£ !\n",
       "11819           í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.             í›”ì³ë³´ëŠ” ê±° í‹°ë‚˜ë‚˜ë´ìš”.\n",
       "11820              í‘ê¸°ì‚¬ í•´ì£¼ëŠ” ì§ë‚¨.                    ì„¤ë œê² ì–´ìš”.\n",
       "11821  í˜ë“  ì—°ì•  ì¢‹ì€ ì—°ì• ë¼ëŠ”ê²Œ ë¬´ìŠ¨ ì°¨ì´ì¼ê¹Œ?  ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆëŠ” ì‚¬ì´ ì—¬ë¶€ì¸ ê±° ê°™ì•„ìš”.\n",
       "11822               í˜ë“¤ì–´ì„œ ê²°í˜¼í• ê¹Œë´        ë„í”¼ì„± ê²°í˜¼ì€ í•˜ì§€ ì•Šê¸¸ ë°”ë¼ìš”."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b04d470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q    0\n",
       "A    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.isna().sum()  # ê²°ì¸¡ì¹˜ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1dacac",
   "metadata": {},
   "source": [
    "### ğŸ“˜Dataset, DataLoader ì •ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e64f82",
   "metadata": {},
   "source": [
    "### ğŸ“˜ Tokenization\n",
    "\n",
    "### Subwordë°©ì‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873e859",
   "metadata": {},
   "source": [
    "ğŸ“ ë‹¤ìŒ ì½”ë“œì˜ ë¹ˆì¹¸ì„ ì±„ìš°ê³  ì£¼ì„ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seqì—ì„œëŠ” ì •ê·œí™” ê°™ì€ ì „ì²˜ë¦¬ê°€ í•„ìš”í•˜ì§€ ì•Šë‹¤. ë¶€ì •ê³¼ ê¸ì •ì„ íŒë‹¨í•˜ëŠ” RSTM ê°™ì€ ê²ƒë“¤ì€ ì „ì²˜ë¦¬ë‚˜ í´ëœì§•ì„ í•„ìš”ë¡œ í•¨. \n",
    "# token í•™ìŠµ -> vocab ì‚¬ì „ ìƒì„±.\n",
    "## ì§ˆë¬¸ë“¤ + ë‹µë³€ë“¤ í•©ì³ì„œ í•™ìŠµ.\n",
    "question_texts = df['Q']\n",
    "answer_texts = df['A']\n",
    "all_texts = list(question_texts + \" \"+answer_texts) # ê°™ì€ indexë¼ë¦¬ í•©ì¹˜ê¸° => listë¡œ ë³€í™˜\n",
    "len(question_texts), len(answer_texts), len(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe85a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6796dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27524257",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a60367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2325f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10_000   # ì´ ì–´íœ˜ ìˆ˜\n",
    "min_frequency = 5   # ì–´íœ˜ì‚¬ì „ì— ë“±ë¡ë  ë‹¨ì–´(í† í°)ì˜ ìµœì†Œ ë¹ˆë„ìˆ˜.\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))  # unk ì²˜ë¦¬\n",
    "tokenizer.pre_tokenizer = Whitespace()  # ìŒì ˆ ë‹¨ìœ„ë¡œ ìª¼ê°¬.\n",
    "trainer = BpeTrainer(      \n",
    "    vocab_size=vocab_size,\n",
    "    min_frequency=min_frequency,\n",
    "    continuing_subword_prefix='##', # ì—°ê²° subword ì•ì— ë¶™ì¼ ì ‘ë‘ì–´ì§€ì •. \n",
    "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[SOS]\"] # [SOS]: ë¬¸ì¥ì˜ ì‹œì‘ì„ ì˜ë¯¸í•˜ëŠ” í† í°.\n",
    ")\n",
    "# tokenizer: token + ##izer\n",
    "## í•™ìŠµ\n",
    "tokenizer.train_from_iterator(all_texts, trainer=trainer) # ë¦¬ìŠ¤íŠ¸ë¡œ ë¶€í„° í•™ìŠµ\n",
    "## tokenizer.train(\"íŒŒì¼ê²½ë¡œ\") # íŒŒì¼ì— ìˆëŠ” textë¥¼ í•™ìŠµ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2452d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ì´ ì–´íœ˜ìˆ˜:\", tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc43c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í† í°í™”\n",
    "encode = tokenizer.encode(\"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ë„ˆë¬´ ì¢‹ìŠµë‹ˆë‹¤. ì¦ê±°ìš´ í•˜ë£¨ ë˜ì„¸ìš”. ì¿„ì¿„ì¿œã…‹\")    # idì™€ í† í°ì„ ìƒì„±í•´ì¤Œ. \n",
    "print(encode.ids)   # í† í° id\n",
    "print(encode.tokens)  # í† í° (ë‹¨ì–´)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b83b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.id_to_token(1296), tokenizer.token_to_id('##ì‚¿')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e76d751",
   "metadata": {},
   "source": [
    "### ğŸ“˜ Tokenizer ì €ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da495989",
   "metadata": {},
   "source": [
    "### ğŸ“˜ Dataset, DataLoader ì •ì˜\n",
    "\n",
    "\n",
    "### Dataset ì •ì˜ ë° ìƒì„±\n",
    "- ëª¨ë“  ë¬¸ì¥ì˜ í† í° ìˆ˜ëŠ” ë™ì¼í•˜ê²Œ ë§ì¶°ì¤€ë‹¤.\n",
    "    - DataLoaderëŠ” batch ë¥¼ êµ¬ì„±í•  ë•Œ batchì— í¬í•¨ë˜ëŠ” ë°ì´í„°ë“¤ì˜ shapeì´ ê°™ì•„ì•¼ í•œë‹¤. ê·¸ë˜ì•¼ í•˜ë‚˜ì˜ batchë¡œ ë¬¶ì„ ìˆ˜ ìˆë‹¤.\n",
    "    - ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì •í•´ì£¼ê³  **ìµœëŒ€ ê¸¸ì´ë³´ë‹¤ ì§§ì€ ë¬¸ì¥ì€ `<PAD>` í† í°ì„ ì¶”ê°€**í•˜ê³  **ìµœëŒ€ê¸¸ì´ë³´ë‹¤ ê¸´ ë¬¸ì¥ì€ ìµœëŒ€ ê¸¸ì´ì— ë§ì¶° ì§¤ë¼ì¤€ë‹¤.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c5752",
   "metadata": {},
   "source": [
    "ğŸ“ ë‹¤ìŒ ì½”ë“œì˜ ë¹ˆì¹¸ì„ ì±„ìš°ê³  ì£¼ì„ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9660a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "from torch import optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae7558",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ChatbotDataset\n",
    "    parameter:\n",
    "        question_texts: list[str] - ì§ˆë¬¸ texts ëª©ë¡. ë¦¬ìŠ¤íŠ¸ì— ì§ˆë¬¸ë“¤ì„ ë‹´ì•„ì„œ ë°›ëŠ”ë‹¤. [\"ì§ˆë¬¸1\", \"ì§ˆë¬¸2\", ...]\n",
    "        answer_texts: list[str] - ë‹µ texts ëª©ë¡. ë¦¬ìŠ¤íŠ¸ì— ë‹µë³€ë“¤ì„ ë‹´ì•„ì„œ ë°›ëŠ”ë‹¤.     [\"ë‹µ1\", \"ë‹µ2\", ...]\n",
    "        max_length: ê°œë³„ ë¬¸ì¥ì˜ token ê°œìˆ˜. ëª¨ë“  ë¬¸ì¥ì˜ í† í°ìˆ˜ë¥¼ max_lengthì— ë§ì¶˜ë‹¤.\n",
    "        tokenizer: Tokenizer\n",
    "        vocab_size: int ì´ë‹¨ì–´ìˆ˜\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, question_texts, answer_texts, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        parameter\n",
    "            question_texts: list[str] - ì§ˆë¬¸ texts ëª©ë¡. ë¦¬ìŠ¤íŠ¸ì— ì§ˆë¬¸ë“¤ì„ ë‹´ì•„ì„œ ë°›ëŠ”ë‹¤. [\"ì§ˆë¬¸1\", \"ì§ˆë¬¸2\", ...]\n",
    "            answer_texts: list[str] - ë‹µ texts ëª©ë¡. ë¦¬ìŠ¤íŠ¸ì— ë‹µë³€ë“¤ì„ ë‹´ì•„ì„œ ë°›ëŠ”ë‹¤.     [\"ë‹µ1\", \"ë‹µ2\", ...]\n",
    "            max_length: ê°œë³„ ë¬¸ì¥ì˜ token ê°œìˆ˜. ëª¨ë“  ë¬¸ì¥ì˜ í† í°ìˆ˜ë¥¼ max_lengthì— ë§ì¶˜ë‹¤.\n",
    "            tokenizer: Tokenizer\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n",
    "        self.answer_texts = [self.__process_sequence(a) for a in answer_texts]  # ë°›ì•„ì˜¨ q/a ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ë¥¼ max_lengthì˜ token listë¡œ ë³€í™˜í•´ì„œ attributeë¡œ ì €ì¥.\n",
    "    \n",
    "    def __pad_token_sequence(self, token_sequence): \n",
    "        \"\"\"\n",
    "        max_length ê¸¸ì´ì— ë§ì¶° token_id ë¦¬ìŠ¤íŠ¸ë¥¼ êµ¬ì„±í•œë‹¤.\n",
    "        max_length ë³´ë‹¤ ê¸¸ë©´ ë’¤ì—ë¥¼ ìë¥´ê³  max_length ë³´ë‹¤ ì§§ìœ¼ë©´ [PAD] í† í°ì„ ì¶”ê°€í•œë‹¤.\n",
    "        \n",
    "        Parameter\n",
    "            token_sentence: list[int] - ê¸¸ì´ë¥¼ ë§ì¶œ í•œ ë¬¸ì¥ token_id ëª©ë¡\n",
    "        Return\n",
    "            list[int] - lengthê°€ max_lengthì¸ token_id ëª©ë¡\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('[PAD]')   # [PAD] í† í° idë¥¼ ì¡°íšŒ (0)\n",
    "        seq_len = len(token_sequence) # ì…ë ¥ ë¬¸ì¥ì˜ í† í°ìˆ˜\n",
    "        if seq_len > self.max_length: # ë¬¸ì¥ ìµœëŒ€ í† í°ìˆ˜ ë³´ë‹¤ ê¸¸ë‹¤ë©´.\n",
    "            return token_sequence[:self.max_length]\n",
    "        else:\n",
    "            return token_sequence + ([pad_token] * (self.max_length - seq_len))\n",
    "    \n",
    "    def __process_sequence(self, text): \n",
    "        \"\"\"\n",
    "        í•œ ë¬¸ì¥(str)ì„ ë°›ì•„ì„œ paddingì´ ì¶”ê°€ëœ token_id ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ í›„ ë°˜í™˜\n",
    "        Parameter\n",
    "            text: str - token_id ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•  í•œ ë¬¸ì¥\n",
    "        Return\n",
    "            list[int] - ì…ë ¥ë°›ì€ ë¬¸ì¥ì— ëŒ€í•œ token_id ë¦¬ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        # encoding\n",
    "        encode = self.tokenizer.encode(text) # \"........\" => [. , . , .]\n",
    "        # max_length í¬ê¸°ì— ë§ì¶˜ë‹¤.\n",
    "        token_ids = self.__pad_token_sequence(encode.ids) #[3400, 20, 6, 0, 0, 0 ..]\n",
    "        return token_ids\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.question_texts)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # return  indexì˜ (ì§ˆë¬¸í† í°ë“¤,  ë‹µë³€í† í°ë“¤)\n",
    "        q = self.question_texts[index]  # List\n",
    "        a = self.answer_texts[index]\n",
    "        # List->LongTensor. nn.Embedding()ì˜ ì…ë ¥(ì •ìˆ˜íƒ€ì…)ìœ¼ë¡œ ë“¤ì–´ê°„ë‹¤. \n",
    "        return torch.tensor(q, dtype=torch.int64), torch.tensor(a, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61dc8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì ë‹¹í•œ max_length ê°’: ì „ì²´ ë¬¸ì¥ ì´ í† í°ìˆ˜ì˜ 9ë¶„ìœ„ìˆ˜\n",
    "import numpy as np\n",
    "a = [len(tokenizer.encode(s).ids) for s in all_texts]\n",
    "# a[:5]\n",
    "np.quantile(a, q=[0.9, 0.95, 0.97, 1.0])\n",
    "# max_length=20\n",
    "a  # ê° ë¬¸ì¥ì— ëŒ€í•œ í† í° ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9913d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(a, 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Dataset ì…ìƒ\n",
    "MAX_LENGTH = 20\n",
    "dataset = ChatbotDataset(question_texts, answer_texts, MAX_LENGTH, tokenizer)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]  \n",
    "# (tensor([  10, 1815, 1348,  368,    3,    0,    0,    0,    0,    0,    0,    0,\n",
    "#            0,    0,    0,    0,    0,    0,    0,    0]),  -> ì§ˆë¬¸ \n",
    "# tensor([6118,  378,   47, 2252,    8,    0,    0,    0,    0,    0,    0,    0,\n",
    "#            0,    0,    0,    0,    0,    0,    0,    0])) -> ë‹µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2062d7",
   "metadata": {},
   "source": [
    "### ğŸ“˜ Trainset / Testset ë‚˜ëˆ„ê¸°\n",
    "train : test = .95 : .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(dataset) * 0.95)\n",
    "len(dataset) - int(len(dataset)*0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset)*0.95)   # trainsetì˜ ê°œìˆ˜\n",
    "test_size = len(dataset) - train_size  # testsetì˜ ê°œìˆ˜\n",
    "print(train_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f69526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_split()ì´ìš©í•´ì„œ ë¶„ë¦¬\n",
    "###shuffle(ì„ëŠ”ë‹¤) í›„ ê°œìˆ˜ì— ë§ê²Œ ë‚˜ëˆ”  -> ìˆœì„œëŒ€ë¡œ ë‚˜ëˆ„ì§€ ì•ŠìŒ.\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size]) \n",
    "# random_split(Datasetê°ì²´, [ë‚˜ëˆŒ ê°œìˆ˜, ...])\n",
    "# ex. random_split(dataset, [10,20,30,40,50]) # 5ê°œë¡œ ë‚˜ëˆ”. ê°ê° ì§€ì •í•œ ê°œìˆ˜ë³„ë¡œ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc004437",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset), type(train_set)  # subset (ë¶€ë¶„ ì§‘í•©)ì˜ í˜•íƒœë¡œ ë‚˜ì˜´. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5592260",
   "metadata": {},
   "source": [
    "### ğŸ“˜ DataLoader ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)  #drop_last= True ë‚¨ì€ê±°ëŠ” ì“°ì§€ ì•Šê² ë‹¤.\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a85bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader), len(test_loader) # step ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db7917",
   "metadata": {},
   "source": [
    "### ğŸ“˜ ëª¨ë¸ ì •ì˜\n",
    "\n",
    "## Seq2Seq ëª¨ë¸ ì •ì˜\n",
    "- Seq2Seq ëª¨ë¸ì€ Encoderì™€ Decoderì˜ ì…ë ¥ Sequenceì˜ **ê¸¸ì´**ì™€ **ìˆœì„œ**ê°€ ììœ ë¡­ê¸° ë•Œë¬¸ì— ì±—ë´‡ì´ë‚˜ ë²ˆì—­ì— ì´ìƒì ì¸ êµ¬ì¡°ë‹¤.\n",
    "    - ë‹¨ì¼ RNNì€ ê° timestep ë§ˆë‹¤ ì…ë ¥ê³¼ ì¶œë ¥ì´ ìˆê¸° ë•Œë¬¸ì— ì…/ì¶œë ¥ sequenceì˜ ê°œìˆ˜ê°€ ê°™ì•„ì•¼ í•œë‹¤.(ex. many to many)\n",
    "    - ì±—ë´‡ì˜ ì§ˆë¬¸/ë‹µë³€ì´ë‚˜ ë²ˆì—­ì˜ ëŒ€ìƒ/ê²°ê³¼ ë¬¸ì¥ì˜ ê²½ìš°ëŠ” ì‚¬ìš©í•˜ëŠ” ì–´ì ˆ ìˆ˜ê°€ ë‹¤ë¥¸ ê²½ìš°ê°€ ë§ê¸° ë•Œë¬¸ì— ë‹¨ì¼ RNN ëª¨ë¸ì€ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ê¸° ì–´ë µë‹¤.\n",
    "    - Seq2SeqëŠ” **ì…ë ¥ì²˜ë¦¬(ì§ˆë¬¸,ë²ˆì—­ëŒ€ìƒ)ì²˜ë¦¬ RNNê³¼ ì¶œë ¥ ì²˜ë¦¬(ë‹µë³€, ë²ˆì—­ê²°ê³¼) RNN ì´ ê°ê° ë§Œë“¤ê³  ê·¸ ë‘˜ì„ ì—°ê²°í•œ í˜•íƒœë¡œ ê¸¸ì´ê°€ ë‹¤ë¥´ë”ë¼ë„ ìƒê´€ì—†ë‹¤.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698a9386",
   "metadata": {},
   "source": [
    "## ğŸ“˜ Encoder\n",
    "EncoderëŠ” í•˜ë‚˜ì˜ Vectorë¥¼ ìƒì„±í•˜ë©° ê·¸ VectorëŠ” **ì…ë ¥ ë¬¸ì¥ì˜ ì˜ë¯¸**ë¥¼ N ì°¨ì› ê³µê°„ ì €ì¥í•˜ê³  ìˆë‹¤. ì´ Vectorë¥¼ **Context Vector** ë¼ê³  í•œë‹¤.<br> \n",
    "LSTMê³¼ ë™ì¼(Many to one) -> LSTMì—ì„œ íŠ¹ì§• ì¶”ì¶œí•´ë‚´ëŠ” ê±°ë‘ ë˜‘ê°™ì´ ì—¬ê¸°ì„œë„ ì…ë ¥ ë¬¸ì¥ì˜ contextì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•´ë‚´ëŠ” ê²ƒ\n",
    "![encoder](figures/seq2seq_encoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018c662",
   "metadata": {},
   "source": [
    "ğŸ“ ë‹¤ìŒ ì½”ë“œì˜ ë¹ˆì¹¸ì„ ì±„ìš°ê³  ì£¼ì„ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb5efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, \n",
    "                hidden_size, bidirectional=True, num_layers=1, dropout_rate=0.0):  #bidirectional : ì–‘ë°©í–¥ì„±.  ë¬¸ì¥ tokenì— ëŒ€í•´ì„œ ì™¼ìª½ì—ì„œ ë½‘ì•„ë‚¸ê±°ë‘ ì˜¤ë¥¸ë¥¸ìª½ì—ì„œ ì‹œì‘í•´ì„œ ë½‘ì•„ë‚¸ê±° ë‘˜ë‹¤ ê³ ë ¤.\n",
    "        super().__init__()\n",
    "        # EncoderëŠ” context vector(ë¬¸ì¥ì˜ feature)ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ëª©ì  (ë¶„ë¥˜ê¸°ëŠ” ìƒì„±ì•ˆí•¨.) ì—¬ê¸°ì„œëŠ” ê·¸ëƒ¥ íŠ¹ì§•ì„ decoderì— ì£¼ëŠ” ì—­í• \n",
    "        # Embedding Layer, GRU Layerë¥¼ ìƒì„±.\n",
    "        self.vocab_size = vocab_size # ì–´íœ˜ì‚¬ì „ì˜ ì´ ì–´íœ˜ìˆ˜(í† í°ìˆ˜)\n",
    "        # ì„ë² ë”©ë ˆì´ì–´\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,\t\t# ì´ ì–´íœ˜ê°œìˆ˜ (weight í–‰ë ¬ì˜ í–‰)\n",
    "            embedding_dim,\t# embedding vector ì°¨ì›ìˆ˜. (Weight í–‰ë ¬ì˜ ì—´ ìˆ˜) weight í–‰ë ¬ì˜ shape: [vocab_size, embedding_dim]\n",
    "            padding_idx=0   # [PAD]  (íŒ¨ë”© í† í°ì˜ ID) - paddingì˜ embedding vectorëŠ” í•™ìŠµì´ ì•ˆë˜ë„ë¡ í•œë‹¤.(vectorê°’ì´ 0ìœ¼ë¡œ êµ¬ì„±)\n",
    "        )\n",
    "        # GRU\n",
    "        self.gru = nn.GRU(\n",
    "            embedding_dim,\t\t\t\t# ê°œë³„ í† í°(time step)ì˜ í¬ê¸°(feature ìˆ˜).\n",
    "            hidden_size=hidden_size,\t# hidden stateì˜ í¬ê¸°- ê°œë³„ í† í° ë³„ë¡œ ëª‡ê°œì˜ featureë¥¼ ì¶”ì¶œí• ì§€. \n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout_rate if num_layers > 1 else 0.0  # stacked rnnì¼ ê²½ìš°(layerê°€ ì—¬ëŸ¬ê°œì¼ ê²½ìš°), dropout ì ìš©.  \n",
    "        )\n",
    "    \n",
    "    def forward(self, X):   # ê³„ì‚°\n",
    "        # X shape: (batch, seq_len) í† í°ê°’ í•˜ë‚˜ì”©\n",
    "        X = self.embedding(X) # (batch, seq_len, embedding_dim)\n",
    "        X = X.transpose(1, 0) # (seq_len, batch, embedding_dim)\n",
    "        out, hidden = self.gru(X)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2bb4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding_idx ì˜ˆì‹œ\n",
    "e_l = nn.Embedding(10,5, padding_idx=1)\n",
    "e_l.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c89aadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "encoder_model = Encoder(1000, 200, 256)   # vocab_size : 1000, embì°¨ì›: 200, hidden size: 256\n",
    "dummy_data = torch.zeros((64, 20), dtype=torch.int64)  #(batch:64, seq_len:20)\n",
    "summary(encoder_model, input_data=dummy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd2d3e",
   "metadata": {},
   "source": [
    "## ğŸ“˜Decoder\n",
    "- Encoderì˜ ì¶œë ¥(context vector)ë¥¼ ë°›ì•„ì„œ ë²ˆì—­ ê²°ê³¼ sequenceë¥¼ ì¶œë ¥í•œë‹¤.\n",
    "- DecoderëŠ” ë§¤ time stepì˜ ì…ë ¥ìœ¼ë¡œ **ì´ì „ time stepì—ì„œ ì˜ˆìƒí•œ ë‹¨ì–´ì™€ hidden stateê°’ì´** ì…ë ¥ëœë‹¤.\n",
    "- Decoderì˜ ì²˜ë¦¬ê²°ê³¼ hidden stateë¥¼ Estimator(Linear+Softmax)ë¡œ ì…ë ¥í•˜ì—¬ **ì…ë ¥ ë‹¨ì–´ì— ëŒ€í•œ ë²ˆì—­ ë‹¨ì–´ê°€ ì¶œë ¥ëœë‹¤.** (ì´ ì¶œë ¥ë‹¨ì–´ê°€ ë‹¤ìŒ stepì˜ ì…ë ¥ì´ ëœë‹¤.)\n",
    "    - Decoderì˜ ì²« time step ì…ë ¥ì€ ë¬¸ì¥ì˜ ì‹œì‘ì„ ì˜ë¯¸í•˜ëŠ” <SOS>(start of string) í† í°ì´ê³  hidden stateëŠ” context vector(encoder ë§ˆì§€ë§‰ hidden state) ì´ë‹¤.\n",
    "\n",
    "![decoder](figures/seq2seq_decoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e574585f",
   "metadata": {},
   "source": [
    "ğŸ“ ë‹¤ìŒ ì½”ë“œì˜ ë¹ˆì¹¸ì„ ì±„ìš°ê³  ì£¼ì„ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80810ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    # auto regressive RNN ëª¨ë¸ì€ ë‹¨ë°©í–¥ë§Œ ê°€ëŠ¥\n",
    "    def __init__(self, vocab_size, embedding_dim, \n",
    "                 hidden_size, num_layers=1, bidirectional=False, dropout_rate=0.0):  #ì—¬ê¸°ì„œëŠ” ì—­ë°©í–¥ì„ í•  ìˆ˜ ì—†ìŒ. ì•ì—ì„œ ìƒì„±ì´ ë˜ì–´ì•¼ í•˜ëŠ”ë°, ë’¤ë¡œ í•˜ë©´ ìƒì„± ì•ˆë¨. \n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size # ì´ ì–´íœ˜ì‚¬ì „ í† í° ê°œìˆ˜.\n",
    "        # embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # GRU \n",
    "        ## Auto Regressive RNNì€ ë‹¨ë°©í–¥ë§Œ ê°€ëŠ¥. \n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size, \n",
    "                          num_layers=num_layers, dropout=dropout_rate if num_layers > 1 else 0.0)\n",
    "        # Dropout layer (featureë‘ ë¶„ë¥˜ê¸° ì‚¬ì´ì— dropout layer ë„£ê¸°)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # ë¶„ë¥˜ê¸° (ë‹¤ìŒ ë‹¨ì–´(í† í°)ë¥¼ ì¶”ë¡ )\n",
    "           # - ë‹¤ì¤‘ë¶„ë¥˜(ë‹¨ì–´ì‚¬ì „ì˜ ë‹¨ì–´ë“¤ì˜ ë‹¤ìŒ ë‹¨ì–´ì¼ í™•ë¥¼)\n",
    "        self.lr = nn.Linear(\n",
    "            hidden_size,  # GRU ì¶œë ¥ ê°’ ì¤‘ ë§ˆì§€ë§‰ hidden stateê°’ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ.  # ev -> --- -> hidden state -> linnearì— ë„£ê¸°\n",
    "            vocab_size    # ì¶œë ¥: ë‹¤ìŒ ë‹¨ì–´ì¼ í™•ë¥ .   \n",
    "        )\n",
    "        \n",
    "    def forward(self, X, hidden):\n",
    "        # X: torch.LongTensor: shape - [batch] : í•œ ë‹¨ì–´ì”© ì…ë ¥ì„ ë°›ìŒ.\n",
    "        # hidden: torch.FloatTensor: shape - [1, batch, hidden_size] (ì´ì „ê¹Œì§€ì˜ íŠ¹ì„±)   # sequence_lengthëŠ” 1ì´ ë¨ (ë‹¨ì–´ê°€ í•œê°œ)\n",
    "        \n",
    "        X = X.unsqueeze(1) # seq_len ì¶•ì„ ì¶”ê°€. [batch] -> [batch, 1] (Embedding Layerì˜ input shape)  1: sequance_length\n",
    "        X = self.embedding(X) # [batch, 1, embedding ì°¨ì›]\n",
    "        X = X.transpose(1, 0) # [1, batch, embedding ì°¨ì›]  #seq_lenì´ë‘ batch ì¶• ë°”ê¿ˆ. \n",
    "        \n",
    "        out, hidden = self.gru(X, hidden)\n",
    "        last_out = out[-1] # out: ì „ì²´ hidden stateê°’-> ë§ˆì§€ë§‰ hidden stateì„ ì¶”ì¶œ  # ê·¼ë° ì–´ì°¨í”¼ seq_lenì´ 1ì´ë‹ˆê¹Œ í•œê°œì„.\n",
    "        self.dropout(last_out)   # ê³¼ì í•©ì„ ë§‰ì•„ì£¼ê¸° ìœ„í•´ì„œ dropout ì§„í–‰\n",
    "        last_out = self.lr(last_out)\n",
    "\n",
    "        #last_out : ì–´íœ˜ ì‚¬ì „ì˜ ë‹¨ì–´ë“¤ì— ëŒ€í•´ ë‹¤ìŒ ë‹¨ì–´ì¼ í™•ë¥ . \n",
    "        return last_out, hidden # (hidden: ë‹¤ìŒ timestepì— ì „ë‹¬.)  # hiddenë„ ê°™ì´ ë‹¤ìŒ êº¼ì— ë„£ì–´ì•¼ í•¨,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb315c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### summary\n",
    "\n",
    "decoder_model = Decoder(1000, 200, 256)\n",
    "\n",
    "dummy_input = torch.ones((64, ), dtype=torch.int64)\n",
    "dummy_hidden = torch.ones((1, 64, 256), dtype=torch.float32)\n",
    "\n",
    "summary(decoder_model, input_data=(dummy_input, dummy_hidden))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
