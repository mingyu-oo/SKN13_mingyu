{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702c5b37-cadd-4e88-af53-581268bc2b18",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1748842106648,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "702c5b37-cadd-4e88-af53-581268bc2b18"
   },
   "outputs": [],
   "source": [
    "## GRU 입출력  확인\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# dummy data\n",
    "input_data = torch.randn((20, 2, 10))\n",
    "# (20: seq len, 2: batch, 10: 개별 timestep의 입력 feature수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7d86e6-0a72-4fde-9e57-51417b1ed782",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1748842106831,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "8b7d86e6-0a72-4fde-9e57-51417b1ed782",
    "outputId": "26ffa4e0-8ffe-4bd2-9fad-635da33dc968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 256])\n",
      "torch.Size([1, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# 단방향, layer 수: 1\n",
    "gru1 = nn.GRU(\n",
    "    input_size=10,      # 개별 timestep의 feature수(embedding_dim)\n",
    "    hidden_size=256,    # 각 timestep 별로 256개의 특성을 추출.(unit수)\n",
    "    num_layers=1,       # 몇층(layer)를 쌓을 지. (default: 1)\n",
    "    bidirectional=False # 양방향 여부 (default: False)\n",
    ")\n",
    "out1, hidden1 = gru1(input_data)\n",
    "#모든 timestep의 hidden state값을 묶어서 반환.[20:seq len, 2:batch, 256:hidden_size]\n",
    "print(out1.shape)\n",
    "# 마지막 timestep 처리 hidden state값 [1: seq len, 2, 256]\n",
    "print(hidden1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794b0319-660e-42f0-a390-6ec71ade0b17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1748842106863,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "794b0319-660e-42f0-a390-6ec71ade0b17",
    "outputId": "adeb0ac0-a263-4446-86d1-2e1da5a2a95d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 512])\n",
      "torch.Size([2, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# bidirectional=True (양방향), layer 수 1개\n",
    "gru2 = nn.GRU(\n",
    "    input_size=10,\n",
    "    hidden_size=256,\n",
    "    num_layers=1, # 몇층(layer)를 쌓을 지. (default: 1)\n",
    "    bidirectional=True # 양방향 여부 (default: False)\n",
    ")\n",
    "out2, hidden2 = gru2(input_data)\n",
    "\n",
    "# [20:seq_len, 2: batch, 512:hidden_size * 2]   양방향 hidden state를 합쳐서(concat) 반환.\n",
    "print(out2.shape)\n",
    "# [2:정/역방향 두개, 2: batch, 256:hidden size]\n",
    "print(hidden2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf63dd57-148c-4a77-9ceb-aedde38a86b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1748842106896,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "cf63dd57-148c-4a77-9ceb-aedde38a86b6",
    "outputId": "e8fc7fc2-751c-4081-ef3e-088d32a032a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 256])\n",
      "torch.Size([4, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# 단방향, multi layer(4개 층)\n",
    "gru3 = nn.GRU(\n",
    "    input_size=10,\n",
    "    hidden_size=256,\n",
    "    num_layers=4, # 몇층(layer)를 쌓을 지. (default: 1)\n",
    "    bidirectional=False # 양방향 여부 (default: False)\n",
    ")\n",
    "out3, hidden3 = gru3(input_data)\n",
    "\n",
    "#[20, 2, 256] - 마지막 GRU Layer가 출력한 결과들이 최종 feature이므로 그것을 모아서 반환.\n",
    "# num_layers가 몇개든 out의 shape은 동일.\n",
    "print(out3.shape)\n",
    "# [4: 레이어수, 2, 256]  - 각 layer의 마지막 hidden state들을 모아서 반환\n",
    "print(hidden3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da1abf35-6271-41de-a217-63ff74d33837",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1748842107233,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "da1abf35-6271-41de-a217-63ff74d33837",
    "outputId": "e1133153-a738-4622-eebd-7d50a9b2072c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 512])\n",
      "torch.Size([8, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# multi layer(4개 층), 양방향\n",
    "\n",
    "gru4 = nn.GRU(\n",
    "    input_size=10,\n",
    "    hidden_size=256,\n",
    "    num_layers=4, # 몇층(layer)를 쌓을 지. (default: 1)\n",
    "    bidirectional=True # 양방향 여부 (default: False)\n",
    ")\n",
    "out4, hidden4 = gru4(input_data)\n",
    "print(out4.shape) # [20, 2, 512: 양방향 hidden 합친것]\n",
    "# [8:양방향(2) x 레이어수: 각각, 2, 256]\n",
    "print(hidden4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd0c3c-2b8f-4a4c-b90c-a0fa6d828c4c",
   "metadata": {
    "id": "5bbd0c3c-2b8f-4a4c-b90c-a0fa6d828c4c"
   },
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed2c29e-1aef-48c3-87ba-a89cc8ed6146",
   "metadata": {
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1748842107614,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "5ed2c29e-1aef-48c3-87ba-a89cc8ed6146"
   },
   "outputs": [],
   "source": [
    "# requests 모듈로 받기\n",
    "import requests\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fc98856-b66d-4e2e-bc8a-27e3d34dcfd4",
   "metadata": {
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1748842108130,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "0fc98856-b66d-4e2e-bc8a-27e3d34dcfd4"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv\"\n",
    "res = requests.get(url)\n",
    "if res.status_code == 200:\n",
    "    with open(\"data/chatbot_data.csv\", \"wt\", encoding=\"utf-8\") as fw:\n",
    "        fw.write(res.text)\n",
    "else:\n",
    "    print(f\"불러오지 못함: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e670d063-8c71-4ddf-b6b0-15631c7f58da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1117,
     "status": "ok",
     "timestamp": 1748842109249,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "e670d063-8c71-4ddf-b6b0-15631c7f58da",
    "outputId": "b43bf7e1-4d05-4116-e478-8c3c3466cba5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/chatbot_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "796816ae-1851-4b97-892b-671b5f869cab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1748842109296,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "796816ae-1851-4b97-892b-671b5f869cab",
    "outputId": "2d4f8d9b-a7d4-456d-f969-a822e8e2a97c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e784426-2a6d-4988-b9bc-4bfbd37b26e2",
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1748842109325,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "5e784426-2a6d-4988-b9bc-4bfbd37b26e2"
   },
   "outputs": [],
   "source": [
    "# 라벨 제거\n",
    "df.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaeb3e95-7b21-418e-9936-988b76d38070",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1748842109397,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "eaeb3e95-7b21-418e-9936-988b76d38070",
    "outputId": "872ca449-6981-47cb-9af6-bd31fdffb4a3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11823,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11662,\n        \"samples\": [\n          \"\\uc0ac\\ub791\\ud558\\ub294 \\uc0ac\\ub78c \\uc78a\\ub294 \\ubc95\",\n          \"\\uc220 \\uc548 \\uba39\\uc73c\\uba74 \\uce5c\\uad6c\\ub791 \\ubb50\\ud558\\uc9c0\",\n          \"\\uc9dd\\ub0a8\\uc774 \\uace0\\uc2dc\\uc0dd\\uc774\\uba74 \\uae30\\ub2e4\\ub824\\uc57c \\ud558\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7779,\n        \"samples\": [\n          \"\\uc720\\uba38\\ucf54\\ub4dc\\uac00 \\ub9de\\ub294 \\uc0ac\\ub78c\\uc744 \\ucc3e\\uc544\\ubcf4\\uc138\\uc694.\",\n          \"\\uc5ec\\ud589\\uc744 \\ub5a0\\ub098 \\ubcf4\\uc138\\uc694.\",\n          \"\\ud589\\ubcf5\\ud560 \\uac70\\ub77c \\uc0dd\\uac01\\ud574\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-34276dd6-c7e6-4e93-9825-5059192f27a3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34276dd6-c7e6-4e93-9825-5059192f27a3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-34276dd6-c7e6-4e93-9825-5059192f27a3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-34276dd6-c7e6-4e93-9825-5059192f27a3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-b2460fc5-69c9-48dd-a8cb-da5634d1849d\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2460fc5-69c9-48dd-a8cb-da5634d1849d')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-b2460fc5-69c9-48dd-a8cb-da5634d1849d button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                 Q            A\n",
       "0           12시 땡!   하루가 또 가네요.\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "4          PPL 심하네   눈살이 찌푸려지죠."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38845196-7a1d-4da8-9227-3d99ec5024ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1748842109426,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "38845196-7a1d-4da8-9227-3d99ec5024ce",
    "outputId": "cf7c54bf-fd82-414f-df02-6cbfc8b79a26"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\\ud751\\uae30\\uc0ac \\ud574\\uc8fc\\ub294 \\uc9dd\\ub0a8.\",\n          \"\\ud798\\ub4e4\\uc5b4\\uc11c \\uacb0\\ud63c\\ud560\\uae4c\\ubd10\",\n          \"\\ud6d4\\uccd0\\ubcf4\\ub294 \\uac83\\ub3c4 \\ub208\\uce58 \\ubcf4\\uc784.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\ud6d4\\uccd0\\ubcf4\\ub294 \\uac70 \\ud2f0\\ub098\\ub098\\ubd10\\uc694.\",\n          \"\\ub3c4\\ud53c\\uc131 \\uacb0\\ud63c\\uc740 \\ud558\\uc9c0 \\uc54a\\uae38 \\ubc14\\ub77c\\uc694.\",\n          \"\\uc124\\ub81c\\uaca0\\uc5b4\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ed86be46-518e-4998-abba-a674a9dea11b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed86be46-518e-4998-abba-a674a9dea11b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ed86be46-518e-4998-abba-a674a9dea11b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ed86be46-518e-4998-abba-a674a9dea11b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-6b5fb0ec-cfd3-4552-b2c4-d833a5c845fb\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b5fb0ec-cfd3-4552-b2c4-d833a5c845fb')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-6b5fb0ec-cfd3-4552-b2c4-d833a5c845fb button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                             Q                         A\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aad072-2245-41e8-9863-a0b451262fdd",
   "metadata": {
    "id": "d1aad072-2245-41e8-9863-a0b451262fdd"
   },
   "source": [
    "# Dataset, DataLoader 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e0b8d-ee13-488b-ae6e-2a7d4189fd6c",
   "metadata": {
    "id": "cd6e0b8d-ee13-488b-ae6e-2a7d4189fd6c"
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "### Subword방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d080f3aa-6d49-464f-9469-91ef9bcd351c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1748842109533,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "d080f3aa-6d49-464f-9469-91ef9bcd351c",
    "outputId": "5cf11f01-63fa-4555-ce4e-43e20691bff6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 11823, 11823)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token 학습 -> vocab 사전 생성.\n",
    "## 질문들 + 답변들 합쳐서 학습.\n",
    "question_texts = df['Q']\n",
    "answer_texts = df['A']\n",
    "all_texts = list(question_texts + \" \"+answer_texts) # 같은 index끼리 합치기 => list로 변환\n",
    "len(question_texts), len(answer_texts), len(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8ea110e-9215-4385-9d41-2d6675fd2c17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1748842109554,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "a8ea110e-9215-4385-9d41-2d6675fd2c17",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c55141cf-8c0e-4369-cc59-f352f095e2db",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡! 하루가 또 가네요.',\n",
       " '1지망 학교 떨어졌어 위로해 드립니다.',\n",
       " '3박4일 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " '3박4일 정도 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " 'PPL 심하네 눈살이 찌푸려지죠.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac2eea8d-c5c6-42e0-9314-c94043113668",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1748842109556,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "ac2eea8d-c5c6-42e0-9314-c94043113668"
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60438a5d-a238-42e3-96ea-c02d458fbee3",
   "metadata": {
    "executionInfo": {
     "elapsed": 448,
     "status": "ok",
     "timestamp": 1748842110021,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "60438a5d-a238-42e3-96ea-c02d458fbee3"
   },
   "outputs": [],
   "source": [
    "vocab_size = 10_000\n",
    "min_frequency = 5\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=vocab_size,\n",
    "    min_frequency=min_frequency,\n",
    "    continuing_subword_prefix='##', # 연결 subword 앞에 붙일 접두어지정.\n",
    "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[SOS]\"] # [SOS]: 문장의 시작을 의미하는 토큰.\n",
    ")\n",
    "# tokenizer: token + ##izer\n",
    "## 학습\n",
    "tokenizer.train_from_iterator(all_texts, trainer=trainer) # 리스트로 부터 학습\n",
    "## tokenizer.train(\"파일경로\") # 파일에 있는 text를 학습."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad5b0c24-3261-4c24-be02-6cff4f789540",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1748842110049,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "ad5b0c24-3261-4c24-be02-6cff4f789540",
    "outputId": "50b37ba7-af4e-4014-98e3-c4377175f5d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 어휘수: 7040\n"
     ]
    }
   ],
   "source": [
    "print(\"총 어휘수:\", tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44198fe6-9e49-49c4-ab70-d3ab3b2bdf45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1748842110065,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "44198fe6-9e49-49c4-ab70-d3ab3b2bdf45",
    "outputId": "b033aeef-1169-460c-ffc9-6b9ffcebbe37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2290, 3852, 2258, 5913, 8, 3271, 2447, 322, 2243, 8, 1, 1, 1, 1920]\n",
      "['오늘', '날씨가', '너무', '좋습니다', '.', '즐거운', '하루', '되', '##세요', '.', '[UNK]', '[UNK]', '[UNK]', '##ㅋ']\n"
     ]
    }
   ],
   "source": [
    "# 토큰화\n",
    "encode = tokenizer.encode(\"오늘 날씨가 너무 좋습니다. 즐거운 하루 되세요. 쿄쿄쿜ㅋ\")\n",
    "print(encode.ids)\n",
    "print(encode.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80caf0b3-01d5-4631-87c1-f48ab2f5bafc",
   "metadata": {
    "id": "80caf0b3-01d5-4631-87c1-f48ab2f5bafc"
   },
   "source": [
    "### Tokenizer 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abe8873a-dde0-4c0b-9146-0da961f55bc4",
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1748842110094,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "abe8873a-dde0-4c0b-9146-0da961f55bc4"
   },
   "outputs": [],
   "source": [
    "dir_path = \"saved_model/vocab\"\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "vocab_path = os.path.join(dir_path, \"chatbot_bpe.json\")\n",
    "tokenizer.save(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0ed30c5-fcd0-457a-be8d-a70e8617b7d4",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1748842110096,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "e0ed30c5-fcd0-457a-be8d-a70e8617b7d4"
   },
   "outputs": [],
   "source": [
    "# question_texts, answer_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b068c-ead0-4f75-bd01-4a0ebf486774",
   "metadata": {
    "id": "ba2b068c-ead0-4f75-bd01-4a0ebf486774"
   },
   "source": [
    "## Dataset, DataLoader 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ae89444-25b0-4b96-819a-640e35d933dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1748842110099,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "0ae89444-25b0-4b96-819a-640e35d933dc",
    "outputId": "6229ed4b-9d0d-467e-e4d3-017c8183bcd1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "from torch import optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d181d3a2-a7eb-482a-8c9e-b03feaca8f1a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1748842110119,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "d181d3a2-a7eb-482a-8c9e-b03feaca8f1a"
   },
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ChatbotDataset\n",
    "    parameter:\n",
    "        question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "        answer_texts: list[str] - 답 texts 목록. 리스트에 답변들을 담아서 받는다.     [\"답1\", \"답2\", ...]\n",
    "        max_length: 개별 문장의 token 개수. 모든 문장의 토큰수를 max_length에 맞춘다.\n",
    "        tokenizer: Tokenizer\n",
    "        vocab_size: int 총단어수\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, question_texts, answer_texts, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        parameter\n",
    "            question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "            answer_texts: list[str] - 답 texts 목록. 리스트에 답변들을 담아서 받는다.     [\"답1\", \"답2\", ...]\n",
    "            max_length: 개별 문장의 token 개수. 모든 문장의 토큰수를 max_length에 맞춘다.\n",
    "            tokenizer: Tokenizer\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n",
    "        self.answer_texts = [self.__process_sequence(a) for a in answer_texts]\n",
    "\n",
    "    def __pad_token_sequence(self, token_sequence):\n",
    "        \"\"\"\n",
    "        max_length 길이에 맞춰 token_id 리스트를 구성한다.\n",
    "        max_length 보다 길면 뒤에를 자르고 max_length 보다 짧으면 [PAD] 토큰을 추가한다.\n",
    "\n",
    "        Parameter\n",
    "            token_sentence: list[int] - 길이를 맞출 한 문장 token_id 목록\n",
    "        Return\n",
    "            list[int] - length가 max_length인 token_id 목록\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('[PAD]')\n",
    "        seq_len = len(token_sequence) # 입력 문장의 토큰수\n",
    "        if seq_len > self.max_length: # 문장 최대 토큰수 보다 길다면.\n",
    "            return token_sequence[:self.max_length]\n",
    "        else:\n",
    "            return token_sequence + ([pad_token] * (self.max_length - seq_len))\n",
    "\n",
    "    def __process_sequence(self, text):\n",
    "        \"\"\"\n",
    "        한 문장(str)을 받아서 padding이 추가된 token_id 리스트로 변환 후 반환\n",
    "        Parameter\n",
    "            text: str - token_id 리스트로 변환할 한 문장\n",
    "        Return\n",
    "            list[int] - 입력받은 문장에 대한 token_id 리스트\n",
    "        \"\"\"\n",
    "        # encoding\n",
    "        encode = self.tokenizer.encode(text) # \"........\" => [. , . , .]\n",
    "        # max_length 크기에 맞춘다.\n",
    "        token_ids = self.__pad_token_sequence(encode.ids) #[3400, 20, 6, 0, 0, 0 ..]\n",
    "        return token_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.question_texts)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # return  index의 (질문토큰들,  답변토큰들)\n",
    "        q = self.question_texts[index]  # List\n",
    "        a = self.answer_texts[index]\n",
    "        # List->LongTensor. nn.Embedding()의 입력(정수타입)으로 들어간다.\n",
    "        return torch.tensor(q, dtype=torch.int64), torch.tensor(a, dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23c3e4ad-d4f4-4d2d-98e5-1f190129ca5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1748842110603,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "23c3e4ad-d4f4-4d2d-98e5-1f190129ca5e",
    "outputId": "062e0078-9f65-4ba5-9a2d-afa884296891"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17., 19., 41.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 적당한 max_length 값: 전체 문장 총 토큰수의 9분위수\n",
    "import numpy as np\n",
    "a = [len(tokenizer.encode(s).ids) for s in all_texts]\n",
    "# a[:5]\n",
    "np.quantile(a, q=[0.9, 0.95, 1.0])\n",
    "# max_length=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9635c49e-98fd-4da0-8a69-f39151d4d9e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1748842111021,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "9635c49e-98fd-4da0-8a69-f39151d4d9e0",
    "outputId": "18c7a8c8-1b5e-4f44-b4b1-a6327cb0cf9e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(a, 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "566e885c-77ec-4c7b-b05d-e493e125b460",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 505,
     "status": "ok",
     "timestamp": 1748842111528,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "566e885c-77ec-4c7b-b05d-e493e125b460",
    "outputId": "4b31db08-4270-42b2-e946-11f89fad9a07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# Dataset 셍상\n",
    "MAX_LENGTH = 20\n",
    "dataset = ChatbotDataset(question_texts, answer_texts, MAX_LENGTH, tokenizer)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "409f90d0-4669-4851-a606-e52556fd9802",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1748842111535,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "409f90d0-4669-4851-a606-e52556fd9802",
    "outputId": "b3b756a8-8016-4f0a-fb76-b4c22e8ea33d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  10, 1662, 1383,  368,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " tensor([6118,  378,   47, 2252,    8,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d2b6f-ccf7-4aec-9c08-176a2456e813",
   "metadata": {
    "id": "2b6d2b6f-ccf7-4aec-9c08-176a2456e813"
   },
   "source": [
    "### Trainset / Testset 나누기\n",
    "train : test = 9 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "377218ae-8d2b-4f59-a20a-03800663e298",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1748842111594,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "377218ae-8d2b-4f59-a20a-03800663e298",
    "outputId": "2343cf8e-f37c-497f-bc1d-17ea1b5a2b05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10640"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(dataset) * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb7d0d5a-c8ba-48be-bc46-d5ba12cd89e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1748842111619,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "eb7d0d5a-c8ba-48be-bc46-d5ba12cd89e6",
    "outputId": "43e0723c-b55d-46bb-a70f-2ebd556094e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10640 1183\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(dataset)*0.9)\n",
    "test_size = len(dataset) - train_size\n",
    "print(train_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42aed6cf-4aa2-4262-a4d4-964365ce7dea",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1748842111621,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "42aed6cf-4aa2-4262-a4d4-964365ce7dea"
   },
   "outputs": [],
   "source": [
    "# random_split()이용해서 분리\n",
    "###shuffle 후 개수에 맞게 나눔\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ef5990a-9233-4c0a-9e18-c7f38d3f995e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1748842111628,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "0ef5990a-9233-4c0a-9e18-c7f38d3f995e",
    "outputId": "3218049a-00e3-4643-f47a-22c45f3242c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.ChatbotDataset, torch.utils.data.dataset.Subset)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset), type(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b274f-8c8a-4aa6-af6d-a66bf5c38210",
   "metadata": {
    "id": "3d4b274f-8c8a-4aa6-af6d-a66bf5c38210"
   },
   "source": [
    "### DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c51e1123-cbdd-4dce-8998-d4638ce04e60",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1748842111630,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "c51e1123-cbdd-4dce-8998-d4638ce04e60"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c61053a2-8362-47ff-a167-efcbdf2c8226",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1748842111637,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "c61053a2-8362-47ff-a167-efcbdf2c8226",
    "outputId": "17fe8c34-5ba8-44c4-aaa4-59fd1e28040b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 19)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader) # step 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdaf424-c7de-46be-b74b-88a3efcdf352",
   "metadata": {
    "id": "1cdaf424-c7de-46be-b74b-88a3efcdf352"
   },
   "source": [
    "# 모델 정의\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d7410-a73e-4be1-b41d-9ea07d6b0911",
   "metadata": {
    "id": "e17d7410-a73e-4be1-b41d-9ea07d6b0911"
   },
   "source": [
    "## Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff60f00e-707c-47e9-ab60-dad42d0ec508",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1748842111639,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "ff60f00e-707c-47e9-ab60-dad42d0ec508"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim,\n",
    "                 hidden_size, bidirectional=True, num_layers=1, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        # Encoder는 context vector(문장의 feature)를 생성하는 것이 목적 (분류기는 생성안함.)\n",
    "        # Embedding Layer, GRU Layer를 생성.\n",
    "        self.vocab_size = vocab_size # 어휘사전의 총 어휘수(토큰수)\n",
    "        # 임베딩레이어\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim,   # embedding vector shape: [vocab_size, embedding_dim]\n",
    "            padding_idx=0\n",
    "        )\n",
    "        # GRU\n",
    "        self.gru = nn.GRU(\n",
    "            embedding_dim, # 개별 토큰(time step)의 크기.\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.embedding(X) # (batch, seq_len, embedding_dim)\n",
    "        X = X.transpose(1, 0) # (seq_len, batch, embedding_dim)\n",
    "        out, hidden = self.gru(X)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b7c9fcf-6d84-4c2f-b7b5-82ea92b80150",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1748842114234,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "7b7c9fcf-6d84-4c2f-b7b5-82ea92b80150",
    "outputId": "c13fbfd9-18da-47b4-c7a1-ede95b64d405"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Encoder                                  [20, 64, 512]             --\n",
       "├─Embedding: 1-1                         [64, 20, 200]             200,000\n",
       "├─GRU: 1-2                               [20, 64, 512]             703,488\n",
       "==========================================================================================\n",
       "Total params: 903,488\n",
       "Trainable params: 903,488\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 913.26\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 7.29\n",
       "Params size (MB): 3.61\n",
       "Estimated Total Size (MB): 10.92\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "encoder_model = Encoder(1000, 200, 256)\n",
    "dummy_data = torch.zeros((64, 20), dtype=torch.int64)  #(batch:64, seq_len:20)\n",
    "summary(encoder_model, input_data=dummy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24779603-15ac-4ba1-a24c-6e86658b3ad6",
   "metadata": {
    "id": "24779603-15ac-4ba1-a24c-6e86658b3ad6"
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "282f60e8-7e86-479a-8522-d32aab86b1b0",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1748842114259,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "282f60e8-7e86-479a-8522-d32aab86b1b0"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim,\n",
    "                 hidden_size, num_layers=1, bidirectional=False, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size # 총 어휘사전 토큰 개수.\n",
    "        # embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # GRU\n",
    "        ## Auto Regressive RNN은 단방향만 가능.\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size,\n",
    "                          num_layers=num_layers, dropout=dropout_rate)\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # 분류기 (다음 단어(토큰)를 추론)\n",
    "           # - 다중분류(단어사전의 단어들의 다음 단어일 확를)\n",
    "        self.lr = nn.Linear(\n",
    "            hidden_size,  # GRU 출력 값 중 마지막 hidden state값을 입력으로 받음.\n",
    "            vocab_size    # 출력: 다음 단어일 확률.\n",
    "        )\n",
    "\n",
    "    def forward(self, X, hidden):\n",
    "        # X: torch.LongTensor: shape - [batch] : 한 단어씩 입력을 받음.\n",
    "        # hidden: torch.FloatTensor: shape - [1, batch, hidden_size] (이전까지의 특성)\n",
    "\n",
    "        X = X.unsqueeze(1) # seq_len 축을 추가. [batch] -> [batch, 1] (Embedding Layer의 input shape)\n",
    "        X = self.embedding(X) # [batch, 1, embedding 차원]\n",
    "        X = X.transpose(1, 0) # [1, batch, embedding 차원]\n",
    "\n",
    "        out, hidden = self.gru(X, hidden)\n",
    "        last_out = out[-1] # out: 전체 hidden state값-> 마지막 hidden state을 추출\n",
    "        last_out = self.lr(last_out)\n",
    "\n",
    "        return last_out, hidden # (hidden: 다음 timestep에 전달.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbb1cd25-b1e6-4f64-9319-e397561845ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1748842114294,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "dbb1cd25-b1e6-4f64-9319-e397561845ba",
    "outputId": "97ead303-a55e-45e3-ad68-0a32fe639c47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Decoder                                  [64, 1000]                --\n",
       "├─Embedding: 1-1                         [64, 1, 200]              200,000\n",
       "├─GRU: 1-2                               [1, 64, 256]              351,744\n",
       "├─Linear: 1-3                            [64, 1000]                257,000\n",
       "==========================================================================================\n",
       "Total params: 808,744\n",
       "Trainable params: 808,744\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 51.76\n",
       "==========================================================================================\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 0.75\n",
       "Params size (MB): 3.23\n",
       "Estimated Total Size (MB): 4.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### summary\n",
    "\n",
    "decoder_model = Decoder(1000, 200, 256)\n",
    "\n",
    "dummy_input = torch.ones((64, ), dtype=torch.int64)\n",
    "dummy_hidden = torch.ones((1, 64, 256), dtype=torch.float32)\n",
    "\n",
    "summary(decoder_model, input_data=(dummy_input, dummy_hidden))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3563f5b2-f18b-42b5-9bd4-f4f8abd767ac",
   "metadata": {
    "id": "3563f5b2-f18b-42b5-9bd4-f4f8abd767ac"
   },
   "source": [
    "## Seq2Seq 모델\n",
    "\n",
    "- Encoder - Decoder 를 Layer로 가지며 Encoder로 질문의 feature를 추출하고 Decoder로 답변을 생성한다.\n",
    "\n",
    "### Teacher Forcing\n",
    "- **Teacher forcing** 기법은, RNN계열 모델이 다음 단어를 예측할 때, 이전 timestep에서 예측된 단어를 입력으로 사용하는 대신 **실제 정답 단어(ground truth) 단어를** 입력으로 사용하는 방법이다.\n",
    "    - 모델은 이전 시점의 출력 단어를 다음 시점의 입력으로 사용한다. 그러나 모델이 학습할 때 초반에는 정답과 많이 다른 단어가 생성되어 엉뚱한 입력이 들어가 학습이 빠르게 되지 않는 문제가 있다.\n",
    "> - RNN 기반 모델은 시퀀스를 한 단계씩 예측한다.\n",
    "> - 이때 각 단계의 입력은 이전 단계의 출력인데, 이 출력값이 틀릴 경우 오류가 누적된다.\n",
    "> - 그래서 학습 중에는 \"정답을 정답으로 줘서\" 모델이 빠르게 수렴하게끔 도와주는 것.\n",
    "\n",
    "- **장점**\n",
    "    - **수렴 속도 증가**: 정답 단어를 사용하기 때문에 모델이 더 빨리 학습할 수있다.\n",
    "    - **안정적인 학습**: 초기 학습 단계에서 모델의 예측이 불안정할 때, 잘못된 예측으로 인한 오류가 다음 단계로 전파되는 것을 막아줍니다.\n",
    "- **단점**\n",
    "    - **노출 편향(Exposure Bias) 문제:** 실제 예측 시에는 정답을 제공할 수 없으므로 모델은 전단계의 출력값을 기반으로 예측해 나가야 한다. 학습 과정과 추론과정의 이러한 차이 때문에 모델의 성능이 떨어질 수있다.\n",
    "        - 이런 문제를 해결하기 학습 할 때 **Teacher forcing을 random하게 적용하여 학습시킨다.**\n",
    "\t\t> - 즉, 일정 확률로, \"정답과 \"모델의 출력값\"을 섞어서 사용하는 방법을 의미\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd4aa18b-985a-47fd-868a-47a570dc1545",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1748842114333,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "bd4aa18b-985a-47fd-868a-47a570dc1545",
    "outputId": "969cb9c0-6e0f-459e-83aa-0d9095d0b260"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOS_TOKEN = tokenizer.token_to_id(\"[SOS]\")\n",
    "SOS_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1296c6",
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1748842114334,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "fa1296c6"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder.to(device)\n",
    "        self.decoder = decoder.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, inputs, outputs, teacher_forcing_rate=0.99):\n",
    "        \"\"\"\n",
    "        parameter\n",
    "            inputs: 질문 - (batch, seq_length)\n",
    "            outputs: 답변(정답) - (batch, seq_length)\n",
    "            teacher_forcing_rate: teacher_forcing 적용 확률.\n",
    "        \"\"\"\n",
    "        #################################\n",
    "        # 차원 맞추기\n",
    "        #################################\n",
    "\n",
    "        # 1.질문\n",
    "        if inputs.dim() == 1:\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "        # 2.답변\n",
    "        if outputs.dim() == 1:\n",
    "            outputs = outputs.unsqueeze(0)\n",
    "\n",
    "\n",
    "        #################################\n",
    "        # 기본 변수 설정\n",
    "        #################################\n",
    "\n",
    "        # 1.출력 문장의 길이와 배치 크기 추출\n",
    "        batch_size, output_length = outputs.shape # output_length: 답변문장의 토큰 수\n",
    "\t\t# 2.디코더가 생성할 수 있는 전체 단어 개수\n",
    "        output_vocab_size = self.decoder.vocab_size  # 어휘사전 토큰 총 개수.\n",
    "        # 3. 출력 결과(모든 시점의 예측 결과)를 저장할 텐서\n",
    "\t\t## 생성된 문장을 저장할 변수\n",
    "        ## (seq length, batch size, vocab_size(단어별 확률))\n",
    "        predicted_outputs = torch.zeros(output_length, batch_size, output_vocab_size).to(self.device)\n",
    "\n",
    "\n",
    "        #################################\n",
    "        # 인코더 실행\n",
    "        #################################\n",
    "\n",
    "        # 1.encoder를 이용해서 질문 문장의 context vector(출력 및 hidden state) 추출.\n",
    "        encoder_out, encoder_hidden = self.encoder(inputs)\n",
    "        ### encoder_out: [seq_len, batch, hidden_size * 2(양방향-단방향:1)]\n",
    "        ### encoder_hidden: [2(양방향-단방향:1), batch, hidden_size]\n",
    "        # 2.Decoder의 첫번째 hidden state로써 인코더의 마지막 출력인 Context Vector 사용\n",
    "        decoder_hidden = encoder_out[-1].unsqueeze(0) \n",
    "        # 3.Decoder에 넣을 첫번째 time step의 값: [SOS] -> [batch_size] 형태\n",
    "        decoder_input = torch.full((batch_size, ), fill_value=SOS_TOKEN, device=self.device)\n",
    "\n",
    "\n",
    "        #################################\n",
    "        # 디코더 반복 생성\n",
    "        #################################\n",
    "\n",
    "        # 순회(반복) 하면서 단어들을 하나씩 생성. (최대 ouput_length(답변 문장의 길이)만큼 반복)\n",
    "        for t in range(output_length): # max_length 만큼 생성.\n",
    "            # decoder_input(개별토큰id): [batch_size] - 첫 timestep: [SOS], 두번째: 생성된 토큰\n",
    "            # decoder_out(batch_size, vocab_size): 다음 단어일 확률\n",
    "            # decoder_hidden(1, batch, hidden * 2(양방향, 단: 1)) - 현재 입력의 feature(다음 timestep의 hidden으로 사용)\n",
    "\n",
    "\t\t\t      # 1.디코더에 현재 입력 토큰과 hidden state를 넣어 출력 단어 확률 분포를 받음\n",
    "            decoder_out, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "\t\t\t      # 2.예측된 단어의 확률 분포를 t번째 시점에 저장\n",
    "            predicted_outputs[t] = decoder_out # t번째 예측 단어를 저장.\n",
    "\n",
    "\n",
    "            #################################\n",
    "            # Teacher Forcing 적용 여부 결정\n",
    "            #################################\n",
    "\n",
    "            # 1.teacher_forcing_rate 확률에 따라 정답을 줄지 예측을 줄지 결정(True면 정답)\n",
    "            teacher_forcing = teacher_forcing_rate > random.random() # TeacherForcing 적용여부(bool)\n",
    "            # teacher_forcing_rate의 확률만큼 True.\n",
    "            #>>> 다음 timestep에 넣어줄 값을 생성.\n",
    "            #>>> teacher_forcing 적용: 정답, 비적용: 모델이 추론한 결과\n",
    "\n",
    "\t\t\t# 2.반복할 수록 teacher forcing 비율 감소(모델 자율성 증가)\n",
    "            teacher_forcing_rate = teacher_forcing_rate * 0.99\n",
    "            # 점점 teacher forcing이 적용될 가능성을 줄인다.\n",
    "                          # (모델이 추론한 값이 다음 입력으로 사용할 확률을 높여준다.)\n",
    "\n",
    "            #################################\n",
    "            # 다음 디코더 입력 준비\n",
    "            #################################\n",
    "\n",
    "            # 1.모델이 추론한 단어(예측된 단어)중 가장 확률이 높은(TOP-1) 단어의 인덱스를 추출\n",
    "            top1 = decoder_out.argmax(-1)\n",
    "\n",
    "            # 2.teacher forcing이면 정답(outputs[:, t]) 사용, 아니면 top1 예측 사용\n",
    "            ## teacher_foring이 True: 정답, False: 예측(top1)\n",
    "            decoder_input = outputs[:, t] if teacher_forcing else top1\n",
    "\n",
    "        #################################\n",
    "        # 마무리: 출력 포맷 변경\n",
    "        #################################\n",
    "        return predicted_outputs.transpose(1, 0)\n",
    "\t\t    #>>>> (seq_len, batch, vocab_size) -> (batch, seq_length, vocab_size) 변환."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f061ec70",
   "metadata": {},
   "source": [
    "## 1번 해설\n",
    "---\n",
    "### 1. seq2seq 모델에서 입력 형태\n",
    "일반적으로 딥러닝 모델, 특히 seq2seq은 다음과 같은 입력 형태를 기대합니다.\n",
    "\n",
    "- `inputs` (질문): (batch_size, input_seq_length)\n",
    "- `outputs` (정답): (batch_size, output_seq_length)\n",
    "이렇게 **2차원 텐서**를 입력으로 받아야 배치 연산이 가능합니다.\n",
    "---\n",
    "### 2. 그런데 dim() == 1이란?\n",
    "사용자가 모델에 한 문장만 넣었을 때, batch_size 없이 시퀀스 길이만 있는 텐서가 들어갈 수 있습니다.\n",
    "\n",
    "```python\n",
    "inputs = torch.tensor([101, 303, 505, 999])  # 입력 시퀀스 토큰 ID\n",
    "print(inputs.shape)  # torch.Size([4])\n",
    "print(inputs.dim())  # 1\n",
    "```\n",
    "이 경우 텐서의 형태는 (4,) 즉, 1차원 벡터.\n",
    "\n",
    "---\n",
    "### 3. 왜 unsqueeze(0)이 필요한가?\n",
    "모델은 (batch_size, seq_length) 형태를 기대하지만 지금은 (seq_length,)이므로, 이를 명시적으로 batch 차원을 추가해줘야 합니다.\n",
    "\n",
    "```python\n",
    "inputs = inputs.unsqueeze(0)  # → (1, 4)\n",
    "```\n",
    "이제 모델 입장에서 이건 \"배치 크기 1, 길이 4의 시퀀스\"입니다.\n",
    "\n",
    "- dim == 1 → 한 문장을 줬더니 그냥 리스트 한 줄로 줌\n",
    "- unsqueeze(0) → \"이 문장 하나가 배치 한 개다!\" 라고 감싸주는 것\n",
    "---\n",
    "### 4. 같은 맥락에서 outputs.dim() == 1\n",
    "정답 시퀀스(답변)도 마찬가지입니다. 만약 정답도 그냥 한 문장만 들어와 있다면 (output_seq_len,) 형태일 수 있으므로 아래와 같습니다.\n",
    "\n",
    "```python\n",
    "outputs = outputs.unsqueeze(0)  # → (1, output_seq_len)\n",
    "```\n",
    "---\n",
    "### 5. 결론\n",
    "```puthon\n",
    "if inputs.dim() == 1:\n",
    "    inputs = inputs.unsqueeze(0)  # (seq_len,) → (1, seq_len)\n",
    "\n",
    "if outputs.dim() == 1:\n",
    "    outputs = outputs.unsqueeze(0)  # (seq_len,) → (1, seq_len)\\\n",
    "```\n",
    "이 처리는 **모델의 forward에서 입력이 항상 2차원(batch 포함) 형태가 되도록 보장**하는 안전장치입니다.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fa3e30",
   "metadata": {},
   "source": [
    "## 2번 해설\n",
    "---\n",
    "### 1. encoder_out의 구조\n",
    "먼저 인코더의 출력 형태를 살펴봅시다.\n",
    "```python\n",
    "encoder_out, encoder_hidden = self.encoder(inputs)\n",
    "# encoder_out 구조: [seq_len, batch_size, hidden_size]\n",
    "```\n",
    "\n",
    "- seq_len: 입력 시퀀스 길이\n",
    "- batch_size: 배치 크기\n",
    "- hidden_size: 각 time step의 출력 벡터 크기\n",
    "\n",
    "---\n",
    "\n",
    "### 2. encoder_out[-1]의 의미\n",
    "encoder_out[-1] -> encoder_out 텐서에서 마지막 시점의 출력을 가져오는 코드입니다. <br>\n",
    "encoder_out과 encoder_out[-1]은 아래와 같은 형태를 가집니다.\n",
    "```less\n",
    "encoder_out: [seq_len, batch_size, hidden_size]\n",
    "encoder_out[-1]: [batch_size, hidden_size]\n",
    "```\n",
    "\n",
    "즉, 마지막 시점에서 모든 배치에 대해 인코더가 출력한 벡터입니다. 이게 바로 Context Vector로 쓰입니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. encoder_out[-1]의 의미\n",
    "첫 번째 차원 (seq_len 축) 에 대해 마지막 인덱스를 가져오는 것.<br>\n",
    "encoder_out[-1]은 인덱싱이지 슬라이싱이 아니기 때문에, **그 차원을 \"제거\"**\n",
    "\n",
    "| 코드| 결과 shape| 설명|\n",
    "| ------------------ | ------------------------------ | ------------------ |\n",
    "| `encoder_out[-1]`  | `[batch_size, hidden_size]`    | 단일 인덱싱 → 0번 차원 제거됨 |\n",
    "| `encoder_out[-1:]` | `[1, batch_size, hidden_size]` | 슬라이싱 → 차원 유지됨      |\n",
    "\n",
    "---\n",
    "\n",
    "### 4. 왜 unsqueeze(0)을 쓰는가?\n",
    "디코더의 RNN은 보통 hidden_state를 [num_layers, batch_size, hidden_size] 형식으로 기대합니다.<br>\n",
    "하지만 encoder_out[-1]은 [batch_size, hidden_size] 이기 때문에, 디코더에 넣기 전에 1차원 추가해줘야합니다.\n",
    "\n",
    "```python\n",
    "decoder_hidden = encoder_out[-1].unsqueeze(0)\n",
    "# shape: [1, batch_size, hidden_size]\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf1d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 2, 1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list = [1, 2, 3, 4, 5]\n",
    "\n",
    "list[-2::]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1073338",
   "metadata": {},
   "source": [
    "unsqueeze()는 어디에 쓰였나?\n",
    "| 위치| 설명| 결과|\n",
    "| ------ | ----------- | ------------- |\n",
    "| `inputs.unsqueeze(0)`| 입력이 1D면 batch 차원 추가| `[seq_len] → [1, seq_len]`|\n",
    "| `encoder_out[-1].unsqueeze(0)` | 디코더 hidden에 넣기 위해 time dimension 추가 | `[batch, hidden] → [1, batch, hidden]` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbf0ecb0-c657-4ca5-abf4-a31bab50300b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1748842114335,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "fbf0ecb0-c657-4ca5-abf4-a31bab50300b",
    "outputId": "4388440a-2c86-410f-98ed-aca78bf0dcd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8169343584285167"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random() # 랜덤값생성-0 ~ 1 실수를 반환. 모든 값들이 나올 확률은 동일 - 균등분포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89fed5-b059-4371-b836-c3eb59bebdfb",
   "metadata": {
    "id": "6e89fed5-b059-4371-b836-c3eb59bebdfb"
   },
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac7b8a-935e-4f3a-9fa5-efbacbfc19d7",
   "metadata": {
    "id": "6dac7b8a-935e-4f3a-9fa5-efbacbfc19d7"
   },
   "source": [
    "## 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0280640f-243a-4413-8e8c-dc0285b7aaa2",
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1748842114383,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "0280640f-243a-4413-8e8c-dc0285b7aaa2"
   },
   "outputs": [],
   "source": [
    "#  하이퍼파라미터들 정의\n",
    "VOCAB_SIZE = tokenizer.get_vocab_size()\n",
    "\n",
    "ENCODER_BIDIRECTIONAL = True # 인코더 양방향 여부\n",
    "ENCODER_HIDDEN_SIZE = 200    # 인코더 hidden_size\n",
    "# DECODER의 hidden size는 encoder의 마지막 timestep의 hidden size에 맞춰준다.\n",
    "DECODER_HIDDEN_SIZE = ENCODER_HIDDEN_SIZE * 2 if ENCODER_BIDIRECTIONAL else ENCODER_HIDDEN_SIZE # 인코더에 맞춰주기 위해 size를 조절\n",
    "EMBEDDING_DIM = 256  # 임베딩 차원수\n",
    "TEACHER_FORCING_RATE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a609b827-8287-4ea8-8df7-03a37ac8157d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1748842114384,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "a609b827-8287-4ea8-8df7-03a37ac8157d",
    "outputId": "ac0d52a1-857a-441c-8364-c032a9197a5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7040"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8723fbf1-263d-4cad-93cd-e5d015ce880c",
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1748842114699,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "8723fbf1-263d-4cad-93cd-e5d015ce880c"
   },
   "outputs": [],
   "source": [
    "### 모델 생성\n",
    "encoder = Encoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_size=ENCODER_HIDDEN_SIZE,\n",
    "    num_layers=1,\n",
    "    bidirectional=ENCODER_BIDIRECTIONAL\n",
    ")\n",
    "decoder = Decoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_size=DECODER_HIDDEN_SIZE,\n",
    "    num_layers=1  # auto regressive 모델이므로 단방향 GRU생성.\n",
    ")\n",
    "model = Seq2Seq(encoder, decoder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "465b9510-8603-41fe-bee3-f4fbf1c95189",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1748842114712,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "465b9510-8603-41fe-bee3-f4fbf1c95189",
    "outputId": "85fee9ec-8c70-45a4-8d6d-88082c506717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(7040, 256, padding_idx=0)\n",
      "    (gru): GRU(256, 200, bidirectional=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(7040, 256, padding_idx=0)\n",
      "    (gru): GRU(256, 400)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (lr): Linear(in_features=400, out_features=7040, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba83263-e042-4579-9784-2403eb3c3fa1",
   "metadata": {
    "id": "6ba83263-e042-4579-9784-2403eb3c3fa1"
   },
   "source": [
    "## loss함수, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f94e396-11dd-44a6-b414-11c082747c37",
   "metadata": {
    "executionInfo": {
     "elapsed": 9764,
     "status": "ok",
     "timestamp": 1748842124473,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "4f94e396-11dd-44a6-b414-11c082747c37"
   },
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "model = model.to(device)\n",
    "# 다음 단어를 추론하는 다중분류\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a659df1-87a2-4fe0-a095-e031ed130e68",
   "metadata": {
    "id": "6a659df1-87a2-4fe0-a095-e031ed130e68"
   },
   "source": [
    "## train/evaluation 함수 정의\n",
    "\n",
    "### train 함수정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3b6a36e-c023-47e0-9e86-081d40f06f8b",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1748842124474,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "f3b6a36e-c023-47e0-9e86-081d40f06f8b"
   },
   "outputs": [],
   "source": [
    "# 1 epoch 학습 함수.\n",
    "def train_fn(model, data_loader, optimizer, loss_fn, device,\n",
    "             teacher_forcing_rate=0.99):\n",
    "\n",
    "    model.train()  # Seq2Seq모델.\n",
    "    loss_list = [] # step별 loss를 저장.\n",
    "\n",
    "    for X, y in data_loader: # X:질문, y:답변\n",
    "        # device 로 이동\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 추론\n",
    "        pred = model(X, y, teacher_forcing_rate)\n",
    "        # pred: 추론한 답변 문장: (batch, seq_length, vocab_size:토큰일 확률)\n",
    "\n",
    "        # pred와 정답의 shape을 변경 (loss 함수에 넣을 수 있는 shape으로 변환.)\n",
    "          # pred를 reshape (batch, seq_len, vocab_size) -> (batch*seq_len, vocab_size)\n",
    "        y_hat = pred.reshape(-1, pred.shape[2])\n",
    "        # 정답(y)을 reshape (batch, seq_len:토큰수) -> (batch * seq_len)\n",
    "        y = y.reshape(-1)\n",
    "        # CrossEntropyLoss(): 정답 - 원핫인코딩 안된 형태, 추론값: softmax 처리 안된 상태\n",
    "        #       - 정답  shape: (batch, ) ===> (batch*se1_len)\n",
    "        #       - 추론값shape: (batch, class개수)\n",
    "\n",
    "        # Loss 계산\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        # gradient 계산\n",
    "        loss.backward()\n",
    "        # 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "        # 파라미터 초기화\n",
    "        optimizer.zero_grad()\n",
    "        loss_list.append(loss.item())\n",
    "    return np.mean(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981388d-ad33-4318-844b-29a5a434d2a7",
   "metadata": {
    "id": "8981388d-ad33-4318-844b-29a5a434d2a7"
   },
   "source": [
    "### Test 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2a786b6-f5e3-4db7-a9c6-087abc3e7c1a",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1748842124475,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "b2a786b6-f5e3-4db7-a9c6-087abc3e7c1a"
   },
   "outputs": [],
   "source": [
    "def test_fn(model, data_loader, loss_fn, device):\n",
    "\n",
    "    # 1 에폭 테스트\n",
    "    model.eval()\n",
    "    loss_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            # 이동\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # 추론\n",
    "            # 추론-답변 생성: decoder가 생성한 단어를 다음 단어로 넣어서 추정.\n",
    "            # teacher forcing은 train시에만 적용\n",
    "            pred = model(X, y, teacher_forcing_rate=0.0)\n",
    "            # loss 계산\n",
    "            # y와 pred의 shape을 CrossEntropyLoss 입력에 맞게 reshape\n",
    "            y_hat = pred.reshape(-1, pred.shape[2])\n",
    "            y = y.reshape(-1)\n",
    "            loss_list.append(loss_fn(y_hat, y).item())\n",
    "\n",
    "    return np.mean(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71e20c-8a03-44f4-bbbc-8f4e51b85636",
   "metadata": {
    "id": "4a71e20c-8a03-44f4-bbbc-8f4e51b85636"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5be7490",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1748842124476,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "a5be7490"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dir_path = \"saved_model/chatbot/vocab\"\n",
    "os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "grXZNZgvG_Or",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1748842124477,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "grXZNZgvG_Or",
    "outputId": "c912f44d-6e15-4ed6-afd7-123fda30e387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "i6hkiSMGItcB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181664,
     "status": "ok",
     "timestamp": 1748844419952,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "i6hkiSMGItcB",
    "outputId": "5174fcdb-0007-4402-922c-8bf4b1116954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0에서 저장. inf에서 5.08689로 개선됨.\n",
      "[0/1000] train loss: 0.0087, val loss: 5.0869\n",
      "1에서 개선되지 않음. trigger=1/10\n",
      "[1/1000] train loss: 0.0087, val loss: 5.1152\n",
      "2에서 개선되지 않음. trigger=2/10\n",
      "[2/1000] train loss: 0.0087, val loss: 5.1405\n",
      "3에서 개선되지 않음. trigger=3/10\n",
      "[3/1000] train loss: 0.0105, val loss: 5.2132\n",
      "4에서 저장. 5.08689에서 5.07015로 개선됨.\n",
      "[4/1000] train loss: 0.0176, val loss: 5.0702\n",
      "5에서 개선되지 않음. trigger=1/10\n",
      "[5/1000] train loss: 0.0433, val loss: 5.0900\n",
      "6에서 저장. 5.07015에서 5.05896로 개선됨.\n",
      "[6/1000] train loss: 0.0694, val loss: 5.0590\n",
      "7에서 개선되지 않음. trigger=1/10\n",
      "[7/1000] train loss: 0.0424, val loss: 5.1874\n",
      "8에서 개선되지 않음. trigger=2/10\n",
      "[8/1000] train loss: 0.0217, val loss: 5.2359\n",
      "9에서 개선되지 않음. trigger=3/10\n",
      "[9/1000] train loss: 0.0102, val loss: 5.2841\n",
      "10에서 개선되지 않음. trigger=4/10\n",
      "[10/1000] train loss: 0.0074, val loss: 5.3201\n",
      "11에서 개선되지 않음. trigger=5/10\n",
      "[11/1000] train loss: 0.0057, val loss: 5.4044\n",
      "12에서 개선되지 않음. trigger=6/10\n",
      "[12/1000] train loss: 0.0046, val loss: 5.4629\n",
      "13에서 개선되지 않음. trigger=7/10\n",
      "[13/1000] train loss: 0.0044, val loss: 5.4654\n",
      "14에서 개선되지 않음. trigger=8/10\n",
      "[14/1000] train loss: 0.0044, val loss: 5.4928\n",
      "15에서 개선되지 않음. trigger=9/10\n",
      "[15/1000] train loss: 0.0037, val loss: 5.5584\n",
      "16에서 개선되지 않음. trigger=10/10\n",
      "🔴 Early stopping 발생: 10 epoch 동안 개선 없음\n",
      "⏱️ 전체 학습 시간: 181.58초\n"
     ]
    }
   ],
   "source": [
    "# 1000에폭 patience 넣어 진행\n",
    "\n",
    "EPOCHS = 1000\n",
    "MODEL_SAVE_PATH = 'saved_model/chatbot/seq2seq-chatbot-model.pt'\n",
    "\n",
    "best_loss = np.inf\n",
    "patience = 10\n",
    "trigger = 0\n",
    "s = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_fn(model, train_loader, optimizer, loss_fn,\n",
    "                          device, TEACHER_FORCING_RATE)\n",
    "    val_loss = test_fn(model, test_loader, loss_fn, device)\n",
    "\n",
    "    # val_loss 개선 여부 체크\n",
    "    if val_loss < best_loss:\n",
    "        torch.save(model, MODEL_SAVE_PATH)\n",
    "        print(f\"{epoch}에서 저장. {best_loss:.5f}에서 {val_loss:.5f}로 개선됨.\")\n",
    "        best_loss = val_loss\n",
    "        trigger = 0  # 개선되면 trigger 초기화\n",
    "    else:\n",
    "        trigger += 1\n",
    "        print(f\"{epoch}에서 개선되지 않음. trigger={trigger}/{patience}\")\n",
    "\n",
    "        if trigger >= patience:\n",
    "            print(f\"🔴 Early stopping 발생: {patience} epoch 동안 개선 없음\")\n",
    "            break\n",
    "\n",
    "    print(f\"[{epoch}/{EPOCHS}] train loss: {train_loss:.4f}, val loss: {val_loss:.4f}\")\n",
    "\n",
    "e = time.time()\n",
    "print(\"⏱️ 전체 학습 시간: {:.2f}초\".format(e - s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "335aa2c8-4e29-46dd-90bd-69a41301adf7",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1748844419966,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "335aa2c8-4e29-46dd-90bd-69a41301adf7"
   },
   "outputs": [],
   "source": [
    "# EPOCHS = 1000 #10\n",
    "# MODEL_SAVE_PATH = 'saved_model/chatbot/seq2seq-chatbot-model.pt'\n",
    "\n",
    "# best_loss = np.inf\n",
    "# s = time.time()\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     train_loss = train_fn(model, train_loader, optimizer, loss_fn,\n",
    "#                           device, TEACHER_FORCING_RATE)\n",
    "#     val_loss = test_fn(model, test_loader, loss_fn, device)\n",
    "\n",
    "#     # 저장\n",
    "#     if val_loss < best_loss:\n",
    "#         torch.save(model, MODEL_SAVE_PATH)\n",
    "#         print(f\"{epoch}에서 저장. {best_loss:.5f}에서 {val_loss:.5f}로 개선됨.\")\n",
    "#         best_loss = val_loss\n",
    "\n",
    "#     print(f\"[{epoch}/{EPOCHS}] train loss: {train_loss}, val loss: {val_loss}\")\n",
    "\n",
    "# e = time.time()\n",
    "# print(\"걸린시간:\", (e-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf61c71e-3bbb-4a8b-8681-1dce2e4758f9",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1748844419982,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "bf61c71e-3bbb-4a8b-8681-1dce2e4758f9"
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH_LAST = 'saved_model/chatbot/seq2seq-chatbot-model_last.pt'\n",
    "torch.save(model, MODEL_SAVE_PATH_LAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "32793631-fe59-43f3-aac5-1e2d88eb1e8c",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1748844420002,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "32793631-fe59-43f3-aac5-1e2d88eb1e8c"
   },
   "outputs": [],
   "source": [
    "## 저장 모델 Load\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# map_location=device : 다른 device에 학습/저장한 모델을 읽어올 때 현재 device를 지정해서\n",
    "#                                                현재 device에 맞춰 load하도록한다.\n",
    "best_model = torch.load(MODEL_SAVE_PATH, weights_only=False, map_location=device)\n",
    "best_model.device = device # Attribute device를 현재 device로 지정.\n",
    "\n",
    "last_model = torch.load(MODEL_SAVE_PATH_LAST, weights_only=False, map_location=device)\n",
    "last_model.device = device # Attribute device를 현재 device로 지정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5280dca7-029c-4eb6-b079-39963d7b7932",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1748844420007,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "5280dca7-029c-4eb6-b079-39963d7b7932"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fe0585a-eb35-47dd-88bf-276d749f5f00",
   "metadata": {
    "id": "6fe0585a-eb35-47dd-88bf-276d749f5f00"
   },
   "source": [
    "# 결과확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4bcf956-b7e1-4f05-bd96-723fe0624339",
   "metadata": {
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1748844420099,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "e4bcf956-b7e1-4f05-bd96-723fe0624339"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "def handle_special_tokens(decoded_string):\n",
    "    \"\"\"\n",
    "    Subword 처리\n",
    "    subword는 단어의 시작으로 쓰인 것과 중간 부분(연결)에 사용된 두가지 subword가 있다.  연결 subword는 `#`과 같은 특수문자로 시작 한다.\n",
    "    tokenizer.decode() 결과 문자열은 subword의 특수문자('##')을 처리하지 않는다. 이것을 처리하는 함수\n",
    "    ex) \"이 기회 ##는 내 ##꺼 ##야\" ==> \"이 기회는 내꺼야\"\n",
    "\n",
    "    Parameter\n",
    "        decoded_string: str - Tokenizer가 decode한 중간 subword의 특수문자 처리가 안된 문자열.\n",
    "    Return\n",
    "        str: subword 특수문자 처리한 문자열\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = decoded_string.split() # 공백기준으로 토큰화.\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.startswith(\"##\"): # 연결 토큰\n",
    "            if new_tokens: # len(new_tokens) != 0 원소가 하나라도 있으면\n",
    "                # 토큰에서 ##을 제거하고 리스트의 마지막 원소(문자열) 뒤에 붙인다. >> 가장 최근에 추가된 단어[-1번째] 뒤에 문자열을 그냥 붙임(str의 더하기!)\n",
    "                new_tokens[-1] += token[2:]\n",
    "            else: # new_tokens가 빈 리스트. 현재 token이 첫번째 단어. ##을 지우고 append.(즉, 빈리스트라서 덧붙일 str가 없다면 그냥 ## 빼고 리스트에 넣음.)\n",
    "                new_tokens.append(token[2:])\n",
    "        else: # 단어의 시작인 토큰. (##이 없는 토큰) -> list에 추가.\n",
    "            new_tokens.append(token)\n",
    "\n",
    "    return \" \".join(new_tokens)\n",
    "\n",
    "\n",
    "# dataset에서 일부 데이터들을 가지고 확인\n",
    "def random_evaluation(model, dataset, device, n=10):\n",
    "    \"\"\"\n",
    "    Dataset에서 일부 질문-답변 쌍들을 가져다 모델에 질문을 넣어 추론한 결과와 함께 확인.\n",
    "    Parameter\n",
    "        model: 학습된 seq2seq 모델\n",
    "        dataset: 질문-답변 쌍울 추출할 dataset\n",
    "        device\n",
    "        n: int - 추출할 질문-답변 쌍 개수 default: 10\n",
    "    \"\"\"\n",
    "    ## 평가할 데이터셋을 만들기\n",
    "    n_samples = len(dataset)       # Dataset의 총 데이터개수\n",
    "    index = list(range(n_samples)) # Dataset의 index만들기.\n",
    "    np.random.shuffle(index)       # 값들을 랜덤하게 섞어준다.\n",
    "    sample_index = index[ : n]     # 평가할 데이터 개수만큼 index 생성.\n",
    "\n",
    "    # Dataloader 생성\n",
    "    # SubsetRandomSampler: 지정한 index들 안에서 random한 순서로 제공.\n",
    "    sampler = SubsetRandomSampler(sample_index) # 전체 dataset의 일부를 랜덤하게 제공\n",
    "    # ex. sample_index=[1, 20, 4, 5, 100], dataset에서 [1, 20, 4, 5, 100] index값만 추출. but 리스트내 원소들의 순서는 랜덤하게 바뀔 수 있다.\n",
    "    sample_loader = DataLoader(dataset, batch_size=n, sampler=sampler)\n",
    "\n",
    "    ## 추론 후 확인\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in sample_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X, y, 0.0) # [batch, seq_len, vocab_size]\n",
    "\n",
    "            # torch.Tensor -> ndarray (tokenizer decode에 넣기 위해.)\n",
    "            ## tensor를 cpu로 이동후 변환가능.\n",
    "            ### tensor가 grad를 가지고 있으면(계산그래프에 포함되 있으면)\n",
    "            ####                               -> tensor.detach().cpu().ndarray()\n",
    "            pred = output.cpu().numpy() # 모델의 추정한 답변 # X.to(\"cpu\") cpu로 to()써서 옮기는거랑 .cpu() 메서드쓰는거랑 같은 것.\n",
    "            X = X.cpu().numpy() # 정답-질문\n",
    "            y = y.cpu().numpy() # 정답-답변\n",
    "\n",
    "            for i in range(n):\n",
    "                q = handle_special_tokens(tokenizer.decode(X[i]))\n",
    "                a = handle_special_tokens(tokenizer.decode(y[i]))\n",
    "                p = handle_special_tokens(tokenizer.decode(pred[i].argmax(-1)))\n",
    "                print(f\"질문: {q}\")\n",
    "                print(f\"정답: {a}\")\n",
    "                print(f\"예측: {p}\")\n",
    "                print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bb045b7",
   "metadata": {
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1748844420104,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "1bb045b7"
   },
   "outputs": [],
   "source": [
    "sampler = SubsetRandomSampler([1,2])\n",
    "sample_loader = DataLoader(train_set, batch_size=2, sampler=sampler)\n",
    "a = next(iter(sample_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca10a36a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1748844420105,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "ca10a36a",
    "outputId": "cbfbb16f-ba50-43c1-ab50-c0f82ad76b6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[2428,  107, 1574, 1492, 1290, 2930, 1699, 1295,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [2365, 3076, 2888, 1450, 1826,   46,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0]]),\n",
       " tensor([[3667,  683, 5520, 4641, 2684,    8,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [4756, 3159, 2275, 5143,    8,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0]])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a # sampler가 어떻게 작동하는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b94a1-bc0a-474a-8415-57dc5ea4b894",
   "metadata": {
    "id": "287b94a1-bc0a-474a-8415-57dc5ea4b894"
   },
   "source": [
    "- Sampler:\n",
    "    -  DataLoader가 Datatset의 값들을 읽어서 batch를 만들때 index 순서를 정해주는 객체.\n",
    "    -  DataLoader의 기본 sampler는 SequentialSampler 이다. shuffle=True 일경우 RandomSampler: 랜덤한 순서로 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ca83744",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1748844420107,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "0ca83744",
    "outputId": "b6a0c541-fba0-477c-ef92-b8b9354ec885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 다니던 회사를 그만두고 1년간 여행을 가자고 해 .\n",
      "정답: 큰 용기가 필요하겠네요 .\n",
      "예측: 큰 용기가 필요하겠네요 .\n",
      "==================================================\n",
      "질문: 친구의 전여자친구가 좋은데 사겨도될까 ?\n",
      "정답: 친구을 잃을 수도 있어요 .\n",
      "예측: 친구을 잃을 수도 있어요 .\n",
      "==================================================\n",
      "질문: 힘내라고 말해줘\n",
      "정답: 응원합니다 !\n",
      "예측: 응원합니다 !\n",
      "==================================================\n",
      "질문: 썸 타는 중인데 바빠서 연락 제대로 못하는데 이해해야겠지 .\n",
      "정답: 좋아하는 마음이라면 이해해보세요 .\n",
      "예측: 좋아하는 마음이라면 이해해보세요 .\n",
      "==================================================\n",
      "질문: 사랑이 뭘까 ?\n",
      "정답: 신뢰입니다 .\n",
      "예측: 신뢰입니다 .\n",
      "==================================================\n",
      "질문: 헤어진지 1달\n",
      "정답: 금방 나아질 거예요 .\n",
      "예측: 금방 나아질 거예요 .\n",
      "==================================================\n",
      "질문: 여자친구 무시했다가 이별 당했습니다 .\n",
      "정답: 남을 질타하면 그것은 언젠간 자신에게 돌아와요 .\n",
      "예측: 남을 질타하면 그것은 언젠간 자신에게 돌아와요 .\n",
      "==================================================\n",
      "질문: 오늘 보기로 했던 그녀 , 못 보았네\n",
      "정답: 보지 않는 게 더 나았을 수도 있겠네요 .\n",
      "예측: 보지 않는 게 더 나았을 수도 있겠네요 .\n",
      "==================================================\n",
      "질문: 안경 벗고 완전 훈녀\n",
      "정답: 만화같은 일이네요 .\n",
      "예측: 만화같은 일이네요 .\n",
      "==================================================\n",
      "질문: 집에 가기 싫어\n",
      "정답: 가지마요 . 같이 라면 먹고 가요 .\n",
      "예측: 가지마요 . 같이 라면 먹고 가요 .\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "random_evaluation(model, train_set, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e6e57a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1748844420130,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "1e6e57a7",
    "outputId": "cdde60cc-3dcf-436d-e313-d3430e79de78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 남동생한테 자꾸 화내게 되네\n",
      "정답: 화를 참는 연습을 해보세요 .\n",
      "예측: 화를 참는 연습을 해보세요 .\n",
      "==================================================\n",
      "질문: 전 기다리고 있어 .\n",
      "정답: 기다리면서 상처받지 않을 자신 있나요 .\n",
      "예측: 이제 새로운 출발을 하면 돼요 .\n",
      "==================================================\n",
      "질문: 연락 많이 안하는 썸도 있나\n",
      "정답: 상대방이 너무 바쁜 상태일 수도 있어요 .\n",
      "예측: 자신의 감정을 주변 사람들에게 터놓고 이야기해보세요 .\n",
      "==================================================\n",
      "질문: 이별후 한달\n",
      "정답: 금방 지나갔네요 .\n",
      "예측: 생각보다 많은 시간이 지났네요 .\n",
      "==================================================\n",
      "질문: 짝남이랑 술 마셨는데 기분만 더 더러워졌어 .\n",
      "정답: 항상 후회만 남나봐요 .\n",
      "예측: 노력하는 모습이 좋아 보여요 .\n",
      "==================================================\n",
      "질문: 노후 걱정할 나이는 아닌데\n",
      "정답: 노후는 지금부터 준비하는 게 좋죠 .\n",
      "예측: 직접 말해보세요 .\n",
      "==================================================\n",
      "질문: 나 그대로를 사랑해줄 사람 있나\n",
      "정답: 분명히 있을 거예요 .\n",
      "예측: 아파하겠지요 .\n",
      "==================================================\n",
      "질문: 물가 왤케 비쌈\n",
      "정답: 그러게 말이에요 .\n",
      "예측: 부지런하시네요 .\n",
      "==================================================\n",
      "질문: 멋진 삶을 살고 싶어\n",
      "정답: 지금도 멋져요 .\n",
      "예측: 여유는 마음 가짐에 있어요 .\n",
      "==================================================\n",
      "질문: 휴학하고 싶다 .\n",
      "정답: 계획 세우고 하세요 .\n",
      "예측: 일이라도 해보세요 .\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "random_evaluation(model, test_set,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eea556c4-7534-409b-ae8e-a4d0c189e87c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1748844420188,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "eea556c4-7534-409b-ae8e-a4d0c189e87c",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "cc18ea4b-2dee-444f-9b99-6b94f0f1d36f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========BEST Model===========\n",
      "질문: 미용 몸무게하고 싶다\n",
      "정답: 지금도 충분히 아름다워요 .\n",
      "예측: 그 누구도 비정상이라 규정지 수 있을 거예요 .\n",
      "==================================================\n",
      "질문: 개강이다\n",
      "정답: 곧 방학이예요 .\n",
      "예측: 되도록 만나지 마세요 .\n",
      "==================================================\n",
      "질문: 또 다시 이별을 맞았네\n",
      "정답: 또 다시 잊어봐요 .\n",
      "예측: 잘 정리했길 바랍니다 .\n",
      "==================================================\n",
      "질문: 짝남한테 연락할까 ?\n",
      "정답: 연락해보세요 .\n",
      "예측: 사랑에는 구구절절한 이유가 필요 없어요 .\n",
      "==================================================\n",
      "질문: 아낌없이 퍼주는 스타일 . 호구인걸까 ?\n",
      "정답: 감정에 솔직한거죠 .\n",
      "예측: 신경쓰인다고 귀엽게 이야기해보세요 .\n",
      "==================================================\n",
      "질문: 재밌는거 없나 ?\n",
      "정답: 잼 있는 거는 딸기잼에게 물어봐 주세요 .\n",
      "예측: 오늘은 바지가 좋을거 같아요 .\n",
      "==================================================\n",
      "질문: 입덕했어\n",
      "정답: 즐기실 일만 남았네요 .\n",
      "예측: 꾸준히 치료하세요 .\n",
      "==================================================\n",
      "질문: 그녀는 내가 좋아하는 이 상황을 즐기는 것 같아 .\n",
      "정답: 나쁜 사람일지도 모르겠네요 .\n",
      "예측: 나쁜 사람일지도 모르겠네요 .\n",
      "==================================================\n",
      "질문: 감각이 무뎌질 때도 된 거 같은데\n",
      "정답: 시간이 가면 무뎌질 거예요 .\n",
      "예측: 어장은 포기하는 게 깔끔합니다 .\n",
      "==================================================\n",
      "질문: 어디까지 가야 끝이보일지\n",
      "정답: 끝은 눈에 보이지 않아 더 힘들죠 .\n",
      "예측: 머리랑 가슴이 가끔 따로 놀죠 .\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=========BEST Model===========\")\n",
    "random_evaluation(best_model, test_set, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "50c1f705-58e6-43f0-9abe-af87bf090cb1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1748844420214,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "50c1f705-58e6-43f0-9abe-af87bf090cb1",
    "outputId": "4299f8e7-900a-427b-8630-b9f420686c81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============Last Model=================\n",
      "질문: 짝사랑 해봤어 ?\n",
      "정답: 해봤어요 .\n",
      "예측: 있어도 예뻐요 .\n",
      "==================================================\n",
      "질문: 김치볶음밥 먹어야지\n",
      "정답: 맛있는 식사시간 되시길 바랄게요 .\n",
      "예측: 즐거운 시간 보내시길 바랍니다 .\n",
      "==================================================\n",
      "질문: 생각해주는 척만 한거였어\n",
      "정답: 뒤통수 맞았나봐요 .\n",
      "예측: 너무 늦지 않았을 거예요 .\n",
      "==================================================\n",
      "질문: 차 팔아서 불편해\n",
      "정답: 불편함을 조금 감수해보세요 .\n",
      "예측: 이별의 이유가 있을 테니까요 .\n",
      "==================================================\n",
      "질문: 사진 올려야지\n",
      "정답: 바쁘네요 .\n",
      "예측: 따뜻하게 관리하세요 .\n",
      "==================================================\n",
      "질문: 마음에 든다는 걸 어떻게 알릴 수 있어 ?\n",
      "정답: 자꾸 시선을 마주쳐보세요 .\n",
      "예측: 어떤 일이 있어도 보이지 않는 깊은 끈인 사랑이 둘을 이어줄 거예요 .\n",
      "==================================================\n",
      "질문: 2년만에 연락을 했습니다 .\n",
      "정답: 추억은 추억일 때 좋을 때도 있어요 .\n",
      "예측: 인연이 거기까지인가봐요 .\n",
      "==================================================\n",
      "질문: 너무 기빨려\n",
      "정답: 너무 긴장했나봐요 .\n",
      "예측: 여행을 떠나세요 .\n",
      "==================================================\n",
      "질문: 너가 없으면 못 살 줄 알았는데\n",
      "정답: 마음이 아플 뿐 살 수 있어요 .\n",
      "예측: 지금은 지나면 돌아오지 않아요 .\n",
      "==================================================\n",
      "질문: 개강이다\n",
      "정답: 곧 방학이예요 .\n",
      "예측: 기우제를 지내봅시다 !\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=============Last Model=================\")\n",
    "random_evaluation(last_model, test_set, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "476eae22-4c6a-4f55-8dd2-87f8dd1ba46d",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1748844420228,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "476eae22-4c6a-4f55-8dd2-87f8dd1ba46d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c4965d1-a305-4465-8f64-f689d55490ac",
   "metadata": {
    "id": "3c4965d1-a305-4465-8f64-f689d55490ac"
   },
   "source": [
    "# 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "827215a2-7bdb-44c5-b891-8ff15ae621f5",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1748844420239,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "827215a2-7bdb-44c5-b891-8ff15ae621f5"
   },
   "outputs": [],
   "source": [
    "class ChatbotInputDataset(Dataset):\n",
    "    \"\"\"\n",
    "    질문만 받아서 생성하는 Dataset\n",
    "    - 새로운 데이터 추론용. (섭)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, question_texts, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        parameter\n",
    "            question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "            max_length: 개별 문장의 token 개수. 모든 문장의 토큰수를 max_length에 맞춘다.\n",
    "            tokenizer: Tokenizer\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n",
    "\n",
    "    def __pad_token_sequence(self, token_sequence):\n",
    "        \"\"\"\n",
    "        max_length 길이에 맞춰 token_id 리스트를 구성한다.\n",
    "        max_length 보다 길면 뒤에를 자르고 max_length 보다 짧으면 [PAD] 토큰을 추가한다.\n",
    "\n",
    "        Parameter\n",
    "            token_sentence: list[int] - 길이를 맞출 한 문장 token_id 목록\n",
    "        Return\n",
    "            list[int] - length가 max_length인 token_id 목록\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('[PAD]')\n",
    "        seq_len = len(token_sequence) # 입력 문장의 토큰수\n",
    "        if seq_len > self.max_length: # 문장 최대 토큰수 보다 길다면.\n",
    "            return token_sequence[:self.max_length]\n",
    "        else:\n",
    "            return token_sequence + ([pad_token] * (self.max_length - seq_len))\n",
    "\n",
    "    def __process_sequence(self, text):\n",
    "        \"\"\"\n",
    "        한 문장(str)을 받아서 padding이 추가된 token_id 리스트로 변환 후 반환\n",
    "        Parameter\n",
    "            text: str - token_id 리스트로 변환할 한 문장\n",
    "        Return\n",
    "            list[int] - 입력받은 문장에 대한 token_id 리스트\n",
    "        \"\"\"\n",
    "        # encoding\n",
    "        encode = self.tokenizer.encode(text) # \"........\" => [. , . , .]\n",
    "        # max_length 크기에 맞춘다.\n",
    "        token_ids = self.__pad_token_sequence(encode.ids) #[3400, 20, 6, 0, 0, 0 ..]\n",
    "        return token_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.question_texts)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 질문만 반환.\n",
    "        q = self.question_texts[index]  # List\n",
    "\n",
    "        # List->LongTensor. nn.Embedding()의 입력(정수타입)으로 들어간다.\n",
    "        return torch.tensor(q, dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bb7661e1-c673-4e4b-85a5-df92d1b34e89",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1748844420261,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "bb7661e1-c673-4e4b-85a5-df92d1b34e89"
   },
   "outputs": [],
   "source": [
    "input_data = [\n",
    "    \"난 가족들과 주말에 여행갈 거야.\",\n",
    "    \"와! 내일 주말이다.\",\n",
    "    \"너무 피곤하네요. 좀 쉬었으면 좋겠어요.\",\n",
    "    \"지금 몇시에요.\",\n",
    "    \"여자 친구와 내일 저녁에 만나기로 했어.\"\n",
    "]\n",
    "input_dataset = ChatbotInputDataset(input_data, MAX_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4537cfe8-6bec-40d0-82ca-11aa6dbb90c3",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1748844420267,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "4537cfe8-6bec-40d0-82ca-11aa6dbb90c3"
   },
   "outputs": [],
   "source": [
    "def predict(dataset, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for X in dataset:  # Dataset에서 한 질문씩을 조회\n",
    "            X = X.to(device)\n",
    "            output = model(X.unsqueeze(0), X.unsqueeze(0), 0.0)\n",
    "            pred = output.cpu().numpy()\n",
    "            X = X.cpu().numpy()\n",
    "            q = handle_special_tokens(tokenizer.decode(X))\n",
    "            a = handle_special_tokens(tokenizer.decode(pred[0].argmax(-1)))\n",
    "            print(f\"질문: {q}\")\n",
    "            print(f\"예상답: {a}\")\n",
    "            print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb59d732-5a02-40b2-b70c-6ccaaa2cdd75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1748844420306,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "fb59d732-5a02-40b2-b70c-6ccaaa2cdd75",
    "outputId": "1878a915-0a5b-4e39-f3aa-4e3da71207e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 난 가족들과 주말에 여행갈 거야 .\n",
      "예상답: 인연이 거기까지인가봐요 .\n",
      "=========================================================\n",
      "질문: 와 ! 내일 주말이다 .\n",
      "예상답: 저도 즐거워요\n",
      "=========================================================\n",
      "질문: 너무 피곤하네요 . 좀 쉬었으면 좋겠어요 .\n",
      "예상답: 사랑은 끝나도 당신의 시간은 여전히 진행 중인 걸 잊지 마세요 .\n",
      "=========================================================\n",
      "질문: 지금 몇시에요 .\n",
      "예상답: 지금 많이 힘들겠어요 .\n",
      "=========================================================\n",
      "질문: 여자 친구와 내일 저녁에 만나기로 했어 .\n",
      "예상답: 그게 사랑의 증거가 되겠네요 .\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "predict(input_dataset, last_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7cc2920e-fcdb-47d3-a61d-14c61ddb6809",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1748844420334,
     "user": {
      "displayName": "남궁건우",
      "userId": "00560730431062529338"
     },
     "user_tz": -540
    },
    "id": "7cc2920e-fcdb-47d3-a61d-14c61ddb6809",
    "outputId": "19457d78-f395-49a3-a68c-8ee9636bc697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 난 가족들과 주말에 여행갈 거야 .\n",
      "예상답: 인연이 거기까지인가봐요 .\n",
      "=========================================================\n",
      "질문: 와 ! 내일 주말이다 .\n",
      "예상답: 저도 즐거워요\n",
      "=========================================================\n",
      "질문: 너무 피곤하네요 . 좀 쉬었으면 좋겠어요 .\n",
      "예상답: 사랑은 끝나도 당신의 시간은 여전히 진행 중인 걸 잊지 마세요 .\n",
      "=========================================================\n",
      "질문: 지금 몇시에요 .\n",
      "예상답: 지금 많이 힘들겠어요 .\n",
      "=========================================================\n",
      "질문: 여자 친구와 내일 저녁에 만나기로 했어 .\n",
      "예상답: 그게 사랑의 증거가 되겠네요 .\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "predict(input_dataset, last_model, device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
