{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa57c130",
   "metadata": {},
   "source": [
    "### import, device 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # 다양한 layer/모델 들이 정의된 패키지. (Neural Network)\n",
    "from torch.utils.data import DataLoader # DataLoader 클래스 -> 모델에 데이터들을 제공하는 역할.\n",
    "from torchvision import datasets, transforms \n",
    "# torchvision 패키지(라이브러리): pytorch의 영상 전용 sub package\n",
    "## datasets(모듈): Vision(영상)관련 공개 데이터셋들을 제공하는 모듈\n",
    "## transforms: 영상 데이터 전처리 기능들을 제공하는 모듈\n",
    "\n",
    "import matplotlib.pyplot as plt # 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca11af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 학습이 끝난 모델을 저장할 디렉토리.\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Dataset을 저장할 디렉토리\n",
    "dataset_dir = \"datasets/mnist\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어느 Device에서 연산처리를 할지 지정. (cpu, cuda(GPU))\n",
    "# device = \"cpu\"\n",
    "print(torch.cuda.is_available())  # cuda를 사용할 수있는 환경인지 조회\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # 2.0이전: torch.Device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd90c9",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터, 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25fdf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size 256, learn rate 0.001, epcohs = 20으로 설정\n",
    "batch_size = 256\n",
    "lr = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785e83fc",
   "metadata": {},
   "source": [
    "### MNIST dataset Loading\n",
    "\n",
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac9499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "#  transform=함수 -> input data를 전처리하는 함수를 전달.\n",
    "######################################################################################\n",
    "# transforms.ToTensor 가 하는 처리\n",
    "## ndarray, PIL.Image 객체를 torch.Tensor 로 변환.\n",
    "## (height, width, channel) 순서를 channel first (channel, height, width) 형태로 변환.\n",
    "## pixcel값들(0~255 정수)을 0 ~ 1 로 정규화. (Feature Scaling - MinMaxScaling)\n",
    "\n",
    "trainset = datasets.MNIST(\n",
    "    root=dataset_dir, \t\t\t# Dataset을 읽어올 디렉토리. 저장한 곳에서 읽어오면 됨\n",
    "    download=True,\t\t# root에 dataset이 없을 경우 다운로드 받을지 여부. T/F\n",
    "\ttrain=True,\t\t\t# Trainset인지 여부. True(default): train set, False: test set\t\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "testset = datasets.MNIST(\n",
    "    root=dataset_dir,\n",
    "    download=True,\n",
    "    train=False,      \n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d58e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러온 데이터 조회\n",
    "trainset, testset\n",
    "\n",
    "# 개별 데이터 조회 trainset[0], testset[0]\n",
    "trainset[0], testset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1385ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 위 trainsform 부분 주석 해제하여 데이터 다시 확인\n",
    "# 불러온 데이터 조회\n",
    "trainset,testset\n",
    "\n",
    "# 개별 데이터 조회 trainset[0], testset[0]\n",
    "trainset[0], testset[0]\n",
    "\n",
    "\n",
    "# shape, dtype/type(), min,max 확인 가능\n",
    "t0 = trainset[0][0]\n",
    "t0.shape, t0.dtype, t0.type(), t0.min(), t0.max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2692328a",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6135fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader: Dataset의 데이터들을 모델에 제공하는 역할. 데이터들을 모델에 어떻게 제공할지 설정해서 생성.\n",
    "# Dataset: 데이터들을 가지고 있는 역할. 하나씩 조회하는 기능을 제공.\n",
    "train_loader = DataLoader(\n",
    "    trainset,              \t# 어떤 Dataset을 제공할지\n",
    "    batch_size=batch_size, \t# batch size (256) 처음에 정해준 변수로\n",
    "    shuffle=True,   \t# 모델에 데이터를 제공하기 전에 섞을지 여부. (default: False) True: 한 epoch 학습 전에 섞는다.\n",
    "    drop_last=True, \t# 모델에 제공할 데이터의 개수가 batch_size보다 적으면 제공하지 않는다. (학습에 사용안함) T/F\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "\ttestset, \t\t\t\t\t# 어떤 Dataset을 제공할지\n",
    "\tbatch_size=batch_size\t\t# batch size(256) 처음에 정해준 변수로\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c264c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 data 개수 확인 가능 len(데이터셋) train, test\n",
    "len(trainset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f3cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 epoch 당 step 수 조회, drop last 유무 차이\n",
    "len(trainset) / batch_size, len(testset) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f125cd1",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eecd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subclass(상속) 방식\n",
    "## - nn.Module 상속한 클래스를 정의.\n",
    "## - __init__(): 입력값을 추론(순전파 연산)하는데 필요한 layer객체들을 생성.\n",
    "## - forward(): __init__() 에서 생성한 layer들을 이용해 연산 로직을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\t# 상위클래스 nn.Module 을 초기화해줘야함. super().__init__()\n",
    "\t\t\n",
    "        \n",
    "        # Linear(input feature 개수, output feature 개수)\n",
    "        ## input/output feature 개수는 지켜줘야하며, 그 사이 layer 개수를 정하는건 우리의 몫.\n",
    "        ### layer 4개로 하되 각 히든 layer의 출력 개수는 알아서\n",
    "        self.lr1 = nn.Linear(784, 128) # (784:(28*28): MNIST 이미지의 pixcel수, 출력: 128)\n",
    "        self.lr2 = nn.Linear(128, 64)\n",
    "        self.lr3 = nn.Linear(64, 32)\n",
    "        self.lr4 = nn.Linear(32, 10)   \t# (32: lr3의 출력개수, 출력: 10)\n",
    "        # 마지막 Linear()의 출력 개수(10) - 분류할 class개수(0 ~ 9)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X를 입력 받아서 y를 추론하는 계산로직을 정의\n",
    "        initializer에서 정의한 Linear들을 이용해서 계산.\n",
    "        Args:\n",
    "            X(torch.FloatTensor) - 추론할 MNIST 이미지들. shape: (batch_size, 1, 28, 28)\n",
    "        \"\"\"\n",
    "        # (batch_size, 1, 28, 28)를 (batch_size, 784) feature들을 1차원으로 변환.\n",
    "        X = torch.flatten(X, start_dim=1)\t# 다차원 배열을 1차원 배열로 변환. (start_dim=1, Flatten 시킬 시작 axis지정. 0축은 놔두고 1축 부터 flatten시킨다.)\n",
    "        \n",
    "        X = self.lr1(X)   \t# Linear: 선형 함수\n",
    "        X = nn.ReLU()(X)\t# Activation(활성)함수. ReLU : nn.ReLU()\n",
    "        \n",
    "        X = self.lr2(X)\n",
    "        X = nn.ReLU()(X)\n",
    "        \n",
    "        X = self.lr3(X)\n",
    "        X = nn.ReLU()(X)\n",
    "        \n",
    "        output = self.lr4(X)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35c190a",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0c1ff",
   "metadata": {},
   "source": [
    "#### 모델, loss function, optimizer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3685061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델객체 생성\n",
    "model = MNISTModel()\n",
    "# 확인\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcccbf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss함수 정의\n",
    "## 다중 분류: crossentropyloss -> nn.CrossEntropyLoss()\n",
    "## 이진 분류: Binary CrossEntropy\n",
    "## 회귀: mse\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a3a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer 정의 torch.optim.Adam(model.parameters(), lr)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347baeb0",
   "metadata": {},
   "source": [
    "#### 학습(훈련-train) 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab5c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시 계산에 사용되는 값들은 같은 device(cpu or cuda or mps)에 있어야 한다\n",
    "## device로 이동할 대상: Model객체, X(input), y(output)\n",
    "\n",
    "model = MNISTModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# 학습\n",
    "## 에폭별 검증결과들을 저장할 리스트, 시각화를 위함함\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "valid_acc_list = []\n",
    "s = time.time() # 학습 시간 측정을 위한.\n",
    "\n",
    "# 학습-중첩 반복문: epoch 반복 -> step(batch_size) 에 대한 반복\n",
    "# for epoch in range(epochs)\n",
    "for epoch in range(epochs):\n",
    "    ###############################################\n",
    "    # 모델 Train - 1 epoch : Trainset\n",
    "    ###############################################\n",
    "    \n",
    "    model.train()\t# 모델을 train 모드로 변환 -> 모델명.train()\n",
    "    train_loss = 0 # 현재 epoch의 train loss를 저장할 변수.\n",
    "\n",
    "    # batch 단위로 학습: 1 step - 1개 batch의 데이터로 학습.\n",
    "    for X_train, y_train in train_loader: # loader에서 data 가져오기\n",
    "        # 1. data를 devcie로 이동\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        # 2. 모델을 이용해 추론\n",
    "        pred = model(X_train)\t # Model.forward(X_train) 메소드 호출\n",
    "        # 3. 검증 -> loss 계산\n",
    "        loss = loss_fn(pred, y_train)\n",
    "        # 4. gradient 계산 \n",
    "        loss.backward()\n",
    "        # 5. 모델의 파라미터들(weight, bias) update\n",
    "        optimizer.step()\n",
    "        # 6. gradient 초기화\n",
    "        optimizer.zero_grad\n",
    "        # 학습 결과 저장및 출력을 위해 loss 저장.\n",
    "        train_loss += loss.item() \n",
    "\n",
    "    \n",
    "    train_loss = train_loss / len(train_loader)\t\t# 한 에폭에서 학습한 step별 loss의 평균계산.\n",
    "    train_loss_list.append(train_loss) \t\t\t\t# 리스트에 저장\n",
    "    \n",
    "    ###############################################\n",
    "    # 1 epoch 학습한 결과 검증: Testset\n",
    "    ###############################################\n",
    "      # 모델을 evaluation() (추론, 검증) 모드로 변환 -> 모델명.eval()\n",
    "    valid_loss = 0\n",
    "    valid_acc = 0\n",
    "    with torch.no_grad(): # 추론만 함 -> gradient 계산할 필요 없음. -> grad_fn 구할 필요없다.\n",
    "        for X_valid, y_valid in test_loader:\t# loader에서 data 가져오기\n",
    "            # 1. data를 device로 이동\n",
    "            X_valid, y_valid = X_valid.to(device), y_valid.to(device)\n",
    "            # 2. 추론\n",
    "            pred_valid = model(X_valid)\n",
    "            # 3-1. 검증 -> loss 계산\n",
    "            valid_loss += loss_fn(pred_valid, y_valid).item()\n",
    "            # 3-2. 검증 -> accuracy 계산\n",
    "            ## pred_valid shape: (256, 10: class별 확률) -> 정답 class 추출\n",
    "            pred_valid_class = pred_valid.argmax(dim=-1)\n",
    "            valid_acc += torch.sum(y_valid == pred_valid_class).item()\n",
    "            \n",
    "        \n",
    "        # 검증결과 누적값의 평균\n",
    "        valid_loss = valid_loss / len(test_loader)  # loss는 step수 나눔.\n",
    "        valid_acc = valid_acc / len(testset)        # accuracy는 데이터 개수로 나눔.\n",
    "        valid_loss_list.append(valid_loss) \t\t\t# list에 저장\n",
    "        valid_acc_list.append(valid_acc)\t\t\t# list에 저장\n",
    "\n",
    "        # 검증 결과 출력\n",
    "        print(f\"[{epoch+1:02d}/{epochs}] train_loss: {train_loss}, valid_loss: {valid_loss}, valid_acc: {valid_acc}\")\n",
    "\n",
    "e = time.time()\n",
    "print('학습에 걸린 시간(초):', e-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7212f998",
   "metadata": {},
   "source": [
    "#### 학습 로그 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5de75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loss, valid loss, valid acc 를 epoch 별로 어떻게 변하는지 시각화.\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), train_loss_list, label=\"train loss\")\n",
    "plt.plot(range(1, epochs+1), valid_loss_list, label=\"valid loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\":\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs+1), valid_acc_list)\n",
    "plt.title(\"valid accuracy\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(True, linestyle=\":\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e8bc7",
   "metadata": {},
   "source": [
    "### 모델 성능 최종 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639da5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # 평가모드\n",
    "\n",
    "test_loss = test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for X_test, y_test in test_loader:\n",
    "        # 1. device 이동\n",
    "        X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "        # X_test = X_test.view(X_test.size(0), -1)  # (batch_size, 784)\n",
    "        \n",
    "\t\t# 추론\n",
    "        pred_test = model(X_test)\n",
    "        # 검증 - loss\n",
    "        loss_test = loss_fn(pred_test, y_test)\n",
    "        test_loss += loss_test.item()\n",
    "        # 검증 - accuracy\n",
    "        ## class\n",
    "        pred_test_class = pred_test.argmax(dim=-1)\n",
    "        test_acc += torch.sum(pred_test_class == y_test).item()\n",
    "\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_acc = test_acc / len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c4f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인\n",
    "test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2fdf74",
   "metadata": {},
   "source": [
    "## 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520bc926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_data(device=\"cpu\", *path):\n",
    "    \"\"\"\n",
    "    받은 경로의 이미지들을 읽어서 Tensor로 변환해 반환한다.\n",
    "\n",
    "    1. 전달받은 경로의 이미지 파일들을 읽는다.\n",
    "    2. 28 x 28 로 resize\n",
    "    3. torch.Tensor로 변환 + 전처리\n",
    "    4. devcie로 이동시킨 뒤 반환한다다.\n",
    "    \"\"\"\n",
    "    input_tensors = []\n",
    "    for p in path:\n",
    "        img = Image.open(p)\t\t# 이미지 열어서\n",
    "        # 전처리\n",
    "        img = img.convert(\"L\")\t# grayscale로 변환 -> .convert(\"L\")\n",
    "        img = img.resize((28, 28))\t# 모델이 학습한 데이터 size(28, 28)로 변환 -> .resize((28, 28))\n",
    "        img = transforms.ToTensor()(img)\n",
    "        input_tensors.append(img)\n",
    "        \n",
    "    return torch.stack(input_tensors).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf9efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, inputs, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    받은 model에 inputs를 추론하여 그 결과 class들을 반환한다.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        pred = model(inputs)\n",
    "        pred_class = pred.argmax(dim=-1)\n",
    "        return pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826247cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob을 이용해 테스트 이미지들의 경로 조회.\n",
    "from glob import glob\n",
    "file_list = glob(\"test_img/**/*.png\") # 경로 조회해서 저장\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d617090",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = load_data(device, *file_list)\n",
    "result_pred = predict(model, r)\n",
    "result_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7384f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for idx, (path, label) in enumerate(zip(file_list, result_pred)):\n",
    "    # print(idx, path, label, sep=\" , \")\n",
    "    img = Image.open(path).convert('L')\n",
    "    plt.subplot(3, 5, idx+1)  #3, 4\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(f\"예측결과: {label}\") # Label\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
