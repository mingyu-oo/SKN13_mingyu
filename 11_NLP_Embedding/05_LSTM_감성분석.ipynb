{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e93c9500-6e1f-445a-a5e1-95e687853ae8",
   "metadata": {},
   "source": [
    "# Pytorch의 nn.Embedding\n",
    "- Pytorch의 Embedding Layer는 word2vec과 마찬가지로 word embedding vector를 찾는 **Lookup Table**이다.\n",
    "\t- 단어의 **정수의 고유 index**가 입력으로 들어오면 Embedding Layer의 **그 index의 Vector**를 출력한다.\n",
    "\t- 모델이 학습되는 동안 모델이 풀려는 문제에 맞는 값으로 Embedding Layer의 vector들이 업데이트 된다.\n",
    "\t- Word2Vec의 embedding vector 학습을 nn.Embedding은 자신이 포함된 모델을 학습 하는 과정에서 한다고 생각하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d936d8f7-a203-4452-978f-e2da81b7dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "embed = nn.Embedding(\n",
    "\tnum_embeddings=20_000,\t# vocab size (단어 사전의 단어 수) -> 총 몇개의 단어에 대한 embedding vector를 만들지 정해줌.\n",
    "\tembedding_dim=200,\t\t# embedding vector의 차원수 -> 개별 단어를 몇개의 숫자(feature)로 표현할지.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012e02bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.8652,  0.6973,  0.1999,  ..., -1.8689,  1.1053,  1.0524],\n",
       "         [ 0.4214,  1.5906,  2.4268,  ..., -1.5277, -0.4195,  1.5656],\n",
       "         [-0.3205, -1.0690, -0.8875,  ..., -0.7581,  0.6987,  0.5288],\n",
       "         ...,\n",
       "         [-1.5700,  0.0495, -0.9778,  ..., -0.5380,  0.1932, -1.2541],\n",
       "         [ 0.4305,  0.1151,  1.5855,  ...,  1.9080,  1.0701,  1.0204],\n",
       "         [-0.2333,  1.3051, -0.6628,  ...,  0.0135,  0.4299,  1.8202]],\n",
       "        requires_grad=True),\n",
       " torch.Size([20000, 200]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.weight, embed.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52bdea82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 200])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding layer의 입력 : 문서를 구성하는 토큰들의 ID(int)를 1차원으로 묶어서 전달.\n",
    "\n",
    "# doc = 나는:30|어제:159|밥을:9000|먹었다:326\n",
    "doc = torch.tensor([[30, 158, 9000, 326],[30, 158, 9000, 326],[30, 158, 9000, 326]], dtype=torch.int64)\n",
    "embedding_vector = embed(doc)\n",
    "embedding_vector.shape\n",
    "\n",
    "# [3 : batch_size, 4 : seq_len, 200 : embedding vector 차원 수]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d166e4e-4ced-4bc8-a188-12358670ad0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.1111e-02, -3.2251e-01,  1.0367e+00, -6.6960e-01, -9.6189e-02,\n",
       "        -7.8548e-01, -8.9844e-02, -4.4401e-01,  1.3574e-01, -8.2693e-01,\n",
       "        -1.3005e+00,  4.5376e-01, -5.3921e-01, -8.7179e-01, -8.3617e-01,\n",
       "        -3.5244e-01,  8.8662e-01,  5.1787e-01,  3.3162e-02,  5.7949e-01,\n",
       "         2.0685e-01, -1.1890e+00, -1.4537e+00, -1.1405e+00, -8.0124e-01,\n",
       "        -1.1817e+00,  6.6721e-02,  8.0959e-01,  6.5952e-01, -5.0228e-01,\n",
       "         2.2821e-01,  1.6650e-01,  9.6609e-01, -2.4068e-01,  4.2423e-01,\n",
       "        -3.2666e+00,  2.3355e-01, -2.4706e+00, -3.0557e-01, -1.1308e-01,\n",
       "         6.4986e-01,  9.3035e-01, -1.0062e+00,  2.9876e-01,  1.3428e+00,\n",
       "        -4.2823e-01,  1.2848e-01, -1.2570e+00,  7.9725e-01,  1.1032e+00,\n",
       "        -1.1993e+00,  1.4715e-01, -7.9963e-01,  6.6790e-01, -2.3556e+00,\n",
       "         1.4985e-01,  6.0300e-01, -2.4361e-02,  9.2386e-01, -8.4580e-01,\n",
       "         2.4365e-01, -3.1137e-03, -5.1895e-01, -1.2429e+00,  5.2201e-01,\n",
       "         1.2245e+00,  1.6630e+00,  1.0768e+00,  8.1425e-01,  9.9975e-03,\n",
       "         4.3619e-01, -8.5890e-01, -5.1491e-01,  6.4605e-01,  1.4743e+00,\n",
       "         1.8278e+00,  3.1196e-01, -6.8882e-01,  5.3144e-01,  4.6533e-01,\n",
       "        -1.2450e-01, -3.0512e+00, -5.9073e-01, -2.6607e-02, -1.1157e+00,\n",
       "        -1.0920e-01,  1.8721e-02,  1.2610e+00,  6.2122e-01,  1.4086e+00,\n",
       "        -8.5595e-01,  8.5629e-01, -8.1727e-01, -7.3503e-01,  9.2137e-01,\n",
       "         5.9988e-01, -1.4577e+00,  2.0778e-01,  4.9362e-01,  2.6582e-02,\n",
       "        -2.3193e-01, -5.3779e-01, -9.0940e-01,  4.6607e-01,  8.6353e-01,\n",
       "         7.6824e-01, -8.2855e-01, -4.2398e-01, -1.3179e-01,  1.1079e+00,\n",
       "        -1.6372e+00, -5.2177e-01,  9.4794e-01, -2.1813e-01,  1.0913e+00,\n",
       "        -3.4497e-01, -7.5225e-01,  9.6831e-01,  4.7493e-02, -1.0779e-01,\n",
       "        -1.3196e-01, -7.2755e-01, -1.2782e-01,  3.8692e-01,  1.3879e-01,\n",
       "         1.7775e+00, -3.8903e-01,  9.3909e-01, -2.2779e-01,  4.2177e-01,\n",
       "         5.8571e-01,  1.7949e+00, -9.3845e-01,  1.0224e+00,  1.9027e+00,\n",
       "         1.0940e+00,  2.3340e-01, -1.1444e+00,  1.6478e+00,  3.6680e-01,\n",
       "        -1.7313e+00,  1.3657e+00,  1.7284e-01,  4.0805e-01,  1.8527e+00,\n",
       "        -1.6679e-01, -5.5846e-01,  2.1709e+00,  5.1654e-01,  1.6850e+00,\n",
       "         2.0079e-01, -3.4222e-02, -1.5143e-01,  1.7325e-01, -3.7598e-02,\n",
       "         5.6830e-01, -1.3157e+00, -1.3169e+00, -9.8095e-02,  6.1580e-01,\n",
       "        -8.5636e-01,  1.2988e+00, -1.6877e+00,  6.4031e-01, -1.6754e+00,\n",
       "         6.0722e-01,  2.9086e-01, -1.2517e-01, -2.1544e-01, -1.1139e+00,\n",
       "        -1.0332e+00, -9.3198e-01, -2.9943e-02, -1.1637e-01, -1.4502e+00,\n",
       "        -2.1621e+00, -1.0333e+00,  7.7195e-01,  3.4888e-02, -3.8340e-01,\n",
       "        -4.0793e-01,  6.3002e-02, -1.0786e+00, -4.1447e-01,  2.4465e-01,\n",
       "         1.4985e+00, -6.8979e-01, -2.2166e-01, -5.6899e-01, -1.0841e+00,\n",
       "         1.1767e+00,  8.8993e-01, -1.4515e+00, -8.0214e-01, -3.5693e-02,\n",
       "        -1.5695e-01,  1.2029e+00, -8.4327e-02,  1.0413e+00, -1.0906e+00],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91026ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.1111e-02, -3.2251e-01,  1.0367e+00, -6.6960e-01, -9.6189e-02,\n",
       "        -7.8548e-01, -8.9844e-02, -4.4401e-01,  1.3574e-01, -8.2693e-01,\n",
       "        -1.3005e+00,  4.5376e-01, -5.3921e-01, -8.7179e-01, -8.3617e-01,\n",
       "        -3.5244e-01,  8.8662e-01,  5.1787e-01,  3.3162e-02,  5.7949e-01,\n",
       "         2.0685e-01, -1.1890e+00, -1.4537e+00, -1.1405e+00, -8.0124e-01,\n",
       "        -1.1817e+00,  6.6721e-02,  8.0959e-01,  6.5952e-01, -5.0228e-01,\n",
       "         2.2821e-01,  1.6650e-01,  9.6609e-01, -2.4068e-01,  4.2423e-01,\n",
       "        -3.2666e+00,  2.3355e-01, -2.4706e+00, -3.0557e-01, -1.1308e-01,\n",
       "         6.4986e-01,  9.3035e-01, -1.0062e+00,  2.9876e-01,  1.3428e+00,\n",
       "        -4.2823e-01,  1.2848e-01, -1.2570e+00,  7.9725e-01,  1.1032e+00,\n",
       "        -1.1993e+00,  1.4715e-01, -7.9963e-01,  6.6790e-01, -2.3556e+00,\n",
       "         1.4985e-01,  6.0300e-01, -2.4361e-02,  9.2386e-01, -8.4580e-01,\n",
       "         2.4365e-01, -3.1137e-03, -5.1895e-01, -1.2429e+00,  5.2201e-01,\n",
       "         1.2245e+00,  1.6630e+00,  1.0768e+00,  8.1425e-01,  9.9975e-03,\n",
       "         4.3619e-01, -8.5890e-01, -5.1491e-01,  6.4605e-01,  1.4743e+00,\n",
       "         1.8278e+00,  3.1196e-01, -6.8882e-01,  5.3144e-01,  4.6533e-01,\n",
       "        -1.2450e-01, -3.0512e+00, -5.9073e-01, -2.6607e-02, -1.1157e+00,\n",
       "        -1.0920e-01,  1.8721e-02,  1.2610e+00,  6.2122e-01,  1.4086e+00,\n",
       "        -8.5595e-01,  8.5629e-01, -8.1727e-01, -7.3503e-01,  9.2137e-01,\n",
       "         5.9988e-01, -1.4577e+00,  2.0778e-01,  4.9362e-01,  2.6582e-02,\n",
       "        -2.3193e-01, -5.3779e-01, -9.0940e-01,  4.6607e-01,  8.6353e-01,\n",
       "         7.6824e-01, -8.2855e-01, -4.2398e-01, -1.3179e-01,  1.1079e+00,\n",
       "        -1.6372e+00, -5.2177e-01,  9.4794e-01, -2.1813e-01,  1.0913e+00,\n",
       "        -3.4497e-01, -7.5225e-01,  9.6831e-01,  4.7493e-02, -1.0779e-01,\n",
       "        -1.3196e-01, -7.2755e-01, -1.2782e-01,  3.8692e-01,  1.3879e-01,\n",
       "         1.7775e+00, -3.8903e-01,  9.3909e-01, -2.2779e-01,  4.2177e-01,\n",
       "         5.8571e-01,  1.7949e+00, -9.3845e-01,  1.0224e+00,  1.9027e+00,\n",
       "         1.0940e+00,  2.3340e-01, -1.1444e+00,  1.6478e+00,  3.6680e-01,\n",
       "        -1.7313e+00,  1.3657e+00,  1.7284e-01,  4.0805e-01,  1.8527e+00,\n",
       "        -1.6679e-01, -5.5846e-01,  2.1709e+00,  5.1654e-01,  1.6850e+00,\n",
       "         2.0079e-01, -3.4222e-02, -1.5143e-01,  1.7325e-01, -3.7598e-02,\n",
       "         5.6830e-01, -1.3157e+00, -1.3169e+00, -9.8095e-02,  6.1580e-01,\n",
       "        -8.5636e-01,  1.2988e+00, -1.6877e+00,  6.4031e-01, -1.6754e+00,\n",
       "         6.0722e-01,  2.9086e-01, -1.2517e-01, -2.1544e-01, -1.1139e+00,\n",
       "        -1.0332e+00, -9.3198e-01, -2.9943e-02, -1.1637e-01, -1.4502e+00,\n",
       "        -2.1621e+00, -1.0333e+00,  7.7195e-01,  3.4888e-02, -3.8340e-01,\n",
       "        -4.0793e-01,  6.3002e-02, -1.0786e+00, -4.1447e-01,  2.4465e-01,\n",
       "         1.4985e+00, -6.8979e-01, -2.2166e-01, -5.6899e-01, -1.0841e+00,\n",
       "         1.1767e+00,  8.8993e-01, -1.4515e+00, -8.0214e-01, -3.5693e-02,\n",
       "        -1.5695e-01,  1.2029e+00, -8.4327e-02,  1.0413e+00, -1.0906e+00],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.weight[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "579e9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab 어휘수 : 10개\n",
    "# embedding 벡터 차원수 : 3차원\n",
    "e_layer = nn.Embedding(\n",
    "\tnum_embeddings=10,\n",
    "\tembedding_dim=3,\n",
    ")\n",
    "# 10 * 3 weight 행렬을 생성 -> weight행렬이 전체 어휘들의 embedding vector들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d0b0ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.7583,  0.2622,  1.6925],\n",
       "        [-1.6025,  0.4800, -0.5736],\n",
       "        [ 0.7111, -1.4486, -0.3556],\n",
       "        [-0.4629,  0.2024,  0.8159],\n",
       "        [-0.6671, -0.4670, -1.3596],\n",
       "        [-0.3433,  1.1882,  1.8781],\n",
       "        [-0.5411, -0.2524, -0.9759],\n",
       "        [ 2.8304, -0.0191, -1.4261],\n",
       "        [ 0.3303, -1.3010, -0.9626],\n",
       "        [-0.0734, -1.9948,  0.3436]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "014c75a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7583,  0.2622,  1.6925],\n",
       "        [-0.6671, -0.4670, -1.3596],\n",
       "        [ 0.7111, -1.4486, -0.3556]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"오늘 날씨 좋다\"\t\t# [\"오늘\": 0, \"날씨\":4, \"좋다\":2]\n",
    "# token = tokenizer.encode(sent).ids\n",
    "token = torch.tensor([0, 4, 2], dtype=torch.int64)\n",
    "e_layer(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca59e731-381d-4a79-83c4-1fc20ba006e1",
   "metadata": {},
   "source": [
    "# 네이버 영화 댓글 감성분석(Sentiment Analysis)\n",
    "\n",
    "## 감성분석(Sentiment Analysis) 이란\n",
    "입력된 텍스트가 **긍적적인 글**인지 **부정적인**인지 또는 **중립적인** 글인지 분석하는 것을 감성(감정) 분석이라고 한다.   \n",
    "이를 통해 기업이 고객이 자신들의 기업 또는 제품에 대해 어떤 의견을 가지고 있는지 분석한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7034ada-08b9-4163-b18d-ce429aef275b",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader 생성\n",
    "\n",
    "## Korpora에서 Naver 영화 댓글 dataset 가져오기\n",
    "- https://ko-nlp.github.io/Korpora/ko-docs/corpuslist/nsmc.html\n",
    "- http://github.com/e9t/nsmc/\n",
    "\t- input: 영화댓글\n",
    "\t- output: 0(부정적댓글), 1(긍정적댓글)\n",
    "### API\n",
    "- **corpus 가져오기**\n",
    "\t- `Korpora.load('nsmc')`\n",
    "- **text/label 조회**\n",
    "\t- `corpus.get_all_texts()` : 전체 corpus의 text들을 tuple로 반환\n",
    "\t- `corpus.get_all_labels()`: 전체 corpus의 label들을 list로 반환\n",
    "- **train/test set 나눠서 조회**\n",
    "\t- `corpus.train`\n",
    "\t- `corpus.test`\n",
    "\t- `LabeledSentenceKorpusData` 객체에 text와 label들을 담아서 제공.\n",
    "\t\t- `LabeledSentenceKorpusData.texts`: text들 tuple로 반환.\n",
    "\t\t- `LabeledSentenceKorpusData.labels`: label들 list로 반환."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0e2ea3-6123-4ebd-8e98-27b1db6406ed",
   "metadata": {},
   "source": [
    "## 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aebdb0ac-eaaa-47aa-a0de-11d49e8a427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : e9t@github\n",
      "    Repository : https://github.com/e9t/nsmc\n",
      "    References : www.lucypark.kr/docs/2015-pyconkr/#39\n",
      "\n",
      "    Naver sentiment movie corpus v1.0\n",
      "    This is a movie review dataset in the Korean language.\n",
      "    Reviews were scraped from Naver Movies.\n",
      "\n",
      "    The dataset construction is based on the method noted in\n",
      "    [Large movie review dataset][^1] from Maas et al., 2011.\n",
      "\n",
      "    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n",
      "\n",
      "    # License\n",
      "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
      "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
      "\n",
      "[Korpora] Corpus `nsmc` is already installed at C:\\Users\\Playdata\\Korpora\\nsmc\\ratings_train.txt\n",
      "[Korpora] Corpus `nsmc` is already installed at C:\\Users\\Playdata\\Korpora\\nsmc\\ratings_test.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from Korpora import Korpora\n",
    "\n",
    "corpus = Korpora.load(\"nsmc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f284ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = corpus.get_all_texts()\t\t# inputs : 댓글들 전체\n",
    "all_labels = corpus.get_all_labels()\t# outputs : labels 전체 - 0 : 부정, 1 : 긍정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c08b08d5-bfcd-4430-b4c0-44b19bbf4022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('아 더빙.. 진짜 짜증나네요 목소리',\n",
       " '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나',\n",
       " '너무재밓었다그래서보는것을추천한다',\n",
       " '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정',\n",
       " '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70552ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "659d4613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97546f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('아 더빙.. 진짜 짜증나네요 목소리',\n",
       " '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나',\n",
       " '너무재밓었다그래서보는것을추천한다',\n",
       " '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정',\n",
       " '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train.texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feca9158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train.labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "232a23c0-06c5-49b7-b601-1ede1198b4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('굳 ㅋ',\n",
       " 'GDNTOPCLASSINTHECLUB',\n",
       " '뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아',\n",
       " '지루하지는 않은데 완전 막장임... 돈주고 보기에는....',\n",
       " '3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.test.texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a41920ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.test.labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e7e54a-548d-4bf3-81aa-357ab249f41a",
   "metadata": {},
   "source": [
    "## 토큰화\n",
    "1. 형태소 단위 token화(분절)를 먼저 한다.\n",
    "\t- konlpy로 token화 한 뒤 다시 한 문장으로 만든다.\n",
    "2. 1에서 처리한 corpus를 BPE 로 token화\n",
    "   \n",
    "### 전처리 함수\n",
    "\n",
    "#### 형태소 단위 분절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0bbb39b-9f49-4d29-a969-4839c01f430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "okt = Okt()\n",
    "# 전처리 = cleaning + 정규화(normalize)\n",
    "def text_preprocessing(text):\n",
    "\t\"\"\"\n",
    "\t1. 영문 -> 소문자로 변환\n",
    "\t2. 구두점 제거\n",
    "\t3. 형태소 기반 토큰화\n",
    "\t4. 형태소로 토큰화 한 뒤 다시 하나의 문자열로 묶어서 반환.\n",
    "\t\"\"\"\n",
    "\ttext = text.lower()\t\t# 소문자로 통일해서 대소문자가 달라서 다른 토큰으로 구분되는 것을 방지\n",
    "\t# 구두점 제거 (stop word(불용어))\n",
    "\ttext = re.sub(f\"[{string.punctuation}]\", \" \", text)\n",
    "\t# 정규화\n",
    "\ttokens = okt.morphs(text, stem = True)\t# stem : 원형 복원\n",
    "\treturn ' '.join(tokens)\t\t# [\"단어\", \"단어\", ...] -> str \"단어 단어 단어\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35f45e2f-f76a-4011-b963-d7feb214cc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"[{string.punctuation}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79dd3b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "재미없음 진심 1이훨나 캐스팅두못한듯\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'재미없다 진심 1 이훨 나 캐스팅 두 못 한 듯'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_inputs[101])\n",
    "text_preprocessing(all_inputs[101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc5a94d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 걸린 시간(초) :  406.7154109477997\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "# train set 전처리\n",
    "train_texts = corpus.train.texts\n",
    "train_inputs = [text_preprocessing(txt) for txt in train_texts]\n",
    "train_labels = corpus.train.labels\n",
    "\n",
    "# test set 전처리\n",
    "test_texts = corpus.test.texts\n",
    "test_inputs = [text_preprocessing(txt) for txt in test_texts]\n",
    "test_labels = corpus.test.labels\n",
    "e = time.time()\n",
    "\n",
    "print(\"전처리 걸린 시간(초) : \", e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3760a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe7961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"datasets/nsmc\", exist_ok=True)\n",
    "with open(\"datasets/nsmc/preprocessing_trainset.pkl\", \"wb\") as fw:\n",
    "\tpickle.dump({\"input\":train_inputs, \"output\":train_labels},fw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e658962-2fd6-4b1d-b4ef-a38de3ecc847",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/nsmc/preprocessing_testset.pkl\", \"wb\") as fw:\n",
    "\tpickle.dump({\"input\":test_inputs, \"output\":test_labels},fw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7ae7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 저장한 전처리한 dataset 읽어오기\n",
    "with open(\"datasets/nsmc/preprocessing_trainset.pkl\", \"rb\") as fr:\n",
    "\ttrain_dict = pickle.load(fr)\n",
    "\n",
    "with open(\"datasets/nsmc/preprocessing_testset.pkl\", \"rb\") as fr:\n",
    "\ttest_dict = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8134cfa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 150000, 50000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs = train_dict[\"input\"]\n",
    "train_labels = train_dict[\"output\"]\n",
    "test_inputs = test_dict[\"input\"]\n",
    "test_labels = test_dict[\"output\"]\n",
    "\n",
    "all_inputs = train_inputs + test_inputs\t\t# vocab 만들 때 사용\n",
    "\n",
    "len(all_inputs), len(train_inputs), len(test_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e519a68-d3a0-4481-bcf7-b121d8ba813f",
   "metadata": {},
   "source": [
    "### 토큰화\n",
    "- Subword 방식 토큰화 적용\n",
    "- Byte Pair Encoding 방식으로 huggingface tokenizer 사용\n",
    "\t- BPE: 토큰을 글자 단위로 나눈뒤 가장 자주 등장하는 글자 쌍(byte paire)를 찾아 합친뒤 어휘사전에 추가한다.\n",
    "\t- https://huggingface.co/docs/tokenizers/quicktour\n",
    "\t- `pip install tokenizers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f162bdf-fac9-4468-a264-c656e4b3164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE, Unigram, WordPiece\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a2a123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 30_000\t\t# vocab의 최대 단어 수\n",
    "min_frequency = 5\t\t# 사전에 추가할 최소 빈도수\n",
    "tokenizer = Tokenizer(\n",
    "\tBPE(unk_token=\"[UNK]\")\n",
    ")\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(\n",
    "\tvocab_size=vocab_size,\n",
    "\tmin_frequency=min_frequency,\n",
    "\tspecial_tokens=[\"[UNK]\", \"[PAD]\"],\n",
    "\tcontinuing_subword_prefix=\"##\"\n",
    "\t# 단어의 중간에 나오는 subword일 경우 앞에 ## 붙여주기\n",
    "\t# \"시작하는\" -> \"시작\", \"하는\" => \"시작\",\"##하는\"\n",
    ")\n",
    "tokenizer.train_from_iterator(all_inputs, trainer=trainer)\t# vocab 생성 == tokenizer학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "766c0a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26739"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 총 vocab size:\n",
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de9b29e1-384a-44e8-ab19-e53f0c1303c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "os.makedirs(\"saved_models/nsmc\", exist_ok=True)\n",
    "tokenizer.save(\"saved_models/nsmc/tokenizer_bpe.json\")\n",
    "\n",
    "# load_tokenizer = Tokenizer.from_file(\"saved_models/nsmc/tokenizer_bpe.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e998d38b-e762-4fd5-b37f-8f8a2b6f5849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "명작 을 기억 하다 이렇다 드라마 가 또 다시 나오다 있다\n",
      "[5530, 2190, 5548, 5411, 5455, 5448, 506, 1152, 5486, 5440, 5415]\n",
      "['명작', '을', '기억', '하다', '이렇다', '드라마', '가', '또', '다시', '나오다', '있다']\n"
     ]
    }
   ],
   "source": [
    "idx = 11290\n",
    "print(all_inputs[idx])\n",
    "tokens = tokenizer.encode(all_inputs[idx])\n",
    "print(tokens.ids)\n",
    "print(tokens.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1c9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cea835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = tokenizer.encode(\"pytorch와 pandas와 numpy는 python 라이버러리입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "668b1def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'명작 을 기억 하다 이렇다 드라마 가 또 다시 나오다 있다'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f5c31d-633c-4a31-8f66-dff2ecf8e86a",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35cd4797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1986, 5881, 5426, 5667, 6087], 0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dset[0]\n",
    "tokenizer.encode(train_inputs[0]).ids, train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab3b2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch 사용자 정의 Dataset(custom dataset) def\n",
    "# 1. Dataset 상속\n",
    "# 2. __len__(self) : 총 data 개수 반환\n",
    "# 3. __getitem()__(self, index) : index의 x,y를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8cc3397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1986, 5881, 5426, 5667, 6087],\n",
       " [3034, 5891, 5453, 6036, 5408, 2339, 6775, 5434, 6276, 6134, 5435],\n",
       " [839, 8408, 1478, 3215, 11369, 13191, 5410, 5634, 2889, 950],\n",
       " [12557, 5519, 16063, 5633, 5418, 923, 5412, 5441, 8922]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_labels\n",
    "[tokenizer.encode(txt).ids for txt in train_inputs[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "245f5c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tokenizer.token_to_id(self, token)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.token_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff27280e-dfb7-4947-9192-777e6984286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NSMCDataset(Dataset):\n",
    "\tdef __init__(self, texts, labels, max_length, tokenizer):\n",
    "\t\t\"\"\"\n",
    "\t\ttexts: list - 댓글 목록. 리스트에 댓글들을 담아서 받는다. [\"댓글\", \"댓글\", ...]\n",
    "\t\tlabels: list - 댓글 감정 목록. \n",
    "\t\tmax_length: 개별 댓글의 최대 token 개수. 모든 댓글의 토큰수를 max_length에 맞춘다.(Sequence 개수를 맞춘다)\n",
    "\t\ttokenizer: Tokenizer\n",
    "\t\t\"\"\"\n",
    "\t\tself.max_length = max_length\n",
    "\t\tself.tokenizer = tokenizer\n",
    "\t\tself.labels = labels\n",
    "\t\t# self.texts : 입력 댓글 - token id로 변환된 댓글(문서), 글자 수는 max_length에 맞춤\n",
    "\t\t#\t\t\t   max_length 보다 적으면 [PAD] 추가, max_length보다 많으면 잘라냄\n",
    "\t\tself.texts = [self.__pad_token_sequences(tokenizer.encode(txt).ids) for txt in texts]\n",
    "\n",
    "\t###########################################################################################\n",
    "\t# id로 구성된 개별 문장 tokenizer list를 받아서 패딩 추가 [20, 2, 1] => [20, 2, 1, 0, 0, 0, ..]\n",
    "\t# max_length에 token list의 개수를 맞춰주는 func\n",
    "\t############################################################################################\n",
    "\tdef __pad_token_sequences(self, token_sequences):\n",
    "\t\t\"\"\"\n",
    "\t\tid로 구성된 개별 문서(댓글)의 token_id list를 받아서 max_length 길이에 맞추는 메소드\n",
    "\t\tmax_length 보다 토큰수가 적으면 [PAD] 추가, 많으면 max_length 크기로 줄인다.\n",
    "\t\t\tex) max_length = 5, [PAD] token id가 0\n",
    "\t\t\t- [20, 2, 1] => [20, 2, 1, 0, 0]\n",
    "\t\t\t- [20, 30, 40, 50, 60, 70, 80][:5] -> [20, 30, 40, 50, 60]\n",
    "\t\t\"\"\"\n",
    "\t\tpad_token_id = self.tokenizer.token_to_id(\"[PAD]\")\n",
    "\t\tseq_len = len(token_sequences)\t# 입력받은 토큰 개수.\n",
    "\t\tresult = None\n",
    "\t\tif seq_len > self.max_length:\t# 잘라내기\n",
    "\t\t\tresult = token_sequences[:self.max_length]\n",
    "\t\telse:\n",
    "\t\t\tresult = token_sequences + ([pad_token_id] * (self.max_length - seq_len))\n",
    "\t\treturn result\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.labels)\t\t# 총 data개수 반환\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\t\"\"\"\n",
    "\t\tidx 번째 text와 label을 학습 가능한 type으로 변환해서 반환\n",
    "\t\tParameter\n",
    "\t\t\tidx: int 조회할 index\n",
    "\t\tReturn\n",
    "\t\t\ttuple: (torch.LongTensor, torch.FloatTensor) - 댓글 토큰_id 리스트, 정답 Label\n",
    "\t\t\"\"\"\n",
    "\t\ttxt = self.texts[idx]\n",
    "\t\tlabel = self.labels[idx]\n",
    "\t\treturn (torch.tensor(txt, dtype=torch.int64), torch.tensor([label], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c150c877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 11, 10, 9, 22]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inputs_length = [len(tokenizer.encode(txt)) for txt in all_inputs]\n",
    "all_inputs_length[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44f03ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 89)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.min(all_inputs_length), np.max(all_inputs_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fdc1bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29., 41.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(all_inputs_length, q = [0.9, 0.95])\n",
    "# 전체 중 90%의 token 수는 29개 미만, 95%는 41개 미만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "059f96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30\n",
    "trainset = NSMCDataset(train_inputs, train_labels, MAX_LENGTH, tokenizer)\n",
    "testset = NSMCDataset(test_inputs, test_labels, MAX_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69ab3ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 50000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "006e9005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  540, 11354,   506,  2408,  5414,  5426,  2408,  5414,   119,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04682f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(testset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "768c02c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2343, 782)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b5f038-b32c-4e4e-82c8-956c7cbe0c4d",
   "metadata": {},
   "source": [
    "# 모델링\n",
    "- Embedding Layer를 이용해 Word Embedding Vector를 추출한다.\n",
    "- LSTM을 이용해 Feature 추출\n",
    "- Linear + Sigmoid로 댓글 긍정일 확률 출력\n",
    "  \n",
    "![outline](figures/rnn/RNN_outline.png)\n",
    "\n",
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac88afd6-5c8f-4ade-b930-86c9425e86e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e9cbbd8-d8b4-4a51-ac7a-5765722f139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model def\n",
    "class NSMCClassifier(nn.Module):\n",
    "\n",
    "\tdef __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, bidireational=True, dropout_rate=0.2):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\t\tvocab_size(int) : 어휘사전의 총 어휘수\n",
    "\t\t\tembedding_dim(int) : (word) embedding vector의 차원수\n",
    "\t\t\thidden_size(int) : LSTM의 hidden state의 feature 수\n",
    "\t\t\tnum_layers(int) : LSTM의 layer의 개수\n",
    "\t\t\tbidireational(bool) : LSTM의 양방향 여부\n",
    "\t\t\tdropout_rate(float) : LSTM이 두 개 이상의 layer로 구성된 경우 적용할 dropout 비율\n",
    "\t\t\t\t\t\t\t\t  Dropout Layer의 dropout 비율\n",
    "\t\t\"\"\"\n",
    "\t\tsuper().__init__()\n",
    "\t\t# model을 구성할 Layer들을 정의 : Embedding, LSTM, Dropout, Linear(추론기기), Sigmoid\n",
    "\n",
    "\t\tself.embedding = nn.Embedding(\n",
    "\t\t\tnum_embeddings=vocab_size,\t\t# 총 단어(토큰)수 -> tokenizer에 등록된 총 단어 수\n",
    "\t\t\tembedding_dim=embedding_dim,\t\t# embedding vector의 차원 수\n",
    "\t\t\tpadding_idx=0\t\t\t\t\t# [PAD]의 token ID(tokenizer.token_to_index(\"[PAD]\") 가 0인 것을 아니 그냥 0으로 넣어준것)\n",
    "\t\t\t\t\t\t\t\t\t\t\t# padding token은 학습하지 않는다.\n",
    "\t\t)\n",
    "\t\t# embedding layer의 출력 shape : (batch_size : 64, seq_len : 문서 토큰 수, embedding_dim)\n",
    "\n",
    "\t\tself.lstm= nn.LSTM(\n",
    "\t\t\tinput_size=embedding_dim,\t# 개별 토큰(단어)의 feature수(embedding -> LSTM)\n",
    "\t\t\thidden_size=hidden_size,\n",
    "\t\t\tnum_layers=num_layers,\n",
    "\t\t\tbidirectional=bidireational,\n",
    "\t\t\tdropout=dropout_rate if num_layers > 1 else 0\t# stacked rnn일 경우 설정.\n",
    "\t\t)\n",
    "\n",
    "\t\tself.dropout = nn.Dropout(dropout_rate)\t\t# LSTM과 Linear 사이에 과적합 방지를 위해서 사용\n",
    "\n",
    "\t\t# LSTM의 출력 : out, (hidden, cell)\n",
    "\t\t# out : 모든 timestep의 hidden state 값 [seq_len, batch, hidden * bidirectional ]\n",
    "\t\t# hidden : 마지막 timestep의 hidden state(단기 기억)\n",
    "\t\t# cell : 마지막 timestep의 cell state(장기 기억)\n",
    "\n",
    "\t\tinput_features = hidden_size*2 if bidireational else hidden_size\n",
    "\t\tself.classifier = nn.Linear(input_features, 1)\t# 출력 1: 이진분류 -> positive의 확률\n",
    "\t\tself.sigmoid = nn.Sigmoid()\t\t\t# classifier의 출력값을 확률(0 ~ 1)값으로 변환하는 func\n",
    "\n",
    "\n",
    "\tdef forward(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\t\tX(tensor) : 입력 문서 토큰 list. shape : [batch_size, max_length : anstjxhzmstn] - [64, 30]\n",
    "\t\t\"\"\"\n",
    "\t\tembedding_vectors = self.embedding(X)\n",
    "\t\t# [batch, seq_len] -> embedding -> [batch_size, seq_len, embedding_dim]\n",
    "\t\t# LSTM - batch_first = False : 입력 shape - [seq_len, batch_size, embedding_dim]\\\n",
    "\t\t# embedding_vectors의 batch 축과 seq_len 축(값의 위치)을 바꿔준다!\n",
    "\t\tembedding_vectors = embedding_vectors.transpose(1,0)\t# 0번 축을 1번 축으로, 1번 축을 0번 축으로\n",
    "\t\tout, _ = self.lstm(embedding_vectors)\n",
    "\t\t# out.shape : [seq_len, batch_size, hidden_size * (2 if bidireational else 1)]\n",
    "\t\t# classifier(linear)에는 out의 마지막 index(마지막 seq) 값을 입력\n",
    "\t\toutput = self.dropout(out[-1])\n",
    "\t\toutput = self.classifier(output)\n",
    "\t\tlast_output = self.sigmoid(output)\n",
    "\n",
    "\t\treturn last_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cedffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ev = [\n",
    "# \t[10, 20, 30],\n",
    "# \t[40, 50, 60]\n",
    "# ]\t# shape : (2, 3)\n",
    "# ev.transpose(1,0)\n",
    "# # parametor의 순서\t: index를 이동시킬 축 위치\n",
    "# # parametor 값 \t\t: 이동시킬 대상 index의 축 위치\n",
    "\n",
    "# a = ev.transpose(1, 0)\n",
    "# # 10 idx : [0, 0] -> [0, 0]\n",
    "# # 20 idx : [0, 1] -> [1, 0]\n",
    "# # 30 idx : [0, 2] -> [2, 0]\n",
    "# # 40 idx ; [1, 0] -> [0, 1]\n",
    "# # a = [\n",
    "# # \t[10, 40]\n",
    "# # \t[20, 50]\n",
    "# # \t[30, 60]\n",
    "# # ] # shape : (3, 2)\n",
    "# b = ev.reshape(3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a0171-371e-4cb5-9bd5-ad1e3c14480d",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7830d2b5-d5ed-4b53-a442-bebc83077aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 생성 전 변수들 먼저 선언\n",
    "VOCAB_SIZE = tokenizer.get_vocab_size()\t\t# 총 어휘수\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT_RATE = 0.3\n",
    "\n",
    "# model의 복잡도 올린다 -> EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS를 크게!\n",
    "# Auto regressive model이 아니면 BIDIRECTIONAL=True (양방향)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d04760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSMCClassifier(\n",
      "  (embedding): Embedding(26742, 100, padding_idx=0)\n",
      "  (lstm): LSTM(100, 64, num_layers=2, dropout=0.3, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (classifier): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NSMCClassifier(\n",
    "\tvocab_size=VOCAB_SIZE,\n",
    "\tembedding_dim=EMBEDDING_DIM,\n",
    "\thidden_size=HIDDEN_SIZE,\n",
    "\tnum_layers=NUM_LAYERS,\n",
    "\tbidireational=BIDIRECTIONAL,\n",
    "\tdropout_rate=DROPOUT_RATE\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8842983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NSMCClassifier                           [64, 1]                   --\n",
       "├─Embedding: 1-1                         [64, 30, 100]             2,674,200\n",
       "├─LSTM: 1-2                              [30, 64, 128]             184,320\n",
       "├─Dropout: 1-3                           [64, 128]                 --\n",
       "├─Linear: 1-4                            [64, 1]                   129\n",
       "├─Sigmoid: 1-5                           [64, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 2,858,649\n",
       "Trainable params: 2,858,649\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 525.05\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 3.50\n",
       "Params size (MB): 11.43\n",
       "Estimated Total Size (MB): 14.95\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary\n",
    "i = torch.randint(1, 10, (64, MAX_LENGTH))\t# int64 type의 dummy input data 생성\n",
    "# input shape : ...\n",
    "summary(model, input_data= i, device=device)\n",
    "# summary(model, input_shape) -> 내부적으로 inputdata(float32)를 생성해서 추론함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd5885-8150-4529-ad3a-84931a8824c5",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a1bf6-d8eb-42d0-996e-f975e93888af",
   "metadata": {},
   "source": [
    "### Train/Test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "46099bec-eee3-4cef-921b-ce9ee6cf0f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 epoch train하는 func\n",
    "def train(model, dataloader, loss_fn, optimizer, device=\"cpu\"):\n",
    "\t# 1. model을 train mode로 변환\n",
    "\tmodel.train()\n",
    "\t# 2. model을 device로 이동\n",
    "\tmodel = model.to(device)\n",
    "\ttotal_loss= 0.0 \t# step별 loss를 누적\n",
    "\n",
    "\t# step 단위로 model train (batch)\n",
    "\tfor X, y in dataloader:\n",
    "\t\t# 1. X, y를 device로 이동\n",
    "\t\tX, y = X.to(device), y.to(device)\n",
    "\t\t# 2. predict\n",
    "\t\tpred = model(X)\n",
    "\t\t# 3. loss cal\n",
    "\t\tloss = loss_fn(pred, y)\n",
    "\t\t# 4. Gradient cal\n",
    "\t\tloss.backward()\n",
    "\t\t# 5. parametor update (w.data - w.grad * lr)\n",
    "\t\toptimizer.step()\n",
    "\t\t# 6. Gradient 초기화\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\t# loss 누적\n",
    "\t\ttotal_loss += loss.item()\n",
    "\t# 1 epoch train 완료\n",
    "\treturn total_loss / len(dataloader)\t\t# 1 epoch의 train loss return. (total loss / step 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4c5eb3ea-78e8-4248-a8ce-d07a4c362d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 epoch eval하는 func\n",
    "def test(model, dataloader, loss_fn, device=\"cpu\"):\n",
    "\t# 1. model을 eval mode로 변환\n",
    "\tmodel.eval()\n",
    "\t# 2. model을 devie로 이동\n",
    "\tmodel = model.to(device)\n",
    "\n",
    "\t#loss, accracy\n",
    "\ttotal_loss = 0.0\n",
    "\ttotal_acc = 0.0\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\t# step 단위로 model eval\n",
    "\t\tfor X, y in dataloader:\n",
    "\t\t\t# 1. X, y를 device로 이동\n",
    "\t\t\tX, y = X.to(device), y.to(device)\n",
    "\t\t\t# 2. predict\n",
    "\t\t\tpred_proba = model(X)\t# 양성일 확률\n",
    "\t\t\tpred_label = (pred_proba > 0.5).type(torch.int32)\n",
    "\t\t\ttotal_loss += loss_fn(pred_proba, y).item()\n",
    "\t\t\ttotal_acc += (pred_label == y).sum().item()\n",
    "\n",
    "\t\t# loss, acc 값을 return\n",
    "\t\treturn total_loss / len(dataloader) , total_acc / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8853d0-b137-47bb-8f0d-fc4f05700cf2",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cd806dda-5058-4c44-a3f4-28cadc8a90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "EPOCHS = 3\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "26ccd522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/3] train loss : 0.4384305650957415, val loss : 0.4199439976983668, val acc : 0.80872\n",
      "[1/3] train loss : 0.39988352811799516, val loss : 0.3990680845763982, val acc : 0.81788\n",
      "[2/3] train loss : 0.3753180680840228, val loss : 0.3896147158863904, val acc : 0.82212\n",
      "946.776273727417\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s = time.time()\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "for epoch in range(EPOCHS):\n",
    "\ttrain_loss = train(model, train_loader, loss_fn, optimizer, device)\n",
    "\tval_loss, val_acc = test(model, test_loader, loss_fn, device)\n",
    "\ttrain_loss_list.append(train_loss)\n",
    "\tval_loss_list.append(val_loss)\n",
    "\tval_acc_list.append(val_acc)\n",
    "\tprint(f\"[{epoch}/{EPOCHS}] train loss : {train_loss}, val loss : {val_loss}, val acc : {val_acc}\")\n",
    "e = time.time()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32690441-482a-46b1-b91b-b85329d2141f",
   "metadata": {},
   "source": [
    "## 모델저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80c16618-1517-4371-8e37-ae3cf03428b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(model, \"saved_models/nsmc/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e2d41e8-0715-4f50-aa37-11a8e142706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# load\n",
    "load_model = torch.load(\"saved_models/nsmc/model.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de7ed5-f7f6-4206-b16f-f8535a03405c",
   "metadata": {},
   "source": [
    "# 서비스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827bdaa3-008d-4a93-aee6-0877e829ef32",
   "metadata": {},
   "source": [
    "## 전처리 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a2661a9-3964-4117-b273-e5d8bd4194b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "morph_tokenizer = Okt()\n",
    "\n",
    "def text_preprocessing(text):\n",
    "\t\n",
    "\ttext = text.lower()\n",
    "\ttext = re.sub(f\"[{string.punctuation}]+\", ' ', text)\n",
    "\treturn ' '.join(morph_tokenizer.morphs(text, stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "315603df-159b-4317-9fb4-7897546b7cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_token_sequences(token_sequences, max_length):\n",
    "\t\"\"\"padding 처리 메소드.\"\"\"\n",
    "\tpad_token = tokenizer.token_to_id('[PAD]')  \n",
    "\tseq_length = len(token_sequences)           \n",
    "\tresult = None\n",
    "\tif seq_length > max_length:                 \n",
    "\t\tresult = token_sequences[:max_length]\n",
    "\telse:                                            \n",
    "\t\tresult = token_sequences + ([pad_token] * (max_length - seq_length))\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d73070a-0ee5-4f35-996c-b0d11ba08516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data_preprocessing(text_list):\n",
    "\t\"\"\"\n",
    "\t모델에 입력할 수있는 input data를 생성\n",
    "\tParameter:\n",
    "\t\ttext_list: list - 추론할 댓글리스트\n",
    "\tReturn\n",
    "\t\ttorch.LongTensor - 댓글 token_id tensor\n",
    "\t\"\"\"\n",
    "\n",
    "\t# cleansing + 정규화 \n",
    "\ttext_list = [text_preprocessing(txt) for txt in text_list]\n",
    "\t# text -> 토큰화\n",
    "\ttoken_list = [tokenizer.encode(txt).ids for txt in text_list]\n",
    "\t# token list의 size를 max_length에 맞추기\n",
    "\ttoken_list = [pad_token_sequences(token, MAX_LENGTH) for token in token_list]\n",
    "\n",
    "\treturn torch.tensor(token_list, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e19997-6b61-446f-ac72-376cd34ee495",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6fb00ab-60d0-45f2-bb16-505a5f5cc056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 30])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, string\n",
    "comment_list = [\"하 이 씨 왜 이러는 거냐 이거 ??\", \"아 진짜 재미없다.\", \"여기 식당 먹을만 해요\", \"이걸 영화라고 만들었냐?\", \"기대 안하고 봐서 그런지 괜찮은데.\", \"이걸 영화라고 만들었나?\", \"아! 뭐야 진짜.\", \"재미있는데.\", \"연기 짱 좋아. 한번 더 볼 의향도 있다.\", \"뭐 그럭저럭\"]\n",
    "input_tensor = predict_data_preprocessing(comment_list)\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "499c330d-69ff-43fb-9ee9-ad1c6054f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, comment_list:list[str], input_tensor:torch.tensor, device=\"cpu\"):\n",
    "\t\"\"\"\n",
    "\tmodel로 input_tensor를 추론해서 긍정/부정적인 댓글인지 출력\n",
    "\t출력 형식\n",
    "\t\tcomment(댓글) label 확률\n",
    "\t\t\"아 노잼\"\t   부정\t 0.9\t(부정일 확률)\n",
    "\t\t\"꿀잼 ㅋ\"\t   긍정  0.87\t(긍정일 확률)\n",
    "\t\"\"\"\n",
    "\n",
    "\t# 1. model을 eval mode로 변환\n",
    "\tmodel.eval()\n",
    "\t# 2. model을 device로 이동\n",
    "\tmodel = model.to(device)\n",
    "\tinput_tensor = input_tensor.to(device)\n",
    "\n",
    "\t\n",
    "\twith torch.no_grad():\t# 추론 과정이니까\n",
    "\t\tpred = model(input_tensor)\t# shape : (batch, 1) -> Positive일 확률값\n",
    "\t\tprint(input_tensor, pred)\n",
    "\t\tfor txt, pos_proba in zip(comment_list, pred):\n",
    "\t\t\tlabel = \"겅정적\" if pos_proba.item() > 0.5 else \"붜정적\"\n",
    "\t\t\tproba =\tpos_proba.item() if pos_proba.item() > 0.5 else 1-pos_proba.item()\t\t# 확률\n",
    "\t\t\tprint(txt, label, round(proba, 3), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4350c86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.2163, -0.0730, -0.3866,  ..., -0.6161,  0.2217,  0.2532],\n",
      "        [-1.3381, -0.3152, -0.3420,  ...,  0.4960,  0.5651, -0.2086],\n",
      "        ...,\n",
      "        [ 0.0165, -0.8020, -0.6993,  ..., -0.2035, -1.1119,  1.0679],\n",
      "        [ 1.0535, -0.5065,  0.1828,  ..., -0.4312,  1.2140,  0.9591],\n",
      "        [-0.9558,  0.0808, -0.0384,  ..., -0.2274, -0.0431,  0.9102]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([[ 0.0775,  0.0461, -0.0820,  ..., -0.0546, -0.0665, -0.1228],\n",
      "        [ 0.0901,  0.1379, -0.1562,  ...,  0.0943, -0.0111, -0.0641],\n",
      "        [-0.0205,  0.0995, -0.0474,  ..., -0.0304,  0.0735, -0.0971],\n",
      "        ...,\n",
      "        [ 0.0557,  0.1052, -0.0009,  ...,  0.0238,  0.0179,  0.0100],\n",
      "        [ 0.0418,  0.0114, -0.1022,  ...,  0.1153, -0.0204, -0.1238],\n",
      "        [ 0.0090, -0.0832, -0.1286,  ..., -0.0799,  0.0129,  0.0852]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(list(load_model.parameters())[0],list(load_model.parameters())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bcbc67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 30])\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5819dc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSMCClassifier(\n",
      "  (embedding): Embedding(26741, 100, padding_idx=0)\n",
      "  (lstm): LSTM(100, 64, num_layers=2, dropout=0.3, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (classifier): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ") torch.Size([10, 30])\n"
     ]
    }
   ],
   "source": [
    "print(load_model, input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a666f2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier bias: tensor([0.0638])\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier bias:\", load_model.classifier.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5273ac02-81f3-4391-b802-f9dca1f8d032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2886,  2206,  1974,  2119,  6071,   544,   829,  2206,   544,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [ 1986,  5426,  5471,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [ 5940, 11677,  5561,  2907,  2128,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [ 2206,   548,  5408,  5545,  5439,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [ 5517,  1988,  5470,  5410,  5482,  5549,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [ 2206,   548,  5408,  5545,  5439,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [ 1986,  1440,  2014,  5426,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [ 5465,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [ 5434,  2408,  5417,  5596,   988,  1549, 25395,  1022,  5415,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [ 1440,  6740,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]]) tensor([[0.4170],\n",
      "        [0.4584],\n",
      "        [0.5452],\n",
      "        [0.4386],\n",
      "        [0.5529],\n",
      "        [0.4386],\n",
      "        [0.4592],\n",
      "        [0.5762],\n",
      "        [0.7780],\n",
      "        [0.5042]])\n",
      "하 이 씨 왜 이러는 거냐 이거 ??\t붜정적\t0.583\n",
      "아 진짜 재미없다.\t붜정적\t0.542\n",
      "여기 식당 먹을만 해요\t겅정적\t0.545\n",
      "이걸 영화라고 만들었냐?\t붜정적\t0.561\n",
      "기대 안하고 봐서 그런지 괜찮은데.\t겅정적\t0.553\n",
      "이걸 영화라고 만들었나?\t붜정적\t0.561\n",
      "아! 뭐야 진짜.\t붜정적\t0.541\n",
      "재미있는데.\t겅정적\t0.576\n",
      "연기 짱 좋아. 한번 더 볼 의향도 있다.\t겅정적\t0.778\n",
      "뭐 그럭저럭\t겅정적\t0.504\n"
     ]
    }
   ],
   "source": [
    "predict(load_model, comment_list, input_tensor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "60e5734b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석하려는 댓글을 입력하세요. 종료하려면 '!quit'을 입력하세요.\n",
      "tensor([[0.2454]])\n",
      "흠 그정돈가 ? 노잼임\t붜정적\t0.755\n",
      "tensor([[0.5237]])\n",
      "왜안되냐 갖빚ㄱ\t겅정적\t0.524\n",
      "tensor([[0.6670]])\n",
      "아 씨\t겅정적\t0.667\n",
      "tensor([[0.4872]])\n",
      "아\t붜정적\t0.513\n",
      "tensor([[0.4872]])\n",
      "아\t붜정적\t0.513\n",
      "tensor([[0.4872]])\n",
      "아\t붜정적\t0.513\n",
      "tensor([[0.0698]])\n",
      "개재미없네\t붜정적\t0.93\n",
      "종료\n"
     ]
    }
   ],
   "source": [
    "print(\"분석하려는 댓글을 입력하세요. 종료하려면 '!quit'을 입력하세요.\")\n",
    "while True:\n",
    "\tcomment = input(\"댓글 : \")\n",
    "\tif comment == \"!quit\":\n",
    "\t\tprint(\"종료\")\n",
    "\t\t\n",
    "\t\tbreak\n",
    "\tcomment_list = [comment]\n",
    "\tinput_tensor = predict_data_preprocessing([comment])\n",
    "\tpredict(model, comment_list, input_tensor, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
