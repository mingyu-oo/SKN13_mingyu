{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ee8245-0329-4185-971d-21bf20cc780e",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "**Chain**(체인)은 여러 컴포넌트(요소)를 정해진 순서대로 연결하여 **복잡한 AI 작업을 단계별로 자동화**할 수 있도록 돕는 구조이다.\n",
    "\n",
    "- 각 컴포넌트는 입력을 받아 특정 처리를 수행한 후 다음 단계로 결과를 전달한다.\n",
    "- 복잡한 작업을 여러 개의 단순한 단계로 나누고, 각 단계를 순차적으로 실행함으로써 전체 작업을 체계적으로 구성할 수 있다.\n",
    "\n",
    "## 기본 개념\n",
    "\n",
    "- 체인은 하나의 LLM 호출에 그치지 않고 **여러 LLM 호출이나 도구 실행을 순차적으로 연결**할 수 있다.\n",
    "- 예를 들어, 사용자의 질문 → 검색 → 요약 → 응답 생성 같은 일련의 작업을 체인으로 구성할 수 있다.\n",
    "- 체인을 사용하면 코드의 재사용성과 유지 보수성이 향상된다.\n",
    "\n",
    "## LangChain에서의 Chain 구성 방식\n",
    "\n",
    "LangChain은 다음 두 가지 방식을 통해 체인을 구성할 수 있다.\n",
    "\n",
    "### 1. Off-the-shelf Chains 방식 (클래식 방식)\n",
    "\n",
    "- LangChain에서 제공하는 **미리 정의된 Chain 클래스**(예: `LLMChain`, `SequentialChain`, `SimpleSequentialChain`)를 활용하는 방식이다.\n",
    "- 이 방식은 LangChain의 **초기 구조**이며, 대부분의 클래스는 현재 **더 이상 사용되지 않음(deprecated)** 상태이다.\n",
    "\n",
    "> 현재 LangChain에서는 이 방식을 권장하지 않는다.\n",
    "\n",
    "### 2. LCEL (LangChain Expression Language) 방식\n",
    "\n",
    "- 체인을 함수형 방식으로 선언할 수 있는 **표현식 기반의 체인 구성 언어**이다.\n",
    "- LCEL 방식은 간결하고 선언적인 문법을 제공하여 **직관적이고 확장성 있는 체인 구성**이 가능하다.\n",
    "- `Runnable`이라는 공통 인터페이스를 기반으로 다양한 요소를 조합하여 체인을 구성한다.\n",
    "- 체인의 각 구성 요소는 `invoke()` 메서드로 실행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1e83dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# off-the-shelf 방식 ! \n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63857f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=\"{item}에 어울리는 이름 {count}개 만들어줘\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model_name = \"gpt-4o-mini\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 변수 : 값 -> (prompt_template) : prompt -> (model) : 응답 -> (parser) : 최종 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a337467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_3244\\1641568219.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "chain = LLMChain(\n",
    "    prompt = prompt_template,\n",
    "    llm = model,\n",
    "    output_parser = parser\n",
    ")\n",
    "response = chain.invoke({\"item\" : \"가방\", \"count\" : 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b7b346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item': '가방',\n",
       " 'count': 5,\n",
       " 'text': '물론입니다! 가방에 어울리는 이름 5개를 만들어보았습니다.\\n\\n1. **민트 미니** - 상큼한 민트 색상과 작은 사이즈의 가방을 연상시키는 이름.\\n2. **에코 패션** - 친환경 소재로 만들어진 스타일리시한 가방에 적합한 이름.\\n3. **로맨틱 로브** - 우아하고 여성스러운 디자인의 가방에 잘 어울리는 이름.\\n4. **시크 백스** - 현대적이고 시크한 느낌을 주는 가방에 어울리는 이름.\\n5. **트레블 터치** - 여행에 적합한 실용적인 가방을 위한 이름.\\n\\n어떤 이름이 마음에 드시나요?'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18243e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 가방에 어울리는 이름 5개를 만들어보았습니다.\n",
      "\n",
      "1. **민트 미니** - 상큼한 민트 색상과 작은 사이즈의 가방을 연상시키는 이름.\n",
      "2. **에코 패션** - 친환경 소재로 만들어진 스타일리시한 가방에 적합한 이름.\n",
      "3. **로맨틱 로브** - 우아하고 여성스러운 디자인의 가방에 잘 어울리는 이름.\n",
      "4. **시크 백스** - 현대적이고 시크한 느낌을 주는 가방에 어울리는 이름.\n",
      "5. **트레블 터치** - 여행에 적합한 실용적인 가방을 위한 이름.\n",
      "\n",
      "어떤 이름이 마음에 드시나요?\n"
     ]
    }
   ],
   "source": [
    "print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba00ec-6c7c-496e-b31f-f3978b74bdba",
   "metadata": {},
   "source": [
    "# [LCEL](https://python.langchain.com/docs/how_to/#langchain-expression-language-lcel) (LangChain Expression Language)\n",
    "- LCEL은 LangChain의 핵심 기능인 체인(Chain)을 더욱 간결하고 유연하게 구성할 수 있도록 고안된 **선언형 체인(chain) 구성 언어**이다.\n",
    "- 파이프 연산자 `|`를 사용해 선언적 방법으로 여러 작업을 연결한다.\n",
    "- 체인을 구성하는 각 요소는 `Runnable` 타입이나 `func등 Callable 객체`으로, 체인 내에서 실행 가능한 단위이다.\n",
    "- 각 단계는 invoke() 메서드를 통해 실행되며, 앞 단계의 출력이 다음 단계의 입력으로 자동 전달된다.\n",
    "    - [Runnable 컴포넌트별 입출력 타입](https://python.langchain.com/docs/concepts/runnables/#input-and-output-types)\n",
    "    - 각 컴포넌트의 input과 output 타입에 맞춰 값이 전달되도록 한다.\n",
    "- https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddf96182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'물론이죠! 다음은 게임에 어울리는 이름 5개입니다:\\n\\n1. **드래곤의 파편 (Fragments of the Dragon)**\\n2. **어둠의 전사 (Warrior of Shadows)**\\n3. **시간의 경계 (Boundaries of Time)**\\n4. **신비한 세계의 문 (Gateway to the Enchanted Realm)**\\n5. **전설의 탐험가 (Legendary Explorer)**\\n\\n이 이름들이 게임의 주제나 분위기에 잘 맞기를 바랍니다!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2 = prompt_template | model | parser\n",
    "\n",
    "chain2.invoke({\"item\" : \"게임\" , \"count\" : 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f0d52c-23da-4ec6-87cc-925e3d6259ea",
   "metadata": {},
   "source": [
    "## [Runnable](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html)\n",
    "- LangChain의 Runnable은 실행 가능한 작업 단위를 캡슐화한 개념으로, 데이터 흐름의 각 단계를 정의하고 **체인(chain) 에 포함 되어**  복잡한 작업의 각 단계를 수행 한다.\n",
    "- Chain을 구성하는 class들은 Runnable의 상속 받아 구현한다.\n",
    "- **Prompt Template클래스**, **Chat 모델, LLM 모델 클래스**, **Output Parser 클래스** 등 다양한 컴포넌트가 Runnable을 상속받아 구현된다.\n",
    "\n",
    "### 주요 특징\n",
    "- 작업 단위의 캡슐화:\n",
    "    - Runnable은 특정 작업(예: 프롬프트 생성, LLM 호출, 출력 파싱 등)을 수행하는 독립적인 컴포넌트이다.\n",
    "    - 각 컴포넌트는 독립적으로 테스트 및 재사용이 가능하며, 조합하여 복잡한 체인을 구성할 수 있다.\n",
    "- 체인 연결 및 작업 흐름 관리:\n",
    "    - Runnable은 체인(chain, 일련의 연결된 작업 흐름)을 구성하는 기본 단위로 사용된다.\n",
    "    - LangChain Expression Language(LCEL)를 사용하면 `|(or)` 연산자를 통해 여러 Runnable을 쉽게 연결할 수 있다.\n",
    "    - 입력과 출력의 형식을 일관되게 유지하여 각 단계가 자연스럽게 연결된다.\n",
    "- 모듈화 및 디버깅 용이성:\n",
    "    - 각 단계가 명확히 분리되어 문제 발생 시 어느 단계에서 오류가 발생했는지 쉽게 확인할 수 있다.\n",
    "    - 복잡한 작업을 작은 단위로 나누어 체계적으로 관리할 수 있다.\n",
    "      \n",
    "### Runnable의 표준 메소드\n",
    "- 모든 Runnable이 구현하는 공통 메소드\n",
    "    - `invoke()`: 단일 입력을 처리하여 결과를 반환.\n",
    "    - `batch()`: 여러 입력 데이터들을 한 번에 처리.\n",
    "    - `stream()`: 입력에 대해 스트리밍 방식으로 응답을 반환.\n",
    "    - `ainvoke()`: 비동기 방식으로 입력을 처리하여 결과를 반환.\n",
    "\t- `a`가 붙으면 비동기 방식, 빠르다 ? 한꺼번에 처리하는 느낌\n",
    "\n",
    "### Runnable의 주요 구현체(하위 클래스)\n",
    "\n",
    "- `RunnableSequence`\n",
    "    - 여러 `Runnable`을 순차적으로 연결하여 실행하는 구성이다.\n",
    "    - 각 단계의 출력이 다음 단계의 입력으로 전달된다.\n",
    "    - LCEL을 사용하여 체인을 구성할 경우 자동으로 `RunnableSequence`로 변환된다.\n",
    "-  `RunnablePassthrough`\n",
    "    - 입력 데이터를 가공하지 않고 그대로 다음 단계로 전달하는 `Runnable`이다.\n",
    "    - 선택적으로 미리 정의된 키-값 쌍을 함께 전달할 수 있다.\n",
    "\n",
    "- `RunnableParallel`\n",
    "    - 여러 `Runnable`을 병렬로 실행한 후, 결과를 결합하여 다음 단계로 전달한다.\n",
    "    - 병렬 처리를 통해 처리 속도를 개선할 수 있다.\n",
    "\n",
    "- `RunnableLambda`\n",
    "    - 일반 함수 또는 `lambda` 함수를 `Runnable`로 변환하여 체인에 포함할 수 있다.\n",
    "    - 사용자 정의 함수로 동작을 확장할 때 유용하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a22719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98816c-6666-4d36-a91d-4b4f64519de4",
   "metadata": {},
   "source": [
    "#### Runnable 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c11041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable\t# All Runnable의 TOP\n",
    "# 사용자 정의 Runnable\n",
    "class MyRunnable(Runnable):\n",
    "    \n",
    "\tdef invoke(self, input_data : str, config : dict = None):\n",
    "\t\t# invoke() : 구현하는 Runnable이 해야하는 작업을 구현하는 method\n",
    "\t\t# input_data : 입력값\n",
    "\t\t# config : 일할 때 필요한 설정 값\n",
    "\n",
    "\t\tif config is not None and config.get(\"lang\") == \"en\":\n",
    "\t\t\treturn f\"Explain {input_data} in one sentences.\"\n",
    "\t\treturn f\"{input_data}에 대해서 한 문장으로 설명 부탁~ 해요 ~\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4913ec80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explain Apple in one sentences.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_runnable = MyRunnable()\n",
    "my_runnable.invoke(\"사과\")\n",
    "my_runnable.invoke(\"콤퓨타\")\n",
    "my_runnable.invoke(\"Apple\", {\"lang\" : \"en\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4646d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='An apple is a round fruit produced by the apple tree, typically characterized by its sweet or tart flavor, crisp texture, and a variety of colors including red, green, and yellow.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 13, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BgjJ0r0xH51tCJmIt1RKiXMP4erfC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--69cdad69-cf6f-4c41-8862-f4276ec0321e-0' usage_metadata={'input_tokens': 13, 'output_tokens': 37, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "my_runnable = MyRunnable()\n",
    "model = ChatOpenAI(model_name = \"gpt-4o-mini\")\n",
    "\n",
    "prompt = my_runnable.invoke(\"apple\", {\"lang\" : \"en\"})\n",
    "response = model.invoke(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eca440f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain은 언어 모델을 활용하여 다양한 애플리케이션을 구축할 수 있도록 지원하는 프레임워크입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 21, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BgjJcn7jvQwnNvvLEq0cRvzo4BgZ8', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--154a0b36-a53d-4755-b88d-297712135b1e-0' usage_metadata={'input_tokens': 21, 'output_tokens': 28, 'total_tokens': 49, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "prompt = my_runnable.invoke(\"langchain\")\n",
    "response = model.invoke(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a49a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='과일 배는 달콤하고 juicy한 맛을 가진 과일로, 주로 가을에 수확되며 신선하게 먹거나 desserts에 활용됩니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 22, 'total_tokens': 58, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Bgjgw8tiu0617QGPzugo93fiRcCWJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--3580622b-efaa-40f2-b29a-b318b3d08548-0' usage_metadata={'input_tokens': 22, 'output_tokens': 36, 'total_tokens': 58, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# chain -> Runnable | Runnable | Runnable\n",
    "chain = my_runnable | model\n",
    "\n",
    "# chain 호출\n",
    "res = chain.invoke(\"과일 배\")\n",
    "# my_runnable.invoke -> 출력 값\n",
    "# model.invoke(출력 값) -> chain의 최종 출력\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a907ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기본 chain 구성 : prompt_templat -> model -> output parser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser, StrOutputParser\n",
    "\n",
    "# role : system, user/human, ai/assistant\n",
    "# \t\t system : 채팅 전체에 적용되는 공통 지침을 지정하는 role\n",
    "\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", \"당신은 경력이 아주 오래된 베테랑 한국 관광가이드입니다. 여행객들에게 설명하듯이 친절하게 답변해주세요.\"),\n",
    "        (\"human\", \"{query}\")\n",
    "\t]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model_name = \"gpt-4o-mini\", temperature=1.0)\n",
    "\n",
    "guide_chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "type(guide_chain)\t# RunnableSequence : Runnable type\n",
    "\t\t\t\t\t# ==> chain도 다른 chain의 구성요소로 포함될 수 있음 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d423aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"대구 관광지 세 가지 알려줘\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d6ab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 대구는 한국의 중심부에 위치한 도시로, 역사와 현대가 조화를 이루는 매력적인 관광지들이 많이 있습니다. 여기 세 가지 추천 관광지를 소개해드릴게요.\n",
      "\n",
      "1. **대구 근대골목**: 대구 근대골목은 대구의 역사와 문화를 느낄 수 있는 곳입니다. 미관이 아름다운 근대 건축물들이 줄지어 있어 산책하기에 아주 좋은 장소입니다. 20세기 초의 대구를 느낄 수 있는 다양한 카페와 상점들이 있어, 사진 찍기에도 좋고 여유롭게 시간을 보낼 수 있습니다.\n",
      "\n",
      "2. **대구 동성로**: 동성로는 대구의 대표적인 쇼핑 거리로, 다양한 패션 브랜드와 맛있는 음식점, 카페들이 즐비해 있습니다. 특히 젊은 사람들이 많이 모이는 곳으로, 분위기가 활기차고 현대적인 느낌이 물씬 풍깁니다. 간단한 쇼핑과 함께 대구의 다양한 먹거리를 경험해 보시길 추천합니다.\n",
      "\n",
      "3. **팔공산**: 대구 시내에서 조금만 나가면 자연을 만끽할 수 있는 팔공산이 있습니다. 등산을 즐기시는 분들에게 안성맞춤인 곳이며, 정상에서 바라보는 경치는 정말 아름답습니다. 특히 봄철에는 꽃들이 만개해 더욱 화사한 풍경을 즐길 수 있습니다. 팔공산에는 불교 사찰인 동화사도 있어 문화체험도 가능합니다.\n",
      "\n",
      "대구에는 이 외에도 많은 매력적인 장소들이 있으니, 방문하실 기회가 있다면 꼭 즐겨보세요!\n"
     ]
    }
   ],
   "source": [
    "response = guide_chain.invoke({\"query\" : query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "612b9102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User :  이건 진짜 모르겠네\n",
      "AI :  안녕하세요! 여러분, 한국에 오신 것을 진심으로 환영합니다! 한국의 아름다움과 풍부한 문화유산을 함께 탐험하게 되어 매우 기쁩니다. 어떤 질문이든지 환영합니다. 한국의 명소, 전통 음식, 문화 경험 등 여러분이 궁금한 점은 무엇이든 말씀해 주세요. 제가 친절히 안내해드리겠습니다!\n",
      "User :  답변이 왜 계쏙 이렇게 되지 ? 내말이 안들려 ? 너 누구야 ?\n",
      "AI :  안녕하세요, 여러분! 한국을 방문해 주셔서 정말 감사합니다. 저는 여러분과 함께 이 아름다운 나라를 탐험하게 되어 매우 기쁩니다. 한국은 풍부한 역사와 문화, 그리고 멋진 자연경관이 어우러진 곳입니다.\n",
      "\n",
      "오늘은 여러분에게 한국의 대표적인 관광지를 소개해 드릴게요. \n",
      "\n",
      "첫 번째로는 서울의 경복궁입니다. 이곳은 조선 왕조의 첫 번째 궁궐로, 아름다운 전통 건축을 감상할 수 있습니다. 특히 매일 정오에 열리는 수문장 교대식은 꼭 보셔야 할 하이라이트 중 하나입니다!\n",
      "\n",
      "다음으로는 전주 한옥마을입니다. 전주의 전통 한옥들이 잘 보존되어 있어 한국의 전통 문화를 느낄 수 있는 좋은 곳입니다. 여기서 맛볼 수 있는 비빔밥, 한옥 체험, 그리고 전통 찻집도 놓치지 마세요!\n",
      "\n",
      "그리고 자연을 사랑하시는 분들에게는 제주도를 추천합니다. 제주도는 아름다운 해변과 독특한 자연경관으로 유명합니다. 한라산의 트레킹이나 우도의 경치를 감상하며 여유로운 시간을 보내시면 좋습니다.\n",
      "\n",
      "마지막으로, 한국의 다양한 음식도 빼놓을 수 없습니다. 불고기, 김치, 비빔밥 등 한국의 전통 음식들은 맛도 훌륭하고 건강에도 좋답니다. \n",
      "\n",
      "여행 중 궁금한 점이나 도움이 필요하시면 언제든지 말씀해 주세요. 여러분의 여행이 더욱 특별하고 기억에 남는 시간이 되도록 도와드릴게요. 감사합니다!\n",
      "User :  답변이 왜 안나올까 ??\n",
      "AI :  안녕하세요, 여러분! 저는 여러분과 함께 한국의 아름다운 관광지를 탐험할 가이드입니다. 오늘은 한국의 풍부한 역사와 문화, 그리고 아름다운 자연경관에 대해 설명해 드릴게요. \n",
      "\n",
      "한국은 사계절이 뚜렷한 나라로, 각 계절마다 그 특색을 만끽할 수 있습니다. 봄에는 벚꽃이 만개하고, 여름의 초록빛 숲속에서 시원한 계곡을 즐길 수 있습니다. 가을에는 단풍이 물드는 산을 배경으로 하여, 겨울에는 하얗게 눈 덮인 풍경이 우리를 맞이합니다.\n",
      "\n",
      "서울에 오시면 경복궁을 꼭 방문해 보세요. 이곳은 조선 왕조의 첫 번째 궁궐로, 아름다운 건축물과 정원이 정말 인상적입니다. 특히, 국립민속박물관이 근처에 있어 한국의 전통 문화를 좀 더 깊이 이해할 수 있는 좋은 기회가 됩니다.\n",
      "\n",
      "전주에 가시면 유명한 전주비빔밥과 한옥마을을 잊지 말고 경험해 보세요. 전통 한옥에서 한국의 전통 음식과 문화를 체험할 수 있는 매우 특별한 경험이랍니다.\n",
      "\n",
      "부산에서는 해운대 해수욕장과 자갈치 시장을 추천드립니다. 해운대에서는 바다의 아름다움을 즐길 수 있고, 자갈치 시장에서는 신선한 해산물을 맛볼 수 있습니다.\n",
      "\n",
      "모든 장소에는 각자의 매력이 있으니, 여러분의 취향에 맞춰 경로를 설정해 보세요. 여행 중 궁금한 점이 있으시면 언제든지 질문해 주시기 바랍니다. 그럼 환상적인 한국 여행이 되길 바랍니다!\n",
      "User :  야이새기야!!!!!!!\n",
      "AI :  안녕하세요! 한국에 오신 것을 진심으로 환영합니다. 저는 여러분의 가이드가 될 베테랑 관광가이드입니다. 궁금한 점이나 도움이 필요한 부분이 있다면 언제든지 말씀해 주세요. 한국의 아름다운 문화, 역사, 음식, 관광지에 대해 친절하게 설명해 드리겠습니다. \n",
      "\n",
      "예를 들어, 서울의 경복궁, 찜질방의 매력, 맛있는 김치찌개에 대해 이야기해 드릴 수 있어요. 어떤 주제에 대해 더 알고 싶으신가요?\n",
      "User :  ㅇ\n",
      "AI :  안녕하세요! 한국의 아름다움을 안내해드리게 되어 매우 기쁩니다. 어떤 질문이든지 편하게 해주시면, 한국의 문화, 역사, 명소 등에 대해 친절히 설명해드릴게요. 혹시 방문하고 싶은 특정 지역이나 관광지가 있으신가요? 혹은 한국의 전통 음식이나 축제에 대해 궁금하신 점이 있다면 말씀해 주세요!\n",
      "User :  근데 이제 중동 관광 가이드와 대화하려면 어떤 대화를 나누면 좋을ㄲ ㅏ?\n",
      "AI :  안녕하세요, 여러분! 오늘 한국을 탐험하실 준비가 되셨나요? 저는 여러분의 가이드로서 한국의 아름다움과 매력을 함께 나누게 되어 매우 기쁘습니다. \n",
      "\n",
      "한국은 풍부한 역사와 문화, 놀라운 자연경관으로 가득한 나라입니다. 서울은 현대와 전통이 조화롭게 어우러진 도시로, 고궁과 현대적인 건축물들이 함께 존재합니다. Gyeongbokgung(경복궁)에서는 조선 왕조의 역사와 궁중 문화에 대해 배울 수 있으며, 인사동에서는 전통적인 한국의 공예품과 문화를 체험하실 수 있습니다.\n",
      "\n",
      "부산은 해양 도시로 깨끗한 해변과 맛있는 해산물로 유명합니다. 해운대 해수욕장에서 여유로운 시간을 보내실 수 있고, 자갈치 시장에서는 신선한 해산물을 맛보실 수 있습니다.\n",
      "\n",
      "그리고 제주도는 아름다운 자연 경관으로 많은 여행객들이 찾는 명소입니다. 한라산의 웅장함과 푸른 바다, 그리고 독특한 오름과 돌담이 있는 풍경은 꼭 경험해보셔야 합니다.\n",
      "\n",
      "여행 중 궁금한 점이 있으시면 언제든지 물어보세요. 여러분의 여행이 즐겁고 의미 있는 시간이 되도록 최선을 다하겠습니다! 안전하고 즐거운 여행 되세요!\n",
      "User :  대답\n",
      "AI :  안녕하세요! 여러분, 오늘 한국에 오신 것을 정말 환영합니다. 저는 여러분의 관광 가이드입니다. 한국의 멋진 문화, 역사, 그리고 아름다운 자연을 함께 탐험할 준비가 되셨나요?\n",
      "\n",
      "오늘은 한국의 대표적인 명소들을 소개해드리겠습니다. 먼저 서울로 가볼까요? 서울은 현대적인 도시와 전통이 어우러져 있는 곳이에요. 경복궁은 조선 왕조의 대표적인 궁궐로, 반드시 방문해보셔야 할 곳입니다. 이곳에서는 아름다운 건축물과 함께 수 많은 역사적 이야기를 들을 수 있습니다.\n",
      "\n",
      "또한, 인사동 거리도 추천드립니다. 전통 차를 마시거나, 한국의 공예품을 구경하실 수 있습니다. 이곳에서는 한국의 예술과 문화를 가까이서 느껴보실 수 있어요.\n",
      "\n",
      "다음으로는 한국의 전통 음식을 경험해보시는 것도 좋습니다. 비빔밥, 불고기, 김치찌개 등의 요리를 통해 한국의 풍부한 맛을 느끼실 수 있을 거예요.\n",
      "\n",
      "그 밖에도 한국의 아름다운 자연경관도 놓치지 말아야 할 부분이죠. 예를 들어, 제주도는 푸른 바다와 독특한 풍경으로 유명합니다. 한라산에서 트레킹을 하거나, 용두암과 성산일출봉을 방문하시면 환상적인 경치를 감상하실 수 있습니다.\n",
      "\n",
      "궁금한 점이나 방문하고 싶은 장소가 있으시면 언제든지 말씀해 주세요! 여러분의 소중한 여행이 더욱 특별해질 수 있도록 도와드리겠습니다. 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"질문 : \")\n",
    "    if query == \"!q\":\n",
    "        break\n",
    "    resp = guide_chain.invoke({\"query\" : query})\n",
    "    print(\"User : \", query)\n",
    "    print(\"AI : \", resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6c137e-35bb-4e4d-8561-859b0650b62f",
   "metadata": {},
   "source": [
    "#### RunnableLambda 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a5ac9fd-2616-4031-a079-a1822d784e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LLM를 한 문장으로 설명해줘'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "# RunnableLambda(func) -> func를 실행하는 Runnable을 생성.\n",
    "# Lambda만 넣을 수 있는게 아니라 func를 넣는 개념\n",
    "\n",
    "my_runnable2 = RunnableLambda(lambda input_data : f\"{input_data}를 한 문장으로 설명해줘\")\n",
    "my_runnable2.invoke(\"LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92470257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LLM(대형 언어 모델)은 방대한 양의 텍스트 데이터를 학습하여 자연어 처리 작업을 수행하는 AI 모델입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 17, 'total_tokens': 48, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BgkBRE9Hy7hVtJCnULKNQe9OuqdP2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1e4a755e-6d41-4693-a513-4f5c795b0017-0', usage_metadata={'input_tokens': 17, 'output_tokens': 31, 'total_tokens': 48, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = my_runnable2 | model\n",
    "chain.invoke(\"LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e267716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum(nums):\n",
    "    return nums[0] + nums[1]\n",
    "\n",
    "\n",
    "my_runnable3 = RunnableLambda(sum)\n",
    "my_runnable3.invoke({0:10,1:20})\n",
    "\n",
    "# .invoke(입력데이터 : str | dict, 설정정보 : dict)는 parameter를 2개 받아야함.\n",
    "## 입력데이터가 여러 개일 경우 dict등의 자료구조를 이용해서 받음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884fd4c-feaa-46f1-af21-c5779900e502",
   "metadata": {},
   "source": [
    "#### RunnablePassthrough 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e43fcf5-e5c7-4502-830f-b722b832f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "########## RunnablePassthrough ##########\n",
    "# 1. 앞 Runnable이 처리한 결과를 다음 Runnable에 그대로 전달\n",
    "# 2. 앞 Runnable이 처리한 결과에 Item을 추가해서 다음 Runnable에 전달\n",
    "# RunnableParallel과 함께 많이 쓰임\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c8bdd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key': 'value'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough().invoke(\"하이용\")\n",
    "RunnablePassthrough().invoke({\"key\" : \"value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f84825b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '우밍구', 'address': '서울시 금천구', 'phone': '010-2330-2249'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력으로 dictionary 받아서 거기에 item을 추가\n",
    "# RunnablePassthrough.assgin(key = Runnable, key = Runnable, ...)\n",
    "# 받은 dictionary에 \"key1\" : \"Runnable return값\", \"key2\" : \"Runnable return값\", ...\n",
    "# 을 추가해서 다음으로 전달.\n",
    "\n",
    "address_runnable = RunnableLambda(lambda x : \"서울시 금천구\")\t# \"서울시 금천구\"를 return\n",
    "phone_runnable = RunnableLambda(lambda x : \"010-2330-2249\")\n",
    "\n",
    "RunnablePassthrough.assign(address = address_runnable, phone = phone_runnable).invoke({\"name\" : \"우밍구\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ba482-5dab-41df-96d1-c6649ecb8cee",
   "metadata": {},
   "source": [
    "#### RunnableSequence 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afd2c247-a4e3-4b1b-a494-400b077eba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'> 22\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "# chain과 같음. 실제로 RunnableSequence를 써서 만들 필요는 없다.\n",
    "\n",
    "run1 = RunnableLambda(lambda x : x + 1)\n",
    "run2 = RunnableLambda(lambda x : x * 2)\n",
    "\n",
    "chain = RunnableSequence(run1, run2)\n",
    "print(type(chain), chain.invoke(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b60fb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2 = run1 | run2\n",
    "chain.invoke(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1531bb-ad33-4d1b-a59b-62cf08cb4457",
   "metadata": {},
   "source": [
    "#### RunnableParallel 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cce6992c-85e1-4a2f-b16f-e294c50a3c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result1': 11, 'result2': 20, 'result3': 3, 'result4': 10}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "\n",
    "run1 = RunnableLambda(lambda x: x+1)\n",
    "run2 = RunnableLambda(lambda x: x*2)\n",
    "run3 = RunnableLambda(lambda x: x//3)\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    {\n",
    "        \"result1\":run1,\n",
    "        \"result2\":run2,\n",
    "        \"result3\":run3,\n",
    "        \"result4\":RunnablePassthrough() # 앞에서 받은 값을 그대로 다음에 전달.\n",
    "    }\n",
    ")\n",
    "# Runnable들을 각각 실행하고 그 결과를 key에 할당한 Dictionary에 반환\n",
    "runnable.invoke(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31115cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result1': 121, 'result2': 240, 'result3': 40}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LCEL 안에서는 RunnableParallel은 { }로 표현 가능 !\n",
    "run0 = RunnableLambda(lambda x : x + 100)\n",
    "# run0 -> {run1, run2, run3} -> ...\n",
    "chain = run0 | {\"result1\" : run1,\n",
    "                \"result2\" : run2,\n",
    "                \"result3\" : run3}\n",
    "\n",
    "chain.invoke(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af622cf3-8627-4136-80cd-2c87b31f743a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fe6327f-591c-4d0b-87b2-796d41ad6b98",
   "metadata": {},
   "source": [
    "#### LCEL Chain 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b25d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음식 이름을 받아서 레시피를 \"영어\"로 출력하는 chain 구성\n",
    "# prompt template -> model -> output parser\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from textwrap import dedent\n",
    "\n",
    "# 음식 레시피 chain\n",
    "prompt_template = PromptTemplate(\n",
    "    template=dedent\n",
    "    (\"\"\"\n",
    "\t#Instruction\n",
    "    당신은 순력된 요리 연구가입니다. 요청한 음식의 레시피를 작성해주세요.\n",
    "    \n",
    "    #Input data\n",
    "    음식이름 : {food}\n",
    "    \n",
    "    #Output indeicator\n",
    "    - 다음 항목을 넣어서 작성하세요.\n",
    "\t\t- 재료\n",
    "\t\t- 조리 순서\n",
    "\t\"\"\")\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model_name = \"gpt-4o-mini\")\n",
    "\n",
    "food_chain = prompt_template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e95cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = food_chain.invoke({\"food\" : \"아이스크림\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96b68ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 아이스크림 레시피\n",
      "\n",
      "## 재료\n",
      "- 우유 500ml\n",
      "- 생크림 250ml\n",
      "- 설탕 150g\n",
      "- 바닐라 익스트랙 1작은술 (또는 바닐라 슈가 1봉지)\n",
      "- 소금 한 꼬집\n",
      "- 계란 노른자 3개 (옵션, 크림이 더욱 부드럽게 만들기 위해)\n",
      "\n",
      "## 조리 순서\n",
      "\n",
      "1. **재료 준비**: 우유, 생크림, 설탕, 바닐라 익스트랙, 소금을 미리 준비합니다. 계란 노른자를 사용할 경우도 함께 준비합니다.\n",
      "\n",
      "2. **혼합**: 큰 볼에 우유, 생크림, 설탕, 바닐라 익스트랙(또는 바닐라 슈가), 소금을 넣고 잘 섞어줍니다. 설탕이 완전히 녹을 때까지 저어주세요.\n",
      "\n",
      "3. **계란 노른자 추가 (옵션)**: 계란 노른자를 사용할 경우, 작은 볼에 달걀 노른자를 넣고 살짝 휘핑한 후, 우유 혼합물에 조금씩 넣어가며 잘 섞습니다. 이 과정에서 혼합물이 너무 뜨거워지지 않도록 주의합니다.\n",
      "\n",
      "4. **가열**: 믹서를 끓일 수 있는 중간 크기의 냄비에 혼합물을 옮기고 중약 불로 약간의 열을 가합니다. 가열하는 동안 계속 저어주며 혼합물이 약간 걸쭉해질 때까지 끓입니다. (80도 이내가 이상적입니다)\n",
      "\n",
      "5. **냉각**: 혼합물이 완전히 익은 후, 냄비에서 불을 끄고 실온에서 식힌 뒤 냉장고에 넣어 완전히 차갑게 식힙니다. 최소 4시간 이상 냉장보관 하는 것이 좋습니다.\n",
      "\n",
      "6. **냉동**: 차가워진 아이스크림 혼합물을 아이스크림 기계에 넣고 제조사의 지침에 따라 아이스크림을 만듭니다. (아이스크림 기계가 없다면, 혼합물을 큰 냉동 가능한 용기에 옮기고 30분마다 섞어주면서 3-4시간 동안 얼립니다.)\n",
      "\n",
      "7. **서빙**: 아이스크림이 잘 얼었으면 원하는 모양으로 스쿱하여 그릇에 담습니다. 취향에 따라 초콜릿 소스, 견과류, 과일 등을 함께 올려 즐기세요!\n",
      "\n",
      "8. **보관**: 남은 아이스크림은 밀폐 용기에 담아 냉동 보관합니다. \n",
      "\n",
      "맛있게 즐기세요!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d335e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 chain -> 입력된 내용을 지정한 언어로 번역하는 chain\n",
    "\n",
    "prompt_template_trans = PromptTemplate(\n",
    "    template=dedent\n",
    "\t(\"\"\"\n",
    "\t#Instruction\n",
    "    당신은 모든 언어를 다룰줄 아는 번역가입니다. 입력 내용을 지정된 언어 {language}로 번역해주세요.\n",
    "    \n",
    "    #Input data (번역할 문장)\n",
    "    내용 : {content}\n",
    "\t\"\"\")\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model_name = \"gpt-4o-mini\")\n",
    "\n",
    "translate_chain = prompt_template_trans | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40279253",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_res = translate_chain.invoke({\"content\" : response, \"language\" : \"일본어\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4eee2ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# アイスクリーム レシピ\n",
      "\n",
      "## 材料\n",
      "- 牛乳 500ml\n",
      "- 生クリーム 250ml\n",
      "- 砂糖 150g\n",
      "- バニラエッセンス 小さじ1（またはバニラシュガー 1袋）\n",
      "- 塩 ひとつまみ\n",
      "- 卵黄 3個（オプション、クリームをさらに滑らかにするため）\n",
      "\n",
      "## 調理手順\n",
      "\n",
      "1. **材料準備**: 牛乳、生クリーム、砂糖、バニラエッセンス、塩を事前に準備します。卵黄を使用する場合も一緒に準備します。\n",
      "\n",
      "2. **混合**: 大きなボウルに牛乳、生クリーム、砂糖、バニラエッセンス（またはバニラシュガー）、塩を入れてよく混ぜます。砂糖が完全に溶けるまでかき混ぜてください。\n",
      "\n",
      "3. **卵黄追加（オプション）**: 卵黄を使用する場合、小さいボウルに卵黄を入れて軽く泡立てた後、牛乳混合物に少しずつ加えながらよく混ぜます。この過程で混合物が熱くなりすぎないように注意します。\n",
      "\n",
      "4. **加熱**: 中程度の大きさの鍋に混合物を移し、中弱火で少し加熱します。加熱中は常にかき混ぜ、混合物が少しとろみが出るまで煮ます。（80度以内が理想です）\n",
      "\n",
      "5. **冷却**: 混合物が完全に加熱されたら、鍋の火を消し、常温で冷ました後、冷蔵庫に入れて完全に冷やします。最低4時間以上冷蔵保存するのが良いです。\n",
      "\n",
      "6. **冷凍**: 冷やしたアイスクリーム混合物をアイスクリームメーカーに入れ、メーカーの指示に従ってアイスクリームを作ります。（アイスクリームメーカーがない場合は、混合物を大きな冷凍可能な容器に移し、30分ごとにかき混ぜながら3-4時間冷凍します。）\n",
      "\n",
      "7. **サービング**: アイスクリームが良く冷凍されたら、お好みの形にすくって器に盛ります。お好みに応じてチョコレートソース、ナッツ、フルーツなどをトッピングして楽しんでください！\n",
      "\n",
      "8. **保存**: 残ったアイスクリームは密閉容器に入れて冷凍保存します。\n",
      "\n",
      "美味しくお楽しみください！\n"
     ]
    }
   ],
   "source": [
    "print(trans_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cfbc5c-6c03-48fc-9e4d-ddf8f34893f5",
   "metadata": {},
   "source": [
    "## Chain과 Chain간의 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98e306d3-430f-4bfa-982c-a806e1910f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# food_chain | translate_chain\n",
    "## food_chain_prompt : 변수 = food\n",
    "## translate_chain_prompt : 변수 = language\n",
    "\n",
    "# food -> food_chain, language -> translate_chain\n",
    "# food_chain 응답 결과(레시피) -> {\"content\" : 레시피} => translate_chain\n",
    "\n",
    "# RunnableParallel({\"key1\" : Runnable, \"key2\" : Runnable})\n",
    "# LCEL에서 RunnableParallel => {\"key1\" : Runnable, \"key2\" : Runnable}\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "full_chain = RunnableParallel(\n",
    "    {\"content\" : food_chain,\n",
    "     \"language\" : RunnableLambda(lambda x : x[\"language\"])}\n",
    ") | translate_chain\n",
    "\n",
    "full_res = full_chain.invoke({\"food\" : \"토마토 파스타\", \"language\" : \"영어\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b35f4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Tomato Pasta Recipe\n",
      "\n",
      "### Ingredients\n",
      "- 200g spaghetti\n",
      "- 4 fresh tomatoes (or 400g canned tomatoes)\n",
      "- 2 tablespoons olive oil\n",
      "- 2 cloves garlic (minced)\n",
      "- 1 onion (chopped)\n",
      "- Fresh basil leaves (optional)\n",
      "- Salt and pepper (to taste)\n",
      "- Parmesan cheese (optional)\n",
      "\n",
      "### Cooking Instructions\n",
      "1. **Cooking the Pasta**: Bring a large pot of water to a boil, add salt, and cook the spaghetti according to the time indicated on the packaging. Once the pasta is cooked, drain it in a colander and drizzle a little olive oil to prevent it from sticking together.\n",
      "\n",
      "2. **Preparing the Sauce**: Heat olive oil in a pan over medium heat. Add the chopped onion and sauté until it becomes translucent.\n",
      "\n",
      "3. **Adding Garlic and Tomatoes**: Once the onion is translucent, add the minced garlic and sauté for another minute until fragrant. Chop the fresh tomatoes into small pieces and add them to the pan; if using canned tomatoes, add them directly to the pan.\n",
      "\n",
      "4. **Simmering the Sauce**: Bring the tomato sauce to a simmer over medium heat, then season with salt and pepper. Let it simmer for about 10 minutes until the sauce thickens. You can add a little water to adjust the sauce's consistency if needed.\n",
      "\n",
      "5. **Combining Main Ingredients**: Add the cooked spaghetti to the pan with the sauce and stir well while sautéing for an additional 2-3 minutes to combine the pasta with the sauce thoroughly.\n",
      "\n",
      "6. **Plating**: Now serve the pasta on a plate, adding fresh basil leaves and Parmesan cheese if desired.\n",
      "\n",
      "7. **Finishing Touch**: Enjoy your warm tomato pasta! You can drizzle additional olive oil or sprinkle more pepper if you like.\n",
      "\n",
      "Bon appétit!\n"
     ]
    }
   ],
   "source": [
    "print(full_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b59505-5ef9-4bc5-9a32-9e359d3bf0a1",
   "metadata": {},
   "source": [
    "# 사용자 함수를 Chain에 적용하기\n",
    "\n",
    "## 사용자 함수를 Runnable로 정의 (RunnableLambda)\n",
    "- 임의의 함수를 Runnable로 정의 할 수있다.\n",
    "  - chain에 포함할 기능을 함수로 정의할 때 주로 사용. \n",
    "- `RunnableLambda(함수)` 사용\n",
    "  - 함수는 invoke() 메소드를 통해 입력받은 값을 받을 **한개의 파라미터**를 선언해야 한다.\n",
    "\n",
    "## 사용자 함수를 Chain으로 정의\n",
    "- Chain 을 구성하는 작업 사이에 추가 작업이 필요할 경우, 중간 결과를 모두 사용해야 하는 경우 함수로 구현한다.\n",
    "- `@chain` 데코레이터를 사용해 함수에 선언한다.\n",
    "\n",
    "### Runnable 에 사용할 **사용자 정의 함수** 구문\n",
    "- 이전 Chain의 출력을 입력 받는 **파라미터를 한개** 선언한다. (첫번째 파라미터)\n",
    "- `invoke()`로 호출 할때 전달 하는 추가 설정을 입력받는 파라미터를 선언한다.(두번째 파라미터 - Optional)\n",
    "  - RunnableConfig 타입의 값을 받는데 Dictionary 형식으로 `{\"configuable\": {\"설정이름\":\"설정값\"}}` 형식으로 받는다.\n",
    "- 만약 함수가 여러개의 인자를 받는 경우 단일 입력을 받아들이고 이를 여러 인수로 풀어내는 래퍼 함수를 작성하여 Runnable로 만든다.\n",
    "  ```python\n",
    "  def plus(num1, num2):\n",
    "      ...\n",
    "\n",
    "  def wrapper_plus(nums:dict|list):\n",
    "      return plus(nums['num1'], nums['num2'])\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c0de6e8-4bcf-412c-8983-9be3d7679ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "# 기존에 정의된 func을 Runnable로 정의하고 싶음\n",
    "\n",
    "def plus(num1, num2, num3):\n",
    "    return num1 + num2 + num3\n",
    "\n",
    "# 실제 존재하는 걸 감싸준다는 뜻 : wrapper\n",
    "def wrapper_plus(nums : list):\n",
    "    return plus(nums[0], nums[1], nums[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9120a03",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RunnableLambda.invoke() takes from 2 to 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m run0 = RunnableLambda(plus)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mrun0\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# invoke(input_data, config:RunnableConfig(설정정보)=None)\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: RunnableLambda.invoke() takes from 2 to 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "run0 = RunnableLambda(plus)\n",
    "run0.invoke(1, 2, 3)\n",
    "# invoke(input_data, config:RunnableConfig(설정정보)=None)\n",
    "# 라서 이런 식으로 못 씀."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93fd2ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run1 = RunnableLambda(wrapper_plus)\n",
    "run1.invoke([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69710192-a281-43a2-b944-ccd3705d3b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 소재를 이용해서 이야기를 생성하는 chain\n",
    "# 장문을 입력 받아서 요약하는 chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from textwrap import dedent\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "370c44ce-3e5b-4992-9ddf-cb2835c361be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model_name = \"gpt-4o-mini\")\n",
    "story_prompt_template = PromptTemplate(\n",
    "    template=dedent(\"\"\"\n",
    "\t# Instruction\n",
    "\t너는 아이들을 위한 이야기를 창작하는 스토리텔러야 !\n",
    "\t주어진 소재로 잠자리에서 아이들에게 들려줄 재밌는 이야기를 들려줘 !\n",
    "\t\n",
    "\t# Input Data\n",
    "\t소재 : {topic}\n",
    "                    \n",
    "\t# Output Indicator\n",
    "\t- 이야기는 30문장 이내로 구성해줘\n",
    "\t- 이야기는 구어체로 작성해줘.\n",
    "\"\"\")\n",
    ")\n",
    "story_chain = story_prompt_template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51a442bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 chain\n",
    "summary_prompt = PromptTemplate(\n",
    "    template=dedent\n",
    "   (\"\"\"\n",
    "\t# Instruction\n",
    "    주어진 문장 내용을 2문장으로 요약 해줘\n",
    "    \n",
    "    # Input Data\n",
    "    {content}\n",
    "\"\"\")\n",
    ")\n",
    "\n",
    "summary_chain = summary_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ba0702e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "옛날 옛적, 깊은 숲 속에 호랑이가 살았어요. 이 호랑이 이름은 ‘호호’였답니다. 호호는 무척 용감하고 힘이 세서, 숲의 왕이라고 불렸죠.\n",
      "\n",
      "하루는 호호가 숲 속을 걷고 있었어요. 그러다가 작은 토끼가 웅크리고 있는 걸 발견했어요. 호호가 다가가서 물었어요. “안녕, 친구! 왜 이렇게 숨어 있어?” \n",
      "\n",
      "토끼가 떨리는 목소리로 대답했어요. “호호, 숲 속에 사는 맹수들이 자꾸 나를 괴롭혀서 도망치고 있어.” \n",
      "\n",
      "호호는 그 말을 듣고 생각했어요. “내가 도와줄게! 함께 힘을 합치자!” 그래서 호호와 토끼는 친구가 되었답니다.\n",
      "\n",
      "다음 날, 호호는 토끼와 함께 숲 속으로 나갔어요. 그리고 친구들을 찾아서 용감하게 말했죠. “우리 모두 힘을 내자! 나와 함께 하라!” \n",
      "\n",
      "다람쥐, 사슴, 그리고 새들까지 모두 모였어요. 호호는 다른 동물들에게 힘을 주었어요. “우리가 서로 도와주면 어떤 맹수도 두렵지 않아!”\n",
      "\n",
      "그렇게 동물들은 함께 맹수들이 나타나는 곳으로 갔어요. 그리고 호호가 큰 소리로 외쳤어요. “이리 와, 맹수들! 우리는 두렵지 않단다!”\n",
      "\n",
      "그러자 무서운 늑대가 나타났어요. 늑대가 ‘어쩔 수 없군’ 하며 퇴각하려고 했는데, 호호가 용감하게 맞섰어요. “우리는 항상 하나니까, 너희는 더 이상 괴롭힐 수 없어!”\n",
      "\n",
      "호호의 용기에 다른 동물들도 힘을 내었답니다. 그 모습을 보고 늑대는 쫄아서 도망쳤어요. 동물들은 모두 기뻐하며 춤을 췄어요.\n",
      "\n",
      "“호호, 우리를 지켜줘서 고마워!” 토끼가 외쳤어요. 호호는 미소 지으며 대답했어요. “친구를 돕는 건 당연한 일이야.”\n",
      "\n",
      "그 이후로 호호는 더욱 더 숲의 영웅이 되었어요. 어떤 동물이 위험에 처해도, 호호는 항상 나서서 도와줬답니다. \n",
      "\n",
      "호호와 친구들은 해가 지고 밤이 되어도 함께 놀며 행복하게 살았어요. 호호는 이제 숲 위험을 감지하는 ‘호호 경보’가 되었답니다!\n",
      "\n",
      "그리고 매일 밤, 별이 반짝일 때면 호호는 친구들에게 이야기해 주었어요. “우리는 언제나 함께라서 강해! 두려울 게 하나도 없어!”\n",
      "\n",
      "이렇게 호호와 친구들은 사랑과 용기로 가득한 숲 속에서 오래오래 행복하게 살았답니다. 이제 여러분도 그들의 이야기를 마음 속에 담고 함께 용감해질 수 있기를 바래요. 잘 잤으면 좋겠어요!\n"
     ]
    }
   ],
   "source": [
    "print(story_chain.invoke({\"topic\" : \"호랑이\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10288c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'호호라는 용감한 호랑이는 숲에서 친구 토끼를 도와 함께 힘을 합쳐 맹수들에 맞섰고, 그 과정에서 다양한 동물들과 우정을 쌓았다. 이후 호호는 숲의 영웅으로서 친구들을 보호하며 행복한 삶을 살게 되었다.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = story_chain | summary_chain\n",
    "chain.invoke({\"topic\":\"호랑이\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "45216f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "# 사용자 정의 chain : 원하는 흐름으로 구조를 정의 가능\n",
    "@chain\t# runnable이 돼.\n",
    "def custom_chain(topic : str) -> dict[str, str]:\n",
    "    # story_chain과 summary_chain을 원하는 흐름으로 구현하고 싶엉\n",
    "    # story_chain의 결과와 summary_chain으이 결과를 모두 반환하도록.\n",
    "    story = story_chain.invoke({\"topic\" : topic})\n",
    "    summary = summary_chain.invoke({\"content\" : story})\n",
    "    \n",
    "    return {\"전체이야기\" :  story, \"요약\" : summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e9efca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableLambda"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(custom_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "080be05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = custom_chain.invoke(\"호랑이\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc788bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['전체이야기', '요약'])\n"
     ]
    }
   ],
   "source": [
    "print(type(res))\n",
    "print(res.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "55174fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "옛날 옛적, 깊은 숲 속에 호랑이가 살았어요. 이 호랑이 이름은 ‘호호’였답니다. 호호는 무척 용감하고 힘이 세서, 숲의 왕이라고 불렸죠.\n",
      "\n",
      "하루는 호호가 숲 속을 걷고 있었어요. 그러다가 작은 토끼가 웅크리고 있는 걸 발견했어요. 호호가 다가가서 물었어요. “안녕, 친구! 왜 이렇게 숨어 있어?” \n",
      "\n",
      "토끼가 떨리는 목소리로 대답했어요. “호호, 숲 속에 사는 맹수들이 자꾸 나를 괴롭혀서 도망치고 있어.” \n",
      "\n",
      "호호는 그 말을 듣고 생각했어요. “내가 도와줄게! 함께 힘을 합치자!” 그래서 호호와 토끼는 친구가 되었답니다.\n",
      "\n",
      "다음 날, 호호는 토끼와 함께 숲 속으로 나갔어요. 그리고 친구들을 찾아서 용감하게 말했죠. “우리 모두 힘을 내자! 나와 함께 하라!” \n",
      "\n",
      "다람쥐, 사슴, 그리고 새들까지 모두 모였어요. 호호는 다른 동물들에게 힘을 주었어요. “우리가 서로 도와주면 어떤 맹수도 두렵지 않아!”\n",
      "\n",
      "그렇게 동물들은 함께 맹수들이 나타나는 곳으로 갔어요. 그리고 호호가 큰 소리로 외쳤어요. “이리 와, 맹수들! 우리는 두렵지 않단다!”\n",
      "\n",
      "그러자 무서운 늑대가 나타났어요. 늑대가 ‘어쩔 수 없군’ 하며 퇴각하려고 했는데, 호호가 용감하게 맞섰어요. “우리는 항상 하나니까, 너희는 더 이상 괴롭힐 수 없어!”\n",
      "\n",
      "호호의 용기에 다른 동물들도 힘을 내었답니다. 그 모습을 보고 늑대는 쫄아서 도망쳤어요. 동물들은 모두 기뻐하며 춤을 췄어요.\n",
      "\n",
      "“호호, 우리를 지켜줘서 고마워!” 토끼가 외쳤어요. 호호는 미소 지으며 대답했어요. “친구를 돕는 건 당연한 일이야.”\n",
      "\n",
      "그 이후로 호호는 더욱 더 숲의 영웅이 되었어요. 어떤 동물이 위험에 처해도, 호호는 항상 나서서 도와줬답니다. \n",
      "\n",
      "호호와 친구들은 해가 지고 밤이 되어도 함께 놀며 행복하게 살았어요. 호호는 이제 숲 위험을 감지하는 ‘호호 경보’가 되었답니다!\n",
      "\n",
      "그리고 매일 밤, 별이 반짝일 때면 호호는 친구들에게 이야기해 주었어요. “우리는 언제나 함께라서 강해! 두려울 게 하나도 없어!”\n",
      "\n",
      "이렇게 호호와 친구들은 사랑과 용기로 가득한 숲 속에서 오래오래 행복하게 살았답니다. 이제 여러분도 그들의 이야기를 마음 속에 담고 함께 용감해질 수 있기를 바래요. 잘 잤으면 좋겠어요!\n"
     ]
    }
   ],
   "source": [
    "print(res[\"전체이야기\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e95ce54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호호라는 용감한 호랑이는 숲에서 친구 토끼를 도와 함께 힘을 합쳐 맹수들에 맞섰고, 그 과정에서 다양한 동물들과 우정을 쌓았다. 이후 호호는 숲의 영웅으로서 친구들을 보호하며 행복한 삶을 살게 되었다.\n"
     ]
    }
   ],
   "source": [
    "print(res[\"요약\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8b48ae-b4b2-412f-a7b5-17e9c1ebc1a4",
   "metadata": {},
   "source": [
    "# Cache\n",
    "\n",
    "- 응답 결과를 저장해서 같은 질문이 들어오면 LLM에 요청하지 않고 저장된 결과를 보여주도록 한다.\n",
    "    - 처리속도와 비용을 절감할 수 있다.\n",
    "    - 특히 chatbot같이 비슷한 질문을 하는 경우 유용하다.\n",
    "- 저장 방식은 `메모리`, `sqlite` 등 다양한 방식을 지원한다.\n",
    "  \n",
    "    ```python\n",
    "    set_llm_cache(Cache객체)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1e498cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "# 메모장에 text를 적고 file에 저장하는 것 데이터를 파일에 저장하는 느낌.. ?\n",
    "\n",
    "# 대화 내역을 cache에 저장\n",
    "set_llm_cache(InMemoryCache())\t# memory에 저장\n",
    "# set_llm_cache(SQLiteCache(\"llm_cache.sqlite\"))\t# 얘는 file로 저장한거라 restart해도 바로바로야 음~\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "response = model.invoke(\"주요 프로그래밍 언어 5개 설명 부탁~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9d501e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 아래는 현재 널리 사용되는 주요 프로그래밍 언어 다섯 가지에 대한 간단한 설명입니다.\n",
      "\n",
      "1. **Python**:\n",
      "   - **개요**: Python은 간결하고 읽기 쉬운 문법을 가지고 있어 초보자부터 전문가까지 폭넓게 사용되는 언어입니다.\n",
      "   - **특징**: 다목적 언어로, 웹 개발, 데이터 분석, 인공지능, 머신러닝, 자동화 스크립팅 등에 활용됩니다. 다양한 라이브러리와 프레임워크(예: Django, Flask, Pandas, TensorFlow)가 제공되어 생산성을 높입니다.\n",
      "\n",
      "2. **JavaScript**:\n",
      "   - **개요**: JavaScript는 주로 웹 페이지의 인터랙션과 동적 콘텐츠 작성을 위해 사용되는 프로그래밍 언어입니다.\n",
      "   - **특징**: 클라이언트 측 언어로 시작했지만, Node.js와 같은 런타임 환경 덕분에 서버 측에서도 사용됩니다. React, Angular, Vue.js 등의 프레임워크와 함께 풍부한 웹 애플리케이션 개발을 지원합니다.\n",
      "\n",
      "3. **Java**:\n",
      "   - **개요**: Java는 객체 지향 프로그래밍 언어로, \"한 번 작성하면 어디서나 실행된다\"는 슬로건을 내세웁니다.\n",
      "   - **특징**: 플랫폼에 독립적인 특성 덕분에 다양한 환경에서 실행 가능하며, 대규모 기업 애플리케이션과 안드로이드 앱 개발에 많이 사용됩니다. 장기적인 유지보수와 안정성을 중시하는 경우에 적합합니다.\n",
      "\n",
      "4. **C++**:\n",
      "   - **개요**: C++는 C 언어의 확장으로, 객체 지향 프로그래밍을 지원하며 시스템 프로그래밍 및 성능이 중요한 어플리케이션에 적합합니다.\n",
      "   - **특징**: 게임 개발, 그래픽 소프트웨어, 임베디드 시스템 등에서 널리 사용됩니다. C++는 메모리 관리와 성능을 세밀하게 조정할 수 있어 복잡한 시스템의 개발에 강력한 도구가 됩니다.\n",
      "\n",
      "5. **C#**:\n",
      "   - **개요**: C#은 마이크로소프트가 만든 프로그래밍 언어로, .NET 프레임워크와 함께 사용되며 주로 윈도우 애플리케이션과 게임 개발에 사용됩니다.\n",
      "   - **특징**: 객체 지향 언어로, 다양한 개발 환경(예: ASP.NET, Unity 게임 엔진)에서 활용됩니다. 강력한 타입 시스템과 관리되는 환경 덕분에 안정성이 뛰어나며, 생산성이 높습니다.\n",
      "\n",
      "이 언어들은 각기 다른 강점과 특성이 있어 사용 용도에 따라 선택하여 사용할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8df9d895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 아래는 현재 널리 사용되는 주요 프로그래밍 언어 다섯 가지에 대한 간단한 설명입니다.\n",
      "\n",
      "1. **Python**:\n",
      "   - **개요**: Python은 간결하고 읽기 쉬운 문법을 가지고 있어 초보자부터 전문가까지 폭넓게 사용되는 언어입니다.\n",
      "   - **특징**: 다목적 언어로, 웹 개발, 데이터 분석, 인공지능, 머신러닝, 자동화 스크립팅 등에 활용됩니다. 다양한 라이브러리와 프레임워크(예: Django, Flask, Pandas, TensorFlow)가 제공되어 생산성을 높입니다.\n",
      "\n",
      "2. **JavaScript**:\n",
      "   - **개요**: JavaScript는 주로 웹 페이지의 인터랙션과 동적 콘텐츠 작성을 위해 사용되는 프로그래밍 언어입니다.\n",
      "   - **특징**: 클라이언트 측 언어로 시작했지만, Node.js와 같은 런타임 환경 덕분에 서버 측에서도 사용됩니다. React, Angular, Vue.js 등의 프레임워크와 함께 풍부한 웹 애플리케이션 개발을 지원합니다.\n",
      "\n",
      "3. **Java**:\n",
      "   - **개요**: Java는 객체 지향 프로그래밍 언어로, \"한 번 작성하면 어디서나 실행된다\"는 슬로건을 내세웁니다.\n",
      "   - **특징**: 플랫폼에 독립적인 특성 덕분에 다양한 환경에서 실행 가능하며, 대규모 기업 애플리케이션과 안드로이드 앱 개발에 많이 사용됩니다. 장기적인 유지보수와 안정성을 중시하는 경우에 적합합니다.\n",
      "\n",
      "4. **C++**:\n",
      "   - **개요**: C++는 C 언어의 확장으로, 객체 지향 프로그래밍을 지원하며 시스템 프로그래밍 및 성능이 중요한 어플리케이션에 적합합니다.\n",
      "   - **특징**: 게임 개발, 그래픽 소프트웨어, 임베디드 시스템 등에서 널리 사용됩니다. C++는 메모리 관리와 성능을 세밀하게 조정할 수 있어 복잡한 시스템의 개발에 강력한 도구가 됩니다.\n",
      "\n",
      "5. **C#**:\n",
      "   - **개요**: C#은 마이크로소프트가 만든 프로그래밍 언어로, .NET 프레임워크와 함께 사용되며 주로 윈도우 애플리케이션과 게임 개발에 사용됩니다.\n",
      "   - **특징**: 객체 지향 언어로, 다양한 개발 환경(예: ASP.NET, Unity 게임 엔진)에서 활용됩니다. 강력한 타입 시스템과 관리되는 환경 덕분에 안정성이 뛰어나며, 생산성이 높습니다.\n",
      "\n",
      "이 언어들은 각기 다른 강점과 특성이 있어 사용 용도에 따라 선택하여 사용할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# cache에 저장되어 있느 상태라서 바로 불러옴요\n",
    "response = model.invoke(\"주요 프로그래밍 언어 5개 설명 부탁~\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a177db65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langchain은 자연어 처리(NLP)와 관련된 다양한 작업을 쉽게 수행할 수 있도록 돕는 프레임워크입니다. 주로 대화형 AI 시스템, 챗봇 및 다양한 자연어 처리 애플리케이션의 개발을 지원합니다. Langchain은 다음과 같은 주요 기능을 제공합니다:\\n\\n1. **모듈화된 구성 요소**: Langchain은 다양한 모듈들을 제공하여 개발자가 필요한 기능을 조합하여 사용할 수 있게 합니다. 예를 들어, 텍스트 전처리, 모델 선택, 후처리 등의 작업을 각각의 모듈로 나누어 처리할 수 있습니다.\\n\\n2. **다양한 모델 지원**: Langchain은 여러 가지 언어 모델을 통합할 수 있는 기능을 제공하여, 사용자가 OpenAI의 GPT-3, Hugging Face의 Transformers 모델 등 여러 모델 중에서 선택하여 사용할 수 있도록 합니다.\\n\\n3. **대화 생성**: Langchain은 사용자와의 상호작용을 위한 대화 생성 기능을 강화하여, 자연스럽고 일관된 대화를 생성할 수 있게 도와줍니다.\\n\\n4. **사용자 정의**: 개발자가 요구하는 특정 니즈에 맞게 모델을 조정하거나 특화된 데이터를 사용하여 맞춤형 모델을 쉽게 구축할 수 있는 기능을 제공합니다.\\n\\n5. **데이터 통합**: Langchain은 외부 데이터베이스 및 API와의 통합을 용이하게 하여, 더 많은 데이터를 기반으로 한 강력한 기능을 구현할 수 있습니다.\\n\\nLangchain은 이러한 구조 덕분에 개발자들이 빠르게 프로토타입을 만들고, 실험하며, 다양한 자연어 처리 문제를 해결하는데 도움을 줍니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 369, 'prompt_tokens': 14, 'total_tokens': 383, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BhEJIjI0xx8PFEYrmrz0vx0ily01y', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c69031b1-fd21-44ea-a1ff-e5d9ea3bbf95-0', usage_metadata={'input_tokens': 14, 'output_tokens': 369, 'total_tokens': 383, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Langchain에 대해 설명 부탁 ~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3e8c002f-7f0c-4357-b3ae-efe8569f04cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langchain은 자연어 처리(NLP)와 관련된 다양한 작업을 쉽게 수행할 수 있도록 돕는 프레임워크입니다. 주로 대화형 AI 시스템, 챗봇 및 다양한 자연어 처리 애플리케이션의 개발을 지원합니다. Langchain은 다음과 같은 주요 기능을 제공합니다:\\n\\n1. **모듈화된 구성 요소**: Langchain은 다양한 모듈들을 제공하여 개발자가 필요한 기능을 조합하여 사용할 수 있게 합니다. 예를 들어, 텍스트 전처리, 모델 선택, 후처리 등의 작업을 각각의 모듈로 나누어 처리할 수 있습니다.\\n\\n2. **다양한 모델 지원**: Langchain은 여러 가지 언어 모델을 통합할 수 있는 기능을 제공하여, 사용자가 OpenAI의 GPT-3, Hugging Face의 Transformers 모델 등 여러 모델 중에서 선택하여 사용할 수 있도록 합니다.\\n\\n3. **대화 생성**: Langchain은 사용자와의 상호작용을 위한 대화 생성 기능을 강화하여, 자연스럽고 일관된 대화를 생성할 수 있게 도와줍니다.\\n\\n4. **사용자 정의**: 개발자가 요구하는 특정 니즈에 맞게 모델을 조정하거나 특화된 데이터를 사용하여 맞춤형 모델을 쉽게 구축할 수 있는 기능을 제공합니다.\\n\\n5. **데이터 통합**: Langchain은 외부 데이터베이스 및 API와의 통합을 용이하게 하여, 더 많은 데이터를 기반으로 한 강력한 기능을 구현할 수 있습니다.\\n\\nLangchain은 이러한 구조 덕분에 개발자들이 빠르게 프로토타입을 만들고, 실험하며, 다양한 자연어 처리 문제를 해결하는데 도움을 줍니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 369, 'prompt_tokens': 14, 'total_tokens': 383, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BhEJIjI0xx8PFEYrmrz0vx0ily01y', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c69031b1-fd21-44ea-a1ff-e5d9ea3bbf95-0', usage_metadata={'input_tokens': 14, 'output_tokens': 369, 'total_tokens': 383, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Langchain에 대해 설명 부탁 ~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74a46a8-703c-452b-9d57-e80749c3f528",
   "metadata": {},
   "source": [
    "# streaming 방식 응답 처리 !\n",
    "- LLM 응답 완료를 기다리지 않고 실시간으로 우다다 생성되는 토큰/청크를 받아서 처리함\n",
    "- `모델.invoke(input, config) -> 응답 데이터` : 모델의 응답을 기달뎠다가 완료되면 한번에 반환 (마지막에 `<EOS>` 출력되면 토큰들 묶어서 줌)\n",
    "- `모델.stream(input, config) -> Iterator` : 모델이 토큰을 생성하면 바로바로 반환 (timestep 마다 나오는 토큰들을 계속 줌)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "520effd5-677c-46e3-9068-553e973bfea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name = \"gpt-4o-mini\")\n",
    "res = model.stream(\"AI에 대해서 설명 부탁 ~\")\n",
    "print(type(res))\t# Iterator 안에 generator가 있삼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66ad3761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI(인공지능)는 인간의 지능을 모방하거나 확장하는 컴퓨터 시스템이나 프로그램을 의미합니다. AI는 여러 분야에서 다양한 형태로 발전하고 있으며, 크게 두 가지 범주로 나눌 수 있습니다.\n",
      "\n",
      "1. **약한 AI(Weak AI)**: 특정 작업이나 문제를 해결하기 위해 설계된 AI로, 이론적인 인공지능을 가지고 있지 않습니다. 예를 들어, 음성 인식 소프트웨어, 추천 시스템, 자율주행차의 경량 알고리즘 등이 이에 해당합니다.\n",
      "\n",
      "2. **강한 AI(Strong AI)**: 인간과 같은 수준의 지능을 갖춘 AI로, 일반적인 문제 해결 및 학습 능력을 갖추고 있습니다. 현재로서는 강한 AI는 이론적 개념에 가깝고, 실제로 존재하지 않습니다.\n",
      "\n",
      "AI는 머신러닝(Machine Learning)과 딥러닝(Deep Learning) 같은 기술을 통해 발전하고 있습니다. 머신러닝은 데이터에서 학습하여 패턴을 인식하고 예측하는 기술이며, 딥러닝은 인공신경망을 이용하여 더욱 복잡한 문제를 해결하는 하위 분야입니다.\n",
      "\n",
      "AI의 응용 분야는 매우 광범위하며, 예를 들어 의료 진단, 자연어 처리, 이미지 인식, 게임, 로봇 공학 등에서 활용되고 있습니다. AI 기술은 산업 전반에 걸쳐 혁신을 이루고 있으며, 앞으로도 계속해서 발전할 것으로 예상됩니다. \n",
      "\n",
      "AI의 발전은 여러 가지 윤리적, 사회적 질문을 야기하고 있으며, 이에 대한 논의도 활발히 이루어지고 있습니다."
     ]
    }
   ],
   "source": [
    "for token in model.stream(\"AI에 대해서 설명 부탁 ~\"):\n",
    "    print(token.content, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
