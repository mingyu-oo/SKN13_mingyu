{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e145329",
   "metadata": {},
   "source": [
    "# Langchain의 Memory 기능\n",
    "\n",
    "**Memory**란 사용자가 대규모 언어 모델(LLM, Large Language Model)과 주고받은 대화 내용을 저장하고 이를 이후의 대화에 활용하는 기능을 말한다.\n",
    "\n",
    "## 왜 Memory가 필요한가?\n",
    "\n",
    "- 기본적으로 LLM은 상태 비저장 **(stateless)** 모델이다. 애초부터 거대 언어 **생성** 모델이니까\n",
    "  - 의미: 한 번의 질문에 대해 답변을 제공하고, 그 이후에는 해당 질문과 답변 내용을 기억하지 못한다. 따라서 사용자가 이전 대화에 기반한 후속 질문을 하면, 모델은 맥락을 이해하지 못하고 정확한 답변을 하지 못한다.\n",
    "- 이 문제를 해결하기 위해, 지금까지의 대화 내용을 저장하고 이후 질문을 할 때 함께 제공하여 맥락을 이어갈 수 있도록 하는 기능이 바로 **Memory**이다.\n",
    "\n",
    "## Memory의 동작 방식\n",
    "\n",
    "- 사용자의 질문과 LLM의 응답을 저장한다.\n",
    "- 이후 사용자가 새로운 질문을 하면, **저장된 이전 대화 내용과 함께 모델에 전달**하여 자연스러운 연속 대화가 가능하도록 한다.\n",
    "- **주의**:\n",
    "  - LLM은 입력으로 받을 수 있는 [**토큰(Token)** 수에 제한](https://platform.openai.com/docs/models/compare)이 있다. 그래서 대화 내용을 무한정 저장하고 전달할 수 없으며, 필요한 내용을 선택적으로 요약하거나 필터링해서 사용해야 한다.\n",
    "\n",
    "![memory.png](figures/memory.png)\n",
    "\n",
    "- 어디에 저장할지, 입력과 출력을 어떤 알고리즘으로 저장할지."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d6ffb",
   "metadata": {},
   "source": [
    "# 메시지 저장소: ChatMessageHistory\n",
    "메시지 기록을 관리하는 객체로 어디에 저장느냐에 따라 여러 클래스들이 구현되어 제공된다.\n",
    "\n",
    "## 종류\n",
    "- **BaseChatMessageHistory**\n",
    "    - 모든 메시지 기록 저장소 클래스의 **기본(최상위) 클래스**이다. 메시지를 저장하고 검색하는 기능을 정의하고 있으며, 이 클래스를 상속받아 다양한 저장소 방식이 구현된다.\n",
    "- **InMemoryChatMessageHistory**\n",
    "    - 메시지를 **메모리에 저장**하는 방식이다. 속도가 빠르지만, 프로그램을 종료하면 저장된 메시지는 사라진다.\n",
    "- 외부 저장소 연동 \n",
    "    - Langchain은 다양한 **3rd-party 저장소**와 연동할 수 있다. 예를 들어 SQLite, PostgreSQL, Redis, MongoDB 등을 사용해 메시지를 영구적으로 저장할 수 있다.\n",
    "    - https://python.langchain.com/docs/integrations/memory/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9ac90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# ChatMessageHistory : 대화내역 저장소\n",
    "#######################################\n",
    "\n",
    "# memory에 저장\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\t# memory에 저장\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\t# role별 Message 객체\n",
    "\n",
    "# HumanMessage(\"내용\") = (\"user\", \"내용\")\n",
    "# AIMessage(\"내용\") = (\"ai\", \"내용\")\n",
    "# SystemMessage(\"내용\") = (\"system\", \"내용\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a369f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장소 객체 생성\n",
    "message_history = InMemoryChatMessageHistory()\n",
    "\n",
    "# 저장소에 메세지 추가\n",
    "message_history.add_message(SystemMessage(\"당신은 여행 가이드 입니다.\")) # = (\"system\", \"당신은 여행 가이드 입니다.\")\n",
    "message_history.add_message(HumanMessage(\"서울의 여행지 세 곳을 추천해줘용.\"))\t# 질문\n",
    "message_history.add_message(AIMessage(\"경북궁, 덕수궁, 창덕궁 가셈 ㅋㅋ\"))\t\t# 응답, .add_ai_message로도 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f70bf5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 여행 가이드 입니다.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='서울의 여행지 세 곳을 추천해줘용.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='경북궁, 덕수궁, 창덕궁 가셈 ㅋㅋ', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장소에 저장된 대화 이력을 조회\n",
    "message_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccad613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB에 저장 (SQLite)\n",
    "# (참고) langchain_community : 3rd party 리소스/도구(외부 저장소)들과 연결하는 library\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from sqlalchemy import create_engine\t# DB와 연결하기 위해\n",
    "\n",
    "# SQLite\n",
    "# engine = create_engine(\"sqlite:///message_history.sqlite\")\n",
    "# MySQL과 연동\n",
    "engine = create_engine(\"mysql+pymysql://root:1111@localhost:3306/hr\")\n",
    "\n",
    "sql_message_history = SQLChatMessageHistory(\n",
    "    session_id=\"user_1\",\t\t# 대화내역을 저장할 사용자 ID(구분자)\n",
    "    connection=engine\n",
    ")\n",
    "\n",
    "sql_message_history.add_user_message(\"안녕하세요\")\n",
    "sql_message_history.add_ai_message(\"안녕하세요, 어떻게 도와드릴깝쇼 ?!?!\")\n",
    "sql_message_history.add_user_message(\"이름이 뭐에여 ? 저나버너뭐에여 ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e3ba031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕하세요', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요, 어떻게 도와드릴깝쇼 ?!?!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='이름이 뭐에여 ? 저나버너뭐에여 ?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='안녕하세요', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요, 어떻게 도와드릴깝쇼 ?!?!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='이름이 뭐에여 ? 저나버너뭐에여 ?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_message_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5a82702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Using cached PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Using cached PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90598455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='나는 User-2 입니둥', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_message_history = SQLChatMessageHistory(\n",
    "    session_id=\"user_2\",\t\t# 대화내역을 저장할 사용자 ID(구분자)\n",
    "    connection=engine\n",
    ")\n",
    "sql_message_history.add_user_message(\"나는 User-2 입니둥\")\n",
    "# sql_message_history.messages\n",
    "sql_message_history.get_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccbd9f7",
   "metadata": {},
   "source": [
    "# RunnableWithMessageHistory\n",
    "\n",
    "- **`RunnableWithMessageHistory`**는 대화형 애플리케이션에서 **이전 메시지 기록을 자동으로 관리**하여 **대화의 맥락을 유지**할 수 있도록 돕는 클래스이다.  \n",
    "- 이 기능은 **Runnable 체인**과 메시지 저장소인 **ChatMessageHistory**를 결합하여 구현된다.\n",
    "- 대화형 애플리케이션에서는 사용자와 AI 간의 여러 번의 주고받는 대화를 통해 작업을 수행한다. 이때, 이전 대화 내용을 기억하지 못하면 일관성 없는 응답이 발생할 수 있다. \n",
    "- `RunnableWithMessageHistory`는 이러한 문제를 해결하고 대화 흐름을 자연스럽게 유지하도록 설계되었다.\n",
    "\n",
    "## 활용\n",
    "\n",
    "- **대화형 챗봇**: 이전 대화 내용을 바탕으로 사용자 질문에 적절하게 응답해야 하는 경우.\n",
    "- **단계적 워크플로우 처리**: 여러 단계를 거쳐 정보를 처리할 때, 앞 단계의 결과를 기반으로 다음 작업을 수행해야 하는 경우.\n",
    "\n",
    "## 특징\n",
    "\n",
    "- 체인이 실행될 때마다 **대화 메시지를 자동으로 기록**하여 개발자가 별도로 상태를 관리하지 않아도 된다.\n",
    "- `session_id`를 사용하여 대화를 구분한다.\n",
    "  - 동일한 `session_id`를 사용하면 이전 대화를 이어갈 수 있다.\n",
    "  - 새로운 `session_id`를 사용하면 새로운 대화로 인식된다.\n",
    "\n",
    "## 생성\n",
    "\n",
    "`RunnableWithMessageHistory`는 다음과 같은 요소들을 initializer에 전달해 생성한다.\n",
    "\n",
    "- **runnable**: 실제 작업을 수행하는 체인(`Runnable`) 객체이다.\n",
    "- **get_session_history**: 주어진 `session_id`에 해당하는 메시지 기록 저장소(`ChatMessageHistory`) 객체를 반환하는 함수이다.\n",
    "- **input_messages_key**: 사용자 입력 메시지를 저장할 입력 필드의 이름이다.\n",
    "- **history_messages_key**: 저장된 이전 대화 메시지를 불러올 필드의 이름이다.\n",
    "\n",
    "이를 통해 체인을 실행할 때마다 이전 메시지가 자동으로 전달되고, 새로운 메시지도 기록된다.\n",
    "\n",
    "[Langchain Memory Integration 문서](https://python.langchain.com/docs/integrations/memory/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e07cd2",
   "metadata": {},
   "source": [
    "## RunnableWithMessageHistory를 이용해 Chain 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "127a5245-32e4-4ea6-80c4-a593787302a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c18e83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", (\"당신은 AI 분야 전문가야. \"\n",
    "         \"전문가 스타일로 답변해 주시길. \"\n",
    "         \"답변은 20단어 이내로 설명 부탁. \"\n",
    "         \"정확하지 않은 경우 모른다고 꼭 말해주시길.\")),\n",
    "        MessagesPlaceholder(variable_name=\"history\", optional=True),\t# = (\"placeholder\", \"{history}\")\n",
    "        (\"human\", \"{query}\")\n",
    "\t]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model_name = \"gpt-4o-mini\")\n",
    "chain = prompt_template | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"질문\"\n",
    "# response = chain.invoke({\"query\" : query, \"history\" : message_history.get_messages()})\n",
    "# message_history.add_message(query)\n",
    "# message_history.add_message(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa191434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_session_history(session_id:str) -> InMemoryChatMessageHistory:\n",
    "#     # session_id를 받아서 그 session id의 대화를 관리하는 ChatMessageHistory를 반환.\n",
    "#     engine = create_engine(\"mysql+pymysql://playdata:1111@localhost:3306/hr\")\n",
    "\n",
    "#     sql_message_history = SQLChatMessageHistory(\n",
    "#         session_id=session_id, # 대화내역을 저장할 사용자 ID(구분자)\n",
    "#         connection=engine\n",
    "#     )\n",
    "#     return sql_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0648b639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': InMemoryChatMessageHistory(messages=[])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key: session_id, Value: InMemoryChatMessageHistory객체 -> session_id별로 따로 저장소를 생성해서 관리\n",
    "# InMemoryChatMessageHistory는 session_id별로 대화를 관리하는 기능이 없음. 만들어줘야함\n",
    "store = {}\n",
    "def get_session_history(session_id : str) -> InMemoryChatMessageHistory:\n",
    "    # user의 session_id를 받아서 그 session id의 대화를 관리하는 ChatMessageHistory를 반환.\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "get_session_history(\"1\")\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70522cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    runnable=chain,\t\t\t\t\t# 실제 대화를 처리할 chain (prompt_template -> model -> parser(optional))\n",
    "    get_session_history=get_session_history,\t# Session_id를 받아서 그 사용자의 대화를 관리하는 대화 저장소를 제공하는 func or callable\n",
    "    input_messages_key=\"query\",\t\t# 사용자 질문을 넣을 PromptTemplate의 변수 이름.\n",
    "    history_messages_key=\"history\"\t# 대화이력(저장소에서 조회한)을 넣을 PromptTemplate의 변수 이름.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32b39f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우망구님, 어떤 주제에 대해 이야기하고 싶으신가요?\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_history.invoke(\n",
    "    {\"query\" : \"내이름은 우망구입니다.\"},\n",
    "    {\"configurable\" : {\"session_id\" : \"user-1\"}}\n",
    ")\n",
    "print(response.content)\n",
    "# invoke/stream(input, config)\n",
    "## config 형식 : dictionary - (\"configurable\" : {\"설정 key : 설정 value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ad2c884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': InMemoryChatMessageHistory(messages=[]),\n",
       " 'user-1': InMemoryChatMessageHistory(messages=[HumanMessage(content='내이름은 우망구입니다.', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요, 우망구님! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 64, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BhAxBHJz7ZgDMLzSqRUQB8X5cidw2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--66167b4e-d001-41d2-b161-776a3a1c22a5-0', usage_metadata={'input_tokens': 64, 'output_tokens': 15, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='내이름은 우망구입니다.', additional_kwargs={}, response_metadata={}), AIMessage(content='우망구님, 어떤 주제에 대해 이야기하고 싶으신가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 96, 'total_tokens': 114, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BhAxOYgWZdzXXlIAmgIYA1TFxnJNf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--fc394bf8-ae63-4a02-a384-ce682c32ea9a-0', usage_metadata={'input_tokens': 96, 'output_tokens': 18, 'total_tokens': 114, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be239e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = chain_with_history.invoke({\"query\" : \"내 이름 알아 ?\"}, {\"configurable\" : {\"session_id\" : \"user-1\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "338d30fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'네, 우망구님이라고 말씀하셨습니다.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27f318f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='내이름은 우망구입니다.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요, 우망구님! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 64, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BhAxBHJz7ZgDMLzSqRUQB8X5cidw2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--66167b4e-d001-41d2-b161-776a3a1c22a5-0', usage_metadata={'input_tokens': 64, 'output_tokens': 15, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='내이름은 우망구입니다.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='우망구님, 어떤 주제에 대해 이야기하고 싶으신가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 96, 'total_tokens': 114, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BhAxOYgWZdzXXlIAmgIYA1TFxnJNf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--fc394bf8-ae63-4a02-a384-ce682c32ea9a-0', usage_metadata={'input_tokens': 96, 'output_tokens': 18, 'total_tokens': 114, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='내 이름 알아 ?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='네, 우망구님이라고 말씀하셨습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 126, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BhAzjPtzzviPioAd301Cdabe9m1ve', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4222f9a2-da57-40e3-92d5-8e4fedd33ee2-0', usage_metadata={'input_tokens': 126, 'output_tokens': 12, 'total_tokens': 138, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['user-1'].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12f232db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'죄송하지만, 당신의 이름을 알 수 없습니다. 정보를 제공해주시면 도움을 드릴 수 있습니다.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    {\"query\" : \"내이름 뭐라꼬 ??\"},\n",
    "    {\"configurable\" : {\"session_id\" : \"user-2\"}}\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abead1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='내이름 뭐라꼬 ??', additional_kwargs={}, response_metadata={}), AIMessage(content='죄송하지만, 당신의 이름을 알 수 없습니다. 정보를 제공해주시면 도움을 드릴 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 63, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-BhB4a8SqA6xAQ6Qj2yc8RzIoqm2by', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e8e9301b-de4e-4ce6-8eb3-d4e85fddc77e-0', usage_metadata={'input_tokens': 63, 'output_tokens': 24, 'total_tokens': 87, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"user-2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23a6df0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> User : 내 이름은 우망규야\n",
      "<<<<< AI : 안녕하세요, 우망규님! 무엇을 도와드릴까요?\n",
      ">>>>> User : 내 이름 기억하니 ?\n",
      "<<<<< AI : 죄송하지만, 이전 대화 내용을 기억할 수는 없습니다. 질문이나 도움이 필요하시면 말씀해 주세요!\n",
      ">>>>> User : 대답을 좀 하자 친구야\n",
      "<<<<< AI : 물론입니다, 우망규님! 어떤 질문이나 주제가 궁금하신가요? 활발히 대화하겠습니다.\n",
      ">>>> 대화 끗\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\" : {\"session_id\" : \"conv-1\"}}\n",
    "\n",
    "while True:\n",
    "    query = input(\"User Prompt\")\n",
    "    query_dict = {\"query\" : query}\n",
    "    if query == \"!q\":\n",
    "        print(\">>>> 대화 끗\")\n",
    "        break\n",
    "    res = chain_with_history.invoke(query_dict, config)\n",
    "    print(f\">>>>> User : {query}\")\n",
    "    print(f\"<<<<< AI : {res.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
